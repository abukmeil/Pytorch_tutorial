{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feed-Forward Neural Network</h1> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: yellow;\">This tutorial covers the implementation of a feedforward neural network for digit classification using the MNIST dataset.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">This tutorial builds upon the previous tutorials where we utilized:</h3>\n",
    "\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">DataLoader for loading the MNIST dataset.</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">Transform for MNIST dataset transformation.</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">nn.Module to construct our model with an input layer, a hidden layer, and an output layer.</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">Activation functions ReLU and Softmax (Softmax embedded within the loss).</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">Loss and optimization.</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">Batch training loop.</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">Model evaluation.</span></li>\n",
    "  <li><span style=\"color:yellow; font-size: 110%;\">GPU support.</span></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src='bio_activation.png' width=500>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device config\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters definition\n",
    "INPUT_SIZE=784 # 28*28 image size\n",
    "HIDDEN_SIZE=200\n",
    "OUTPUT_SIZE=10\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=64\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset=torchvision.datasets.MNIST(root='./data',\n",
    "                                         train=True,\n",
    "                                         transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "test_dataset=torchvision.datasets.MNIST(root='./data',train=False,\n",
    "                                        transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the first batch: torch.Size([64, 1, 28, 28]) || The shape of the first batch of labels torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "# Print the first batch by converting the train_loader into an iterator object.\n",
    "batch_iter=iter(train_loader)\n",
    "samples, labels=next(batch_iter)\n",
    "print(f'The shape of the first batch: {samples.shape} || The shape of the first batch of labels {labels.shape}')\n",
    "# [64,1,28,28]---> [batch,channel,nrows,ncolumns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a sample of  images\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(samples[i][0],cmap='gray') # We use samples[i][0] with [0] since we intend to access the first channel.\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "class NNET(nn.Module):\n",
    "    def __init__(self, INPUT_SIZE,HIDDEN_SIZE,OUTPUT_SIZE, *args, **kwargs):\n",
    "        super(NNET,self).__init__(*args, **kwargs)\n",
    "        self.l1=nn.Linear(INPUT_SIZE,HIDDEN_SIZE)\n",
    "        self.relu=nn.ReLU(self.l1)\n",
    "        self.l2=nn.Linear(HIDDEN_SIZE,OUTPUT_SIZE) # OUTPUT_SIZE == Numof example\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.relu(self.l1(x))\n",
    "        out=self.l2(out) \n",
    "        #Note: In this context, we refrain from using an activation function due to our intention to apply the binary cross-entropy loss, which inherently incorporates the activation function\n",
    "        return out    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss, and optimization\n",
    "model=NNET(INPUT_SIZE,HIDDEN_SIZE,OUTPUT_SIZE).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/ 10, step 50/938, loss =0.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/ 10, step 100/938, loss =0.489\n",
      "epoch 1/ 10, step 150/938, loss =0.366\n",
      "epoch 1/ 10, step 200/938, loss =0.213\n",
      "epoch 1/ 10, step 250/938, loss =0.225\n",
      "epoch 1/ 10, step 300/938, loss =0.154\n",
      "epoch 1/ 10, step 350/938, loss =0.170\n",
      "epoch 1/ 10, step 400/938, loss =0.364\n",
      "epoch 1/ 10, step 450/938, loss =0.183\n",
      "epoch 1/ 10, step 500/938, loss =0.356\n",
      "epoch 1/ 10, step 550/938, loss =0.152\n",
      "epoch 1/ 10, step 600/938, loss =0.210\n",
      "epoch 1/ 10, step 650/938, loss =0.346\n",
      "epoch 1/ 10, step 700/938, loss =0.228\n",
      "epoch 1/ 10, step 750/938, loss =0.334\n",
      "epoch 1/ 10, step 800/938, loss =0.329\n",
      "epoch 1/ 10, step 850/938, loss =0.139\n",
      "epoch 1/ 10, step 900/938, loss =0.129\n",
      "epoch 2/ 10, step 50/938, loss =0.118\n",
      "epoch 2/ 10, step 100/938, loss =0.054\n",
      "epoch 2/ 10, step 150/938, loss =0.172\n",
      "epoch 2/ 10, step 200/938, loss =0.204\n",
      "epoch 2/ 10, step 250/938, loss =0.104\n",
      "epoch 2/ 10, step 300/938, loss =0.061\n",
      "epoch 2/ 10, step 350/938, loss =0.072\n",
      "epoch 2/ 10, step 400/938, loss =0.159\n",
      "epoch 2/ 10, step 450/938, loss =0.142\n",
      "epoch 2/ 10, step 500/938, loss =0.046\n",
      "epoch 2/ 10, step 550/938, loss =0.133\n",
      "epoch 2/ 10, step 600/938, loss =0.104\n",
      "epoch 2/ 10, step 650/938, loss =0.184\n",
      "epoch 2/ 10, step 700/938, loss =0.159\n",
      "epoch 2/ 10, step 750/938, loss =0.148\n",
      "epoch 2/ 10, step 800/938, loss =0.131\n",
      "epoch 2/ 10, step 850/938, loss =0.151\n",
      "epoch 2/ 10, step 900/938, loss =0.150\n",
      "epoch 3/ 10, step 50/938, loss =0.111\n",
      "epoch 3/ 10, step 100/938, loss =0.228\n",
      "epoch 3/ 10, step 150/938, loss =0.131\n",
      "epoch 3/ 10, step 200/938, loss =0.019\n",
      "epoch 3/ 10, step 250/938, loss =0.057\n",
      "epoch 3/ 10, step 300/938, loss =0.277\n",
      "epoch 3/ 10, step 350/938, loss =0.024\n",
      "epoch 3/ 10, step 400/938, loss =0.037\n",
      "epoch 3/ 10, step 450/938, loss =0.115\n",
      "epoch 3/ 10, step 500/938, loss =0.080\n",
      "epoch 3/ 10, step 550/938, loss =0.025\n",
      "epoch 3/ 10, step 600/938, loss =0.034\n",
      "epoch 3/ 10, step 650/938, loss =0.027\n",
      "epoch 3/ 10, step 700/938, loss =0.042\n",
      "epoch 3/ 10, step 750/938, loss =0.091\n",
      "epoch 3/ 10, step 800/938, loss =0.062\n",
      "epoch 3/ 10, step 850/938, loss =0.115\n",
      "epoch 3/ 10, step 900/938, loss =0.103\n",
      "epoch 4/ 10, step 50/938, loss =0.042\n",
      "epoch 4/ 10, step 100/938, loss =0.116\n",
      "epoch 4/ 10, step 150/938, loss =0.162\n",
      "epoch 4/ 10, step 200/938, loss =0.074\n",
      "epoch 4/ 10, step 250/938, loss =0.060\n",
      "epoch 4/ 10, step 300/938, loss =0.042\n",
      "epoch 4/ 10, step 350/938, loss =0.042\n",
      "epoch 4/ 10, step 400/938, loss =0.045\n",
      "epoch 4/ 10, step 450/938, loss =0.031\n",
      "epoch 4/ 10, step 500/938, loss =0.076\n",
      "epoch 4/ 10, step 550/938, loss =0.077\n",
      "epoch 4/ 10, step 600/938, loss =0.088\n",
      "epoch 4/ 10, step 650/938, loss =0.032\n",
      "epoch 4/ 10, step 700/938, loss =0.066\n",
      "epoch 4/ 10, step 750/938, loss =0.056\n",
      "epoch 4/ 10, step 800/938, loss =0.047\n",
      "epoch 4/ 10, step 850/938, loss =0.054\n",
      "epoch 4/ 10, step 900/938, loss =0.059\n",
      "epoch 5/ 10, step 50/938, loss =0.035\n",
      "epoch 5/ 10, step 100/938, loss =0.133\n",
      "epoch 5/ 10, step 150/938, loss =0.055\n",
      "epoch 5/ 10, step 200/938, loss =0.013\n",
      "epoch 5/ 10, step 250/938, loss =0.088\n",
      "epoch 5/ 10, step 300/938, loss =0.043\n",
      "epoch 5/ 10, step 350/938, loss =0.011\n",
      "epoch 5/ 10, step 400/938, loss =0.018\n",
      "epoch 5/ 10, step 450/938, loss =0.045\n",
      "epoch 5/ 10, step 500/938, loss =0.037\n",
      "epoch 5/ 10, step 550/938, loss =0.015\n",
      "epoch 5/ 10, step 600/938, loss =0.025\n",
      "epoch 5/ 10, step 650/938, loss =0.038\n",
      "epoch 5/ 10, step 700/938, loss =0.015\n",
      "epoch 5/ 10, step 750/938, loss =0.094\n",
      "epoch 5/ 10, step 800/938, loss =0.070\n",
      "epoch 5/ 10, step 850/938, loss =0.032\n",
      "epoch 5/ 10, step 900/938, loss =0.016\n",
      "epoch 6/ 10, step 50/938, loss =0.043\n",
      "epoch 6/ 10, step 100/938, loss =0.012\n",
      "epoch 6/ 10, step 150/938, loss =0.030\n",
      "epoch 6/ 10, step 200/938, loss =0.016\n",
      "epoch 6/ 10, step 250/938, loss =0.019\n",
      "epoch 6/ 10, step 300/938, loss =0.010\n",
      "epoch 6/ 10, step 350/938, loss =0.040\n",
      "epoch 6/ 10, step 400/938, loss =0.035\n",
      "epoch 6/ 10, step 450/938, loss =0.033\n",
      "epoch 6/ 10, step 500/938, loss =0.068\n",
      "epoch 6/ 10, step 550/938, loss =0.066\n",
      "epoch 6/ 10, step 600/938, loss =0.014\n",
      "epoch 6/ 10, step 650/938, loss =0.028\n",
      "epoch 6/ 10, step 700/938, loss =0.002\n",
      "epoch 6/ 10, step 750/938, loss =0.011\n",
      "epoch 6/ 10, step 800/938, loss =0.018\n",
      "epoch 6/ 10, step 850/938, loss =0.064\n",
      "epoch 6/ 10, step 900/938, loss =0.055\n",
      "epoch 7/ 10, step 50/938, loss =0.038\n",
      "epoch 7/ 10, step 100/938, loss =0.010\n",
      "epoch 7/ 10, step 150/938, loss =0.016\n",
      "epoch 7/ 10, step 200/938, loss =0.009\n",
      "epoch 7/ 10, step 250/938, loss =0.007\n",
      "epoch 7/ 10, step 300/938, loss =0.040\n",
      "epoch 7/ 10, step 350/938, loss =0.017\n",
      "epoch 7/ 10, step 400/938, loss =0.008\n",
      "epoch 7/ 10, step 450/938, loss =0.003\n",
      "epoch 7/ 10, step 500/938, loss =0.005\n",
      "epoch 7/ 10, step 550/938, loss =0.032\n",
      "epoch 7/ 10, step 600/938, loss =0.065\n",
      "epoch 7/ 10, step 650/938, loss =0.019\n",
      "epoch 7/ 10, step 700/938, loss =0.058\n",
      "epoch 7/ 10, step 750/938, loss =0.010\n",
      "epoch 7/ 10, step 800/938, loss =0.007\n",
      "epoch 7/ 10, step 850/938, loss =0.036\n",
      "epoch 7/ 10, step 900/938, loss =0.011\n",
      "epoch 8/ 10, step 50/938, loss =0.011\n",
      "epoch 8/ 10, step 100/938, loss =0.003\n",
      "epoch 8/ 10, step 150/938, loss =0.010\n",
      "epoch 8/ 10, step 200/938, loss =0.031\n",
      "epoch 8/ 10, step 250/938, loss =0.010\n",
      "epoch 8/ 10, step 300/938, loss =0.032\n",
      "epoch 8/ 10, step 350/938, loss =0.008\n",
      "epoch 8/ 10, step 400/938, loss =0.012\n",
      "epoch 8/ 10, step 450/938, loss =0.057\n",
      "epoch 8/ 10, step 500/938, loss =0.016\n",
      "epoch 8/ 10, step 550/938, loss =0.044\n",
      "epoch 8/ 10, step 600/938, loss =0.039\n",
      "epoch 8/ 10, step 650/938, loss =0.003\n",
      "epoch 8/ 10, step 700/938, loss =0.016\n",
      "epoch 8/ 10, step 750/938, loss =0.011\n",
      "epoch 8/ 10, step 800/938, loss =0.004\n",
      "epoch 8/ 10, step 850/938, loss =0.003\n",
      "epoch 8/ 10, step 900/938, loss =0.016\n",
      "epoch 9/ 10, step 50/938, loss =0.014\n",
      "epoch 9/ 10, step 100/938, loss =0.002\n",
      "epoch 9/ 10, step 150/938, loss =0.023\n",
      "epoch 9/ 10, step 200/938, loss =0.010\n",
      "epoch 9/ 10, step 250/938, loss =0.008\n",
      "epoch 9/ 10, step 300/938, loss =0.002\n",
      "epoch 9/ 10, step 350/938, loss =0.006\n",
      "epoch 9/ 10, step 400/938, loss =0.024\n",
      "epoch 9/ 10, step 450/938, loss =0.009\n",
      "epoch 9/ 10, step 500/938, loss =0.010\n",
      "epoch 9/ 10, step 550/938, loss =0.004\n",
      "epoch 9/ 10, step 600/938, loss =0.018\n",
      "epoch 9/ 10, step 650/938, loss =0.003\n",
      "epoch 9/ 10, step 700/938, loss =0.005\n",
      "epoch 9/ 10, step 750/938, loss =0.009\n",
      "epoch 9/ 10, step 800/938, loss =0.036\n",
      "epoch 9/ 10, step 850/938, loss =0.030\n",
      "epoch 9/ 10, step 900/938, loss =0.006\n",
      "epoch 10/ 10, step 50/938, loss =0.004\n",
      "epoch 10/ 10, step 100/938, loss =0.004\n",
      "epoch 10/ 10, step 150/938, loss =0.015\n",
      "epoch 10/ 10, step 200/938, loss =0.002\n",
      "epoch 10/ 10, step 250/938, loss =0.022\n",
      "epoch 10/ 10, step 300/938, loss =0.007\n",
      "epoch 10/ 10, step 350/938, loss =0.017\n",
      "epoch 10/ 10, step 400/938, loss =0.001\n",
      "epoch 10/ 10, step 450/938, loss =0.019\n",
      "epoch 10/ 10, step 500/938, loss =0.001\n",
      "epoch 10/ 10, step 550/938, loss =0.003\n",
      "epoch 10/ 10, step 600/938, loss =0.018\n",
      "epoch 10/ 10, step 650/938, loss =0.018\n",
      "epoch 10/ 10, step 700/938, loss =0.002\n",
      "epoch 10/ 10, step 750/938, loss =0.016\n",
      "epoch 10/ 10, step 800/938, loss =0.009\n",
      "epoch 10/ 10, step 850/938, loss =0.005\n",
      "epoch 10/ 10, step 900/938, loss =0.005\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "N_TOTAL_STEPS=len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (samples,labels) in enumerate(train_loader):\n",
    "        # data shape= [100,1,28,28] we have to reahpe the data to be in  shape of 100 x 784\n",
    "        samples=samples.reshape(-1,28*28).to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs=model(samples)\n",
    "        loss_=loss(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad() \n",
    "        loss_.backward()\n",
    "        optimizer.step() # update the parameters \n",
    "        \n",
    "        if (i+1) % 50   ==0:\n",
    "            print(f'epoch {epoch+1}/ {EPOCHS}, step {i+1}/{N_TOTAL_STEPS}, loss ={loss_.item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is: 97.99%\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    for samples,labels in test_loader:\n",
    "        samples=samples.reshape(-1,28*28).to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(samples)\n",
    "        _, prediction= torch.max(outputs,1) # return the value of the index\n",
    "        n_samples+=labels.shape[0]\n",
    "        n_correct+=(prediction==labels).sum().item()\n",
    "total_accuracy= (n_correct/n_samples)*100\n",
    "print(f'The final accuracy is: {total_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
