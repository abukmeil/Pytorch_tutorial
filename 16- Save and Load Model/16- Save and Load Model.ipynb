{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save and Load Pytorch Model</h1>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Saving the model can be achieved in two ways: (a) by saving the entire model (<span style=\"color: red;\">torch.save(model, 'model.pth')</span>), or (b) by saving only the model parameters, which is the recommended method (<span style=\"color: red;\">torch.save(model.state_dict(), 'model_weights.pth')</span>).</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">In addition to the model parameters, we can also save attributes such as epochs, loss, optimizer states, and more.</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/lib/python3/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuda\n",
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class SCNN(nn.Module):\n",
    "    def __init__(self,n_channels,n_classes):\n",
    "        super(SCNN,self).__init__()\n",
    "        self.n_channels=n_channels\n",
    "        self.n_classes=n_classes\n",
    "        self.conv1=nn.Conv2d(in_channels=self.n_channels,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.max_pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.fc=nn.Linear(16*7*7, self.n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.max_pool(F.relu(self.conv1(x)))\n",
    "        out=self.max_pool(F.relu(self.conv2(out)))\n",
    "        out=out.reshape(out.shape[0],-1)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and hyperparameters\n",
    "IN_CHANNELS=1\n",
    "NUM_CLASSES=10\n",
    "LR=0.001\n",
    "BATCH_SIZE=128\n",
    "EPOCHS=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datset and dataloader\n",
    "train_dataset=MNIST(root='dataset/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset=MNIST(root='dataset/',train=False,transform=transforms.ToTensor(),download=True)\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model=SCNN(IN_CHANNELS,NUM_CLASSES).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "0/5 | step: 0/ 469 | loss: 2.3037\n",
      "0/5 | step: 20/ 469 | loss: 2.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5 | step: 40/ 469 | loss: 1.4196\n",
      "0/5 | step: 60/ 469 | loss: 0.7532\n",
      "0/5 | step: 80/ 469 | loss: 0.5039\n",
      "0/5 | step: 100/ 469 | loss: 0.5457\n",
      "0/5 | step: 120/ 469 | loss: 0.3653\n",
      "0/5 | step: 140/ 469 | loss: 0.4000\n",
      "0/5 | step: 160/ 469 | loss: 0.3868\n",
      "0/5 | step: 180/ 469 | loss: 0.2893\n",
      "0/5 | step: 200/ 469 | loss: 0.2670\n",
      "0/5 | step: 220/ 469 | loss: 0.2309\n",
      "0/5 | step: 240/ 469 | loss: 0.1280\n",
      "0/5 | step: 260/ 469 | loss: 0.2090\n",
      "0/5 | step: 280/ 469 | loss: 0.2064\n",
      "0/5 | step: 300/ 469 | loss: 0.2114\n",
      "0/5 | step: 320/ 469 | loss: 0.2540\n",
      "0/5 | step: 340/ 469 | loss: 0.1429\n",
      "0/5 | step: 360/ 469 | loss: 0.2036\n",
      "0/5 | step: 380/ 469 | loss: 0.1336\n",
      "0/5 | step: 400/ 469 | loss: 0.1237\n",
      "0/5 | step: 420/ 469 | loss: 0.0952\n",
      "0/5 | step: 440/ 469 | loss: 0.2018\n",
      "0/5 | step: 460/ 469 | loss: 0.1668\n",
      "1/5 | step: 0/ 469 | loss: 0.2461\n",
      "1/5 | step: 20/ 469 | loss: 0.1150\n",
      "1/5 | step: 40/ 469 | loss: 0.0900\n",
      "1/5 | step: 60/ 469 | loss: 0.1047\n",
      "1/5 | step: 80/ 469 | loss: 0.0783\n",
      "1/5 | step: 100/ 469 | loss: 0.1295\n",
      "1/5 | step: 120/ 469 | loss: 0.1230\n",
      "1/5 | step: 140/ 469 | loss: 0.0668\n",
      "1/5 | step: 160/ 469 | loss: 0.1963\n",
      "1/5 | step: 180/ 469 | loss: 0.1199\n",
      "1/5 | step: 200/ 469 | loss: 0.1522\n",
      "1/5 | step: 220/ 469 | loss: 0.0697\n",
      "1/5 | step: 240/ 469 | loss: 0.0924\n",
      "1/5 | step: 260/ 469 | loss: 0.0698\n",
      "1/5 | step: 280/ 469 | loss: 0.1058\n",
      "1/5 | step: 300/ 469 | loss: 0.0985\n",
      "1/5 | step: 320/ 469 | loss: 0.0603\n",
      "1/5 | step: 340/ 469 | loss: 0.0816\n",
      "1/5 | step: 360/ 469 | loss: 0.1051\n",
      "1/5 | step: 380/ 469 | loss: 0.0976\n",
      "1/5 | step: 400/ 469 | loss: 0.0974\n",
      "1/5 | step: 420/ 469 | loss: 0.0967\n",
      "1/5 | step: 440/ 469 | loss: 0.0793\n",
      "1/5 | step: 460/ 469 | loss: 0.0959\n",
      "Saving checkpoint\n",
      "2/5 | step: 0/ 469 | loss: 0.0746\n",
      "2/5 | step: 20/ 469 | loss: 0.0818\n",
      "2/5 | step: 40/ 469 | loss: 0.0760\n",
      "2/5 | step: 60/ 469 | loss: 0.0854\n",
      "2/5 | step: 80/ 469 | loss: 0.0995\n",
      "2/5 | step: 100/ 469 | loss: 0.1200\n",
      "2/5 | step: 120/ 469 | loss: 0.0783\n",
      "2/5 | step: 140/ 469 | loss: 0.0389\n",
      "2/5 | step: 160/ 469 | loss: 0.1205\n",
      "2/5 | step: 180/ 469 | loss: 0.0927\n",
      "2/5 | step: 200/ 469 | loss: 0.0346\n",
      "2/5 | step: 220/ 469 | loss: 0.0835\n",
      "2/5 | step: 240/ 469 | loss: 0.0461\n",
      "2/5 | step: 260/ 469 | loss: 0.0611\n",
      "2/5 | step: 280/ 469 | loss: 0.2125\n",
      "2/5 | step: 300/ 469 | loss: 0.0691\n",
      "2/5 | step: 320/ 469 | loss: 0.0615\n",
      "2/5 | step: 340/ 469 | loss: 0.1236\n",
      "2/5 | step: 360/ 469 | loss: 0.1120\n",
      "2/5 | step: 380/ 469 | loss: 0.0756\n",
      "2/5 | step: 400/ 469 | loss: 0.0865\n",
      "2/5 | step: 420/ 469 | loss: 0.0502\n",
      "2/5 | step: 440/ 469 | loss: 0.0440\n",
      "2/5 | step: 460/ 469 | loss: 0.0963\n",
      "3/5 | step: 0/ 469 | loss: 0.0850\n",
      "3/5 | step: 20/ 469 | loss: 0.0381\n",
      "3/5 | step: 40/ 469 | loss: 0.0383\n",
      "3/5 | step: 60/ 469 | loss: 0.1020\n",
      "3/5 | step: 80/ 469 | loss: 0.0682\n",
      "3/5 | step: 100/ 469 | loss: 0.0754\n",
      "3/5 | step: 120/ 469 | loss: 0.0285\n",
      "3/5 | step: 140/ 469 | loss: 0.0816\n",
      "3/5 | step: 160/ 469 | loss: 0.0457\n",
      "3/5 | step: 180/ 469 | loss: 0.0292\n",
      "3/5 | step: 200/ 469 | loss: 0.0454\n",
      "3/5 | step: 220/ 469 | loss: 0.0629\n",
      "3/5 | step: 240/ 469 | loss: 0.0521\n",
      "3/5 | step: 260/ 469 | loss: 0.0629\n",
      "3/5 | step: 280/ 469 | loss: 0.0189\n",
      "3/5 | step: 300/ 469 | loss: 0.1319\n",
      "3/5 | step: 320/ 469 | loss: 0.0526\n",
      "3/5 | step: 340/ 469 | loss: 0.0432\n",
      "3/5 | step: 360/ 469 | loss: 0.0392\n",
      "3/5 | step: 380/ 469 | loss: 0.0597\n",
      "3/5 | step: 400/ 469 | loss: 0.0824\n",
      "3/5 | step: 420/ 469 | loss: 0.0218\n",
      "3/5 | step: 440/ 469 | loss: 0.1262\n",
      "3/5 | step: 460/ 469 | loss: 0.1629\n",
      "Saving checkpoint\n",
      "4/5 | step: 0/ 469 | loss: 0.0372\n",
      "4/5 | step: 20/ 469 | loss: 0.0941\n",
      "4/5 | step: 40/ 469 | loss: 0.0539\n",
      "4/5 | step: 60/ 469 | loss: 0.0739\n",
      "4/5 | step: 80/ 469 | loss: 0.0431\n",
      "4/5 | step: 100/ 469 | loss: 0.0881\n",
      "4/5 | step: 120/ 469 | loss: 0.0296\n",
      "4/5 | step: 140/ 469 | loss: 0.0802\n",
      "4/5 | step: 160/ 469 | loss: 0.0408\n",
      "4/5 | step: 180/ 469 | loss: 0.0273\n",
      "4/5 | step: 200/ 469 | loss: 0.0381\n",
      "4/5 | step: 220/ 469 | loss: 0.0439\n",
      "4/5 | step: 240/ 469 | loss: 0.0388\n",
      "4/5 | step: 260/ 469 | loss: 0.0211\n",
      "4/5 | step: 280/ 469 | loss: 0.0819\n",
      "4/5 | step: 300/ 469 | loss: 0.0834\n",
      "4/5 | step: 320/ 469 | loss: 0.0282\n",
      "4/5 | step: 340/ 469 | loss: 0.0295\n",
      "4/5 | step: 360/ 469 | loss: 0.1046\n",
      "4/5 | step: 380/ 469 | loss: 0.0309\n",
      "4/5 | step: 400/ 469 | loss: 0.0458\n",
      "4/5 | step: 420/ 469 | loss: 0.0629\n",
      "4/5 | step: 440/ 469 | loss: 0.0735\n",
      "4/5 | step: 460/ 469 | loss: 0.0485\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "def save_checkpoint(state,file_path='my_checkpoint.pth.tar'):\n",
    "    print('Saving checkpoint')\n",
    "    torch.save(state,file_path)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    checkpoint={'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "    if epoch%2==0:  # Save every two epochs\n",
    "        save_checkpoint(checkpoint)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i, (data,labels) in enumerate(train_loader):\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device)\n",
    "        prediction=model(data)\n",
    "        loss_=loss(prediction,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%20==0:\n",
    "            print(f'{epoch}/{EPOCHS} | step: {i}/ {len(train_loader)} | loss: {loss_.item():.4f}')   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained 59008/60000 with accuracy: 98.35\n",
      "Checking accuracy on test data\n",
      "Obtained 9819/10000 with accuracy: 98.19\n"
     ]
    }
   ],
   "source": [
    "# check accuracy on training and test to see how good our model is\n",
    "def check_accuracy(loader,model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on training data')\n",
    "    else:\n",
    "        print('Checking accuracy on test data')\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,label in loader:\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "            prediction=model(data)\n",
    "            _,pred=prediction.max(1)\n",
    "            num_correct+=(pred==label).sum()\n",
    "            num_samples+=pred.size(0)\n",
    "        print(f'Obtained {num_correct}/{num_samples} with accuracy: '\n",
    "            f'{float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading the saved checkpoint .....</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model=SCNN(IN_CHANNELS,NUM_CLASSES).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint..\n",
      "Saving checkpoint\n",
      "0/5 | step: 0/ 469 | loss: 0.0264\n",
      "0/5 | step: 20/ 469 | loss: 0.1308\n",
      "0/5 | step: 40/ 469 | loss: 0.0552\n",
      "0/5 | step: 60/ 469 | loss: 0.0406\n",
      "0/5 | step: 80/ 469 | loss: 0.1265\n",
      "0/5 | step: 100/ 469 | loss: 0.0795\n",
      "0/5 | step: 120/ 469 | loss: 0.0361\n",
      "0/5 | step: 140/ 469 | loss: 0.0317\n",
      "0/5 | step: 160/ 469 | loss: 0.1040\n",
      "0/5 | step: 180/ 469 | loss: 0.0540\n",
      "0/5 | step: 200/ 469 | loss: 0.0936\n",
      "0/5 | step: 220/ 469 | loss: 0.0170\n",
      "0/5 | step: 240/ 469 | loss: 0.0578\n",
      "0/5 | step: 260/ 469 | loss: 0.0617\n",
      "0/5 | step: 280/ 469 | loss: 0.0465\n",
      "0/5 | step: 300/ 469 | loss: 0.0837\n",
      "0/5 | step: 320/ 469 | loss: 0.0685\n",
      "0/5 | step: 340/ 469 | loss: 0.0447\n",
      "0/5 | step: 360/ 469 | loss: 0.1036\n",
      "0/5 | step: 380/ 469 | loss: 0.0657\n",
      "0/5 | step: 400/ 469 | loss: 0.0842\n",
      "0/5 | step: 420/ 469 | loss: 0.0689\n",
      "0/5 | step: 440/ 469 | loss: 0.0327\n",
      "0/5 | step: 460/ 469 | loss: 0.1045\n",
      "1/5 | step: 0/ 469 | loss: 0.0757\n",
      "1/5 | step: 20/ 469 | loss: 0.0607\n",
      "1/5 | step: 40/ 469 | loss: 0.1234\n",
      "1/5 | step: 60/ 469 | loss: 0.0883\n",
      "1/5 | step: 80/ 469 | loss: 0.0451\n",
      "1/5 | step: 100/ 469 | loss: 0.0808\n",
      "1/5 | step: 120/ 469 | loss: 0.0945\n",
      "1/5 | step: 140/ 469 | loss: 0.1073\n",
      "1/5 | step: 160/ 469 | loss: 0.0141\n",
      "1/5 | step: 180/ 469 | loss: 0.0408\n",
      "1/5 | step: 200/ 469 | loss: 0.0527\n",
      "1/5 | step: 220/ 469 | loss: 0.0246\n",
      "1/5 | step: 240/ 469 | loss: 0.1356\n",
      "1/5 | step: 260/ 469 | loss: 0.0558\n",
      "1/5 | step: 280/ 469 | loss: 0.0355\n",
      "1/5 | step: 300/ 469 | loss: 0.0414\n",
      "1/5 | step: 320/ 469 | loss: 0.0536\n",
      "1/5 | step: 340/ 469 | loss: 0.0300\n",
      "1/5 | step: 360/ 469 | loss: 0.0732\n",
      "1/5 | step: 380/ 469 | loss: 0.0447\n",
      "1/5 | step: 400/ 469 | loss: 0.0765\n",
      "1/5 | step: 420/ 469 | loss: 0.0389\n",
      "1/5 | step: 440/ 469 | loss: 0.0133\n",
      "1/5 | step: 460/ 469 | loss: 0.0719\n",
      "Saving checkpoint\n",
      "2/5 | step: 0/ 469 | loss: 0.1141\n",
      "2/5 | step: 20/ 469 | loss: 0.0504\n",
      "2/5 | step: 40/ 469 | loss: 0.0760\n",
      "2/5 | step: 60/ 469 | loss: 0.0341\n",
      "2/5 | step: 80/ 469 | loss: 0.0583\n",
      "2/5 | step: 100/ 469 | loss: 0.0423\n",
      "2/5 | step: 120/ 469 | loss: 0.0394\n",
      "2/5 | step: 140/ 469 | loss: 0.0789\n",
      "2/5 | step: 160/ 469 | loss: 0.1298\n",
      "2/5 | step: 180/ 469 | loss: 0.0185\n",
      "2/5 | step: 200/ 469 | loss: 0.0341\n",
      "2/5 | step: 220/ 469 | loss: 0.0642\n",
      "2/5 | step: 240/ 469 | loss: 0.0612\n",
      "2/5 | step: 260/ 469 | loss: 0.0137\n",
      "2/5 | step: 280/ 469 | loss: 0.1050\n",
      "2/5 | step: 300/ 469 | loss: 0.0330\n",
      "2/5 | step: 320/ 469 | loss: 0.0531\n",
      "2/5 | step: 340/ 469 | loss: 0.0225\n",
      "2/5 | step: 360/ 469 | loss: 0.0324\n",
      "2/5 | step: 380/ 469 | loss: 0.1050\n",
      "2/5 | step: 400/ 469 | loss: 0.0326\n",
      "2/5 | step: 420/ 469 | loss: 0.0903\n",
      "2/5 | step: 440/ 469 | loss: 0.0361\n",
      "2/5 | step: 460/ 469 | loss: 0.0873\n",
      "3/5 | step: 0/ 469 | loss: 0.0430\n",
      "3/5 | step: 20/ 469 | loss: 0.0693\n",
      "3/5 | step: 40/ 469 | loss: 0.0247\n",
      "3/5 | step: 60/ 469 | loss: 0.0380\n",
      "3/5 | step: 80/ 469 | loss: 0.0725\n",
      "3/5 | step: 100/ 469 | loss: 0.0332\n",
      "3/5 | step: 120/ 469 | loss: 0.0264\n",
      "3/5 | step: 140/ 469 | loss: 0.0133\n",
      "3/5 | step: 160/ 469 | loss: 0.0357\n",
      "3/5 | step: 180/ 469 | loss: 0.0117\n",
      "3/5 | step: 200/ 469 | loss: 0.0154\n",
      "3/5 | step: 220/ 469 | loss: 0.0488\n",
      "3/5 | step: 240/ 469 | loss: 0.0600\n",
      "3/5 | step: 260/ 469 | loss: 0.1552\n",
      "3/5 | step: 280/ 469 | loss: 0.0294\n",
      "3/5 | step: 300/ 469 | loss: 0.0987\n",
      "3/5 | step: 320/ 469 | loss: 0.0355\n",
      "3/5 | step: 340/ 469 | loss: 0.0359\n",
      "3/5 | step: 360/ 469 | loss: 0.0968\n",
      "3/5 | step: 380/ 469 | loss: 0.0413\n",
      "3/5 | step: 400/ 469 | loss: 0.0385\n",
      "3/5 | step: 420/ 469 | loss: 0.0188\n",
      "3/5 | step: 440/ 469 | loss: 0.0519\n",
      "3/5 | step: 460/ 469 | loss: 0.0742\n",
      "Saving checkpoint\n",
      "4/5 | step: 0/ 469 | loss: 0.0495\n",
      "4/5 | step: 20/ 469 | loss: 0.0504\n",
      "4/5 | step: 40/ 469 | loss: 0.0599\n",
      "4/5 | step: 60/ 469 | loss: 0.0931\n",
      "4/5 | step: 80/ 469 | loss: 0.0109\n",
      "4/5 | step: 100/ 469 | loss: 0.0059\n",
      "4/5 | step: 120/ 469 | loss: 0.0361\n",
      "4/5 | step: 140/ 469 | loss: 0.0838\n",
      "4/5 | step: 160/ 469 | loss: 0.0151\n",
      "4/5 | step: 180/ 469 | loss: 0.0181\n",
      "4/5 | step: 200/ 469 | loss: 0.0121\n",
      "4/5 | step: 220/ 469 | loss: 0.0267\n",
      "4/5 | step: 240/ 469 | loss: 0.0206\n",
      "4/5 | step: 260/ 469 | loss: 0.0371\n",
      "4/5 | step: 280/ 469 | loss: 0.0293\n",
      "4/5 | step: 300/ 469 | loss: 0.0334\n",
      "4/5 | step: 320/ 469 | loss: 0.0234\n",
      "4/5 | step: 340/ 469 | loss: 0.0520\n",
      "4/5 | step: 360/ 469 | loss: 0.0410\n",
      "4/5 | step: 380/ 469 | loss: 0.0217\n",
      "4/5 | step: 400/ 469 | loss: 0.0376\n",
      "4/5 | step: 420/ 469 | loss: 0.0473\n",
      "4/5 | step: 440/ 469 | loss: 0.0167\n",
      "4/5 | step: 460/ 469 | loss: 0.0617\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "load_model=True\n",
    "\n",
    "def load_checkpoint(checkpoint):\n",
    "    print('Loading checkpoint..')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "if load_model:\n",
    "    load_checkpoint(torch.load('my_checkpoint.pth.tar'))    \n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    checkpoint={'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "    if epoch%2==0:  # Save every two epochs\n",
    "        save_checkpoint(checkpoint)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i, (data,labels) in enumerate(train_loader):\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device)\n",
    "        prediction=model(data)\n",
    "        loss_=loss(prediction,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%20==0:\n",
    "            print(f'{epoch}/{EPOCHS} | step: {i}/ {len(train_loader)} | loss: {loss_.item():.4f}')   \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
