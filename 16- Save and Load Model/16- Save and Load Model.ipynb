{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save and Load PyTorch Models</h1>\n",
    "\n",
    "<h3 style=\"color: yellow;\">There are two ways to save the model: (a) saving the entire model with <span style=\"color: red;\">torch.save(model, 'model.pth')</span> or (b) saving only the model parameters, which is the preferred method, using <span style=\"color: red;\">torch.save(model.state_dict(), 'model_weights.pth')</span>.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Beyond just the model parameters, it's possible to save attributes such as the number of epochs, loss values, optimizer states, and more.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">There are three primary methods to keep in mind: (a) <span style=\"color: red;\">torch.save(arg, PATH)</span>, (b) <span style=\"color: red;\">torch.load(PATH)</span>, and (c) <span style=\"color: red;\">model.load_state_dict(arg)</span>.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\"><span style=\"color: red;\">torch.save(arg, PATH)</span> can use tensors, models, or dictionaries as parameters for saving. It employs the Python Pickle module to serialize and save objects.</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyModel(\n",
       "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,n_feat, *args, **kwargs):\n",
    "        super(Model,self).__init__(*args, **kwargs)\n",
    "        self.n_feat=n_feat\n",
    "        self.linear=nn.Linear(n_feat,1)\n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Lazy method for saving and loading model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyModel(nn.Module):\n",
    "    def __init__(self, n_input_features, *args, **kwargs):\n",
    "        super(DummyModel, self).__init__()\n",
    "        self.linear=nn.Linear(n_input_features,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "\n",
    "model = DummyModel(3)\n",
    "\n",
    "torch.save(model,'lazy_model.pth')\n",
    "model=torch.load('lazy_model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4445,  0.0294, -0.0880]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2566], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parm in model.parameters():\n",
    "    print(parm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0770, 0.5616, 0.5434]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5496], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyModel1(\n",
       "  (liner): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The recommended method for saving and loading model by using \"state_dict\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyModel1(nn.Module):\n",
    "    def __init__(self,n_input_features):\n",
    "        super(DummyModel1, self).__init__()\n",
    "        self.liner=nn.Linear(n_input_features,1)\n",
    "    def forward(self, x):\n",
    "        x=torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    \n",
    "# Saving the model\n",
    "model = DummyModel1(3)\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "    \n",
    "torch.save(model.state_dict(), 'modle.pth')        \n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')\n",
    "\n",
    "# Loading the model\n",
    "model.load_state_dict(torch.load('model_state_dict.pth'))\n",
    "model.eval()  # It's a good practice to call eval() after loading to set dropout and batch normalization layers to evaluation mode.\n",
    "# During training, BatchNorm uses the batch's mean and variance. However, during inference, it uses the moving average of the mean and variance, which was computed during training\n",
    "# During inference (or evaluation), we want to utilize the full network without dropping any units, so dropout is turned off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0770, 0.5616, 0.5434]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5496], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# We loaded the parameters of the same model architecture into a new model instance.\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('liner.weight', tensor([[ 0.3238, -0.1527, -0.4669]])), ('liner.bias', tensor([-0.3910]))])\n"
     ]
    }
   ],
   "source": [
    "# Print state_dict\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3572, -0.3858, -0.0631]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4825], requires_grad=True)\n",
      "\n",
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "# Saving the checkpoint during training\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyModel1(nn.Module):\n",
    "    def __init__(self,n_input_features):\n",
    "        super(DummyModel1, self).__init__()\n",
    "        self.liner=nn.Linear(n_input_features,1)\n",
    "    def forward(self, x):\n",
    "        x=torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    \n",
    "# Saving the model\n",
    "model = DummyModel1(3)\n",
    "LR=0.01\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=LR)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('')\n",
    "print(optimizer.state_dict())   # We will notice her that the optimizer has its own state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During the training process we can save the checkpoint at a certain epoch\n",
    "checkpoint={\n",
    "    'epoch':60,\n",
    "    'model_state':model.state_dict(),\n",
    "    'optim_state':optimizer.state_dict()    \n",
    "}\n",
    "torch.save(checkpoint,'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "loaded_checkpoint=torch.load('checkpoint.pth')\n",
    "epoch=loaded_checkpoint['epoch']\n",
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('liner.weight', tensor([[-0.0370,  0.1912,  0.5491]])), ('liner.bias', tensor([-0.5027]))])\n",
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "# What if we want to continue the training process from the checkpoint?\n",
    "\n",
    "model=DummyModel1(n_input_features=3)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0) # LR is zero because we will load the optimizer state from the checkpoint to continue the training process\n",
    "model.load_state_dict(loaded_checkpoint['model_state'])\n",
    "optimizer.load_state_dict(loaded_checkpoint['optim_state'])\n",
    "\n",
    "print(model.state_dict())\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the training and saving processes were completed on a CPU, we can use the aforementioned implementation.\n",
    "# If the training was done on a GPU and we want to load on a CPU, we should proceed as follows:\n",
    "\n",
    "device=torch.device('cuda')\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(),'model.pth')\n",
    "\n",
    "#loading ...\n",
    "\n",
    "device=torch.device('cpu')\n",
    "model=DummyModel1(n_input_features=3)\n",
    "model.load_state_dict(torch.load('model.pth',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the training has completed on GPU, and want to load in a GPU, we follow:\n",
    "device=torch.device('cuda')\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(),'model.pth')\n",
    "\n",
    "# Loading ...\n",
    "\n",
    "model=DummyModel1(n_input_features=3)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the training has completed on CPU, and want to load in a GPU, we follow:\n",
    "torch.save(model.state_dict(),'model.pth')\n",
    "\n",
    "device=torch.device('cuda')\n",
    "model=DummyModel(n_input_features=3)\n",
    "model.load(torch.load('model.pth',map_location=device))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model during training\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuda\n",
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class SCNN(nn.Module):\n",
    "    def __init__(self,n_channels,n_classes):\n",
    "        super(SCNN,self).__init__()\n",
    "        self.n_channels=n_channels\n",
    "        self.n_classes=n_classes\n",
    "        self.conv1=nn.Conv2d(in_channels=self.n_channels,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.max_pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.fc=nn.Linear(16*7*7, self.n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.max_pool(F.relu(self.conv1(x)))\n",
    "        out=self.max_pool(F.relu(self.conv2(out)))\n",
    "        out=out.reshape(out.shape[0],-1)\n",
    "        out=self.fc(out)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and hyperparameters\n",
    "IN_CHANNELS=1\n",
    "NUM_CLASSES=10\n",
    "LR=0.001\n",
    "BATCH_SIZE=128\n",
    "EPOCHS=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datset and dataloader\n",
    "train_dataset=MNIST(root='dataset/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset=MNIST(root='dataset/',train=False,transform=transforms.ToTensor(),download=True)\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_=iter(train_loader)\n",
    "images,labels=next(iter_)\n",
    "images  [0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model=SCNN(IN_CHANNELS,NUM_CLASSES).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "0/5 | step: 0/ 469 | loss: 2.3037\n",
      "0/5 | step: 20/ 469 | loss: 2.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5 | step: 40/ 469 | loss: 1.4196\n",
      "0/5 | step: 60/ 469 | loss: 0.7532\n",
      "0/5 | step: 80/ 469 | loss: 0.5039\n",
      "0/5 | step: 100/ 469 | loss: 0.5457\n",
      "0/5 | step: 120/ 469 | loss: 0.3653\n",
      "0/5 | step: 140/ 469 | loss: 0.4000\n",
      "0/5 | step: 160/ 469 | loss: 0.3868\n",
      "0/5 | step: 180/ 469 | loss: 0.2893\n",
      "0/5 | step: 200/ 469 | loss: 0.2670\n",
      "0/5 | step: 220/ 469 | loss: 0.2309\n",
      "0/5 | step: 240/ 469 | loss: 0.1280\n",
      "0/5 | step: 260/ 469 | loss: 0.2090\n",
      "0/5 | step: 280/ 469 | loss: 0.2064\n",
      "0/5 | step: 300/ 469 | loss: 0.2114\n",
      "0/5 | step: 320/ 469 | loss: 0.2540\n",
      "0/5 | step: 340/ 469 | loss: 0.1429\n",
      "0/5 | step: 360/ 469 | loss: 0.2036\n",
      "0/5 | step: 380/ 469 | loss: 0.1336\n",
      "0/5 | step: 400/ 469 | loss: 0.1237\n",
      "0/5 | step: 420/ 469 | loss: 0.0952\n",
      "0/5 | step: 440/ 469 | loss: 0.2018\n",
      "0/5 | step: 460/ 469 | loss: 0.1668\n",
      "1/5 | step: 0/ 469 | loss: 0.2461\n",
      "1/5 | step: 20/ 469 | loss: 0.1150\n",
      "1/5 | step: 40/ 469 | loss: 0.0900\n",
      "1/5 | step: 60/ 469 | loss: 0.1047\n",
      "1/5 | step: 80/ 469 | loss: 0.0783\n",
      "1/5 | step: 100/ 469 | loss: 0.1295\n",
      "1/5 | step: 120/ 469 | loss: 0.1230\n",
      "1/5 | step: 140/ 469 | loss: 0.0668\n",
      "1/5 | step: 160/ 469 | loss: 0.1963\n",
      "1/5 | step: 180/ 469 | loss: 0.1199\n",
      "1/5 | step: 200/ 469 | loss: 0.1522\n",
      "1/5 | step: 220/ 469 | loss: 0.0697\n",
      "1/5 | step: 240/ 469 | loss: 0.0924\n",
      "1/5 | step: 260/ 469 | loss: 0.0698\n",
      "1/5 | step: 280/ 469 | loss: 0.1058\n",
      "1/5 | step: 300/ 469 | loss: 0.0985\n",
      "1/5 | step: 320/ 469 | loss: 0.0603\n",
      "1/5 | step: 340/ 469 | loss: 0.0816\n",
      "1/5 | step: 360/ 469 | loss: 0.1051\n",
      "1/5 | step: 380/ 469 | loss: 0.0976\n",
      "1/5 | step: 400/ 469 | loss: 0.0974\n",
      "1/5 | step: 420/ 469 | loss: 0.0967\n",
      "1/5 | step: 440/ 469 | loss: 0.0793\n",
      "1/5 | step: 460/ 469 | loss: 0.0959\n",
      "Saving checkpoint\n",
      "2/5 | step: 0/ 469 | loss: 0.0746\n",
      "2/5 | step: 20/ 469 | loss: 0.0818\n",
      "2/5 | step: 40/ 469 | loss: 0.0760\n",
      "2/5 | step: 60/ 469 | loss: 0.0854\n",
      "2/5 | step: 80/ 469 | loss: 0.0995\n",
      "2/5 | step: 100/ 469 | loss: 0.1200\n",
      "2/5 | step: 120/ 469 | loss: 0.0783\n",
      "2/5 | step: 140/ 469 | loss: 0.0389\n",
      "2/5 | step: 160/ 469 | loss: 0.1205\n",
      "2/5 | step: 180/ 469 | loss: 0.0927\n",
      "2/5 | step: 200/ 469 | loss: 0.0346\n",
      "2/5 | step: 220/ 469 | loss: 0.0835\n",
      "2/5 | step: 240/ 469 | loss: 0.0461\n",
      "2/5 | step: 260/ 469 | loss: 0.0611\n",
      "2/5 | step: 280/ 469 | loss: 0.2125\n",
      "2/5 | step: 300/ 469 | loss: 0.0691\n",
      "2/5 | step: 320/ 469 | loss: 0.0615\n",
      "2/5 | step: 340/ 469 | loss: 0.1236\n",
      "2/5 | step: 360/ 469 | loss: 0.1120\n",
      "2/5 | step: 380/ 469 | loss: 0.0756\n",
      "2/5 | step: 400/ 469 | loss: 0.0865\n",
      "2/5 | step: 420/ 469 | loss: 0.0502\n",
      "2/5 | step: 440/ 469 | loss: 0.0440\n",
      "2/5 | step: 460/ 469 | loss: 0.0963\n",
      "3/5 | step: 0/ 469 | loss: 0.0850\n",
      "3/5 | step: 20/ 469 | loss: 0.0381\n",
      "3/5 | step: 40/ 469 | loss: 0.0383\n",
      "3/5 | step: 60/ 469 | loss: 0.1020\n",
      "3/5 | step: 80/ 469 | loss: 0.0682\n",
      "3/5 | step: 100/ 469 | loss: 0.0754\n",
      "3/5 | step: 120/ 469 | loss: 0.0285\n",
      "3/5 | step: 140/ 469 | loss: 0.0816\n",
      "3/5 | step: 160/ 469 | loss: 0.0457\n",
      "3/5 | step: 180/ 469 | loss: 0.0292\n",
      "3/5 | step: 200/ 469 | loss: 0.0454\n",
      "3/5 | step: 220/ 469 | loss: 0.0629\n",
      "3/5 | step: 240/ 469 | loss: 0.0521\n",
      "3/5 | step: 260/ 469 | loss: 0.0629\n",
      "3/5 | step: 280/ 469 | loss: 0.0189\n",
      "3/5 | step: 300/ 469 | loss: 0.1319\n",
      "3/5 | step: 320/ 469 | loss: 0.0526\n",
      "3/5 | step: 340/ 469 | loss: 0.0432\n",
      "3/5 | step: 360/ 469 | loss: 0.0392\n",
      "3/5 | step: 380/ 469 | loss: 0.0597\n",
      "3/5 | step: 400/ 469 | loss: 0.0824\n",
      "3/5 | step: 420/ 469 | loss: 0.0218\n",
      "3/5 | step: 440/ 469 | loss: 0.1262\n",
      "3/5 | step: 460/ 469 | loss: 0.1629\n",
      "Saving checkpoint\n",
      "4/5 | step: 0/ 469 | loss: 0.0372\n",
      "4/5 | step: 20/ 469 | loss: 0.0941\n",
      "4/5 | step: 40/ 469 | loss: 0.0539\n",
      "4/5 | step: 60/ 469 | loss: 0.0739\n",
      "4/5 | step: 80/ 469 | loss: 0.0431\n",
      "4/5 | step: 100/ 469 | loss: 0.0881\n",
      "4/5 | step: 120/ 469 | loss: 0.0296\n",
      "4/5 | step: 140/ 469 | loss: 0.0802\n",
      "4/5 | step: 160/ 469 | loss: 0.0408\n",
      "4/5 | step: 180/ 469 | loss: 0.0273\n",
      "4/5 | step: 200/ 469 | loss: 0.0381\n",
      "4/5 | step: 220/ 469 | loss: 0.0439\n",
      "4/5 | step: 240/ 469 | loss: 0.0388\n",
      "4/5 | step: 260/ 469 | loss: 0.0211\n",
      "4/5 | step: 280/ 469 | loss: 0.0819\n",
      "4/5 | step: 300/ 469 | loss: 0.0834\n",
      "4/5 | step: 320/ 469 | loss: 0.0282\n",
      "4/5 | step: 340/ 469 | loss: 0.0295\n",
      "4/5 | step: 360/ 469 | loss: 0.1046\n",
      "4/5 | step: 380/ 469 | loss: 0.0309\n",
      "4/5 | step: 400/ 469 | loss: 0.0458\n",
      "4/5 | step: 420/ 469 | loss: 0.0629\n",
      "4/5 | step: 440/ 469 | loss: 0.0735\n",
      "4/5 | step: 460/ 469 | loss: 0.0485\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "def save_checkpoint(state,file_path='my_checkpoint.pth.tar'):\n",
    "    print('Saving checkpoint')\n",
    "    torch.save(state,file_path)\n",
    "\n",
    "\n",
    "checkpoint={'model_state': model.state_dict(),'optimizer_state':optimizer.state_dict()}\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    checkpoint={'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "    if epoch%2==0:  # Save every two epochs\n",
    "        save_checkpoint(checkpoint)\n",
    "        \n",
    "    for i, (data,labels) in enumerate(train_loader):\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device)\n",
    "        prediction=model(data)\n",
    "        loss_=loss(prediction,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%20==0:\n",
    "            print(f'{epoch}/{EPOCHS} | step: {i}/ {len(train_loader)} | loss: {loss_.item():.4f}')   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained 59008/60000 with accuracy: 98.35\n",
      "Checking accuracy on test data\n",
      "Obtained 9819/10000 with accuracy: 98.19\n"
     ]
    }
   ],
   "source": [
    "# check accuracy on training and test to see how good our model is\n",
    "def check_accuracy(loader,model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on training data')\n",
    "    else:\n",
    "        print('Checking accuracy on test data')\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,label in loader:\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "            prediction=model(data)\n",
    "            _,pred=prediction.max(1)\n",
    "            num_correct+=(pred==label).sum()\n",
    "            num_samples+=pred.size(0)\n",
    "        print(f'Obtained {num_correct}/{num_samples} with accuracy: '\n",
    "            f'{float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the checkpoint with the minimal loss\n",
    "\n",
    "def save_checkpoint(state, file_path='my_checkpoint.pth.tar'):\n",
    "    print('Saving checkpoint')\n",
    "    torch.save(state, file_path)\n",
    "\n",
    "min_loss = float('inf')  # Initialize with a large value. When you pass 'inf' to float(), it gives you the floating-point representation of positive infinity.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []  # List to store batch-wise losses for an epoch\n",
    "    \n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predictions = model(data)\n",
    "        \n",
    "        loss_ = loss(predictions, labels)\n",
    "        losses.append(loss_.item())  # Store the batch-wise loss\n",
    "    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f'{epoch}/{EPOCHS} | step: {i}/{len(train_loader)} | loss: {loss_.item():.4f}')\n",
    "    \n",
    "    epoch_loss = sum(losses) / len(losses)  # Average loss for the epoch\n",
    "    \n",
    "    \n",
    "    # Save the model with the minimal loss every two epochs\n",
    "    if epoch % 2 == 0 and epoch_loss < min_loss:\n",
    "        min_loss = epoch_loss\n",
    "        checkpoint = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Saving and Loading the saved checkpoint .....</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model=SCNN(IN_CHANNELS,NUM_CLASSES).to(device)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint..\n",
      "Saving checkpoint\n",
      "0/5 | step: 0/ 469 | loss: 0.0264\n",
      "0/5 | step: 20/ 469 | loss: 0.1308\n",
      "0/5 | step: 40/ 469 | loss: 0.0552\n",
      "0/5 | step: 60/ 469 | loss: 0.0406\n",
      "0/5 | step: 80/ 469 | loss: 0.1265\n",
      "0/5 | step: 100/ 469 | loss: 0.0795\n",
      "0/5 | step: 120/ 469 | loss: 0.0361\n",
      "0/5 | step: 140/ 469 | loss: 0.0317\n",
      "0/5 | step: 160/ 469 | loss: 0.1040\n",
      "0/5 | step: 180/ 469 | loss: 0.0540\n",
      "0/5 | step: 200/ 469 | loss: 0.0936\n",
      "0/5 | step: 220/ 469 | loss: 0.0170\n",
      "0/5 | step: 240/ 469 | loss: 0.0578\n",
      "0/5 | step: 260/ 469 | loss: 0.0617\n",
      "0/5 | step: 280/ 469 | loss: 0.0465\n",
      "0/5 | step: 300/ 469 | loss: 0.0837\n",
      "0/5 | step: 320/ 469 | loss: 0.0685\n",
      "0/5 | step: 340/ 469 | loss: 0.0447\n",
      "0/5 | step: 360/ 469 | loss: 0.1036\n",
      "0/5 | step: 380/ 469 | loss: 0.0657\n",
      "0/5 | step: 400/ 469 | loss: 0.0842\n",
      "0/5 | step: 420/ 469 | loss: 0.0689\n",
      "0/5 | step: 440/ 469 | loss: 0.0327\n",
      "0/5 | step: 460/ 469 | loss: 0.1045\n",
      "1/5 | step: 0/ 469 | loss: 0.0757\n",
      "1/5 | step: 20/ 469 | loss: 0.0607\n",
      "1/5 | step: 40/ 469 | loss: 0.1234\n",
      "1/5 | step: 60/ 469 | loss: 0.0883\n",
      "1/5 | step: 80/ 469 | loss: 0.0451\n",
      "1/5 | step: 100/ 469 | loss: 0.0808\n",
      "1/5 | step: 120/ 469 | loss: 0.0945\n",
      "1/5 | step: 140/ 469 | loss: 0.1073\n",
      "1/5 | step: 160/ 469 | loss: 0.0141\n",
      "1/5 | step: 180/ 469 | loss: 0.0408\n",
      "1/5 | step: 200/ 469 | loss: 0.0527\n",
      "1/5 | step: 220/ 469 | loss: 0.0246\n",
      "1/5 | step: 240/ 469 | loss: 0.1356\n",
      "1/5 | step: 260/ 469 | loss: 0.0558\n",
      "1/5 | step: 280/ 469 | loss: 0.0355\n",
      "1/5 | step: 300/ 469 | loss: 0.0414\n",
      "1/5 | step: 320/ 469 | loss: 0.0536\n",
      "1/5 | step: 340/ 469 | loss: 0.0300\n",
      "1/5 | step: 360/ 469 | loss: 0.0732\n",
      "1/5 | step: 380/ 469 | loss: 0.0447\n",
      "1/5 | step: 400/ 469 | loss: 0.0765\n",
      "1/5 | step: 420/ 469 | loss: 0.0389\n",
      "1/5 | step: 440/ 469 | loss: 0.0133\n",
      "1/5 | step: 460/ 469 | loss: 0.0719\n",
      "Saving checkpoint\n",
      "2/5 | step: 0/ 469 | loss: 0.1141\n",
      "2/5 | step: 20/ 469 | loss: 0.0504\n",
      "2/5 | step: 40/ 469 | loss: 0.0760\n",
      "2/5 | step: 60/ 469 | loss: 0.0341\n",
      "2/5 | step: 80/ 469 | loss: 0.0583\n",
      "2/5 | step: 100/ 469 | loss: 0.0423\n",
      "2/5 | step: 120/ 469 | loss: 0.0394\n",
      "2/5 | step: 140/ 469 | loss: 0.0789\n",
      "2/5 | step: 160/ 469 | loss: 0.1298\n",
      "2/5 | step: 180/ 469 | loss: 0.0185\n",
      "2/5 | step: 200/ 469 | loss: 0.0341\n",
      "2/5 | step: 220/ 469 | loss: 0.0642\n",
      "2/5 | step: 240/ 469 | loss: 0.0612\n",
      "2/5 | step: 260/ 469 | loss: 0.0137\n",
      "2/5 | step: 280/ 469 | loss: 0.1050\n",
      "2/5 | step: 300/ 469 | loss: 0.0330\n",
      "2/5 | step: 320/ 469 | loss: 0.0531\n",
      "2/5 | step: 340/ 469 | loss: 0.0225\n",
      "2/5 | step: 360/ 469 | loss: 0.0324\n",
      "2/5 | step: 380/ 469 | loss: 0.1050\n",
      "2/5 | step: 400/ 469 | loss: 0.0326\n",
      "2/5 | step: 420/ 469 | loss: 0.0903\n",
      "2/5 | step: 440/ 469 | loss: 0.0361\n",
      "2/5 | step: 460/ 469 | loss: 0.0873\n",
      "3/5 | step: 0/ 469 | loss: 0.0430\n",
      "3/5 | step: 20/ 469 | loss: 0.0693\n",
      "3/5 | step: 40/ 469 | loss: 0.0247\n",
      "3/5 | step: 60/ 469 | loss: 0.0380\n",
      "3/5 | step: 80/ 469 | loss: 0.0725\n",
      "3/5 | step: 100/ 469 | loss: 0.0332\n",
      "3/5 | step: 120/ 469 | loss: 0.0264\n",
      "3/5 | step: 140/ 469 | loss: 0.0133\n",
      "3/5 | step: 160/ 469 | loss: 0.0357\n",
      "3/5 | step: 180/ 469 | loss: 0.0117\n",
      "3/5 | step: 200/ 469 | loss: 0.0154\n",
      "3/5 | step: 220/ 469 | loss: 0.0488\n",
      "3/5 | step: 240/ 469 | loss: 0.0600\n",
      "3/5 | step: 260/ 469 | loss: 0.1552\n",
      "3/5 | step: 280/ 469 | loss: 0.0294\n",
      "3/5 | step: 300/ 469 | loss: 0.0987\n",
      "3/5 | step: 320/ 469 | loss: 0.0355\n",
      "3/5 | step: 340/ 469 | loss: 0.0359\n",
      "3/5 | step: 360/ 469 | loss: 0.0968\n",
      "3/5 | step: 380/ 469 | loss: 0.0413\n",
      "3/5 | step: 400/ 469 | loss: 0.0385\n",
      "3/5 | step: 420/ 469 | loss: 0.0188\n",
      "3/5 | step: 440/ 469 | loss: 0.0519\n",
      "3/5 | step: 460/ 469 | loss: 0.0742\n",
      "Saving checkpoint\n",
      "4/5 | step: 0/ 469 | loss: 0.0495\n",
      "4/5 | step: 20/ 469 | loss: 0.0504\n",
      "4/5 | step: 40/ 469 | loss: 0.0599\n",
      "4/5 | step: 60/ 469 | loss: 0.0931\n",
      "4/5 | step: 80/ 469 | loss: 0.0109\n",
      "4/5 | step: 100/ 469 | loss: 0.0059\n",
      "4/5 | step: 120/ 469 | loss: 0.0361\n",
      "4/5 | step: 140/ 469 | loss: 0.0838\n",
      "4/5 | step: 160/ 469 | loss: 0.0151\n",
      "4/5 | step: 180/ 469 | loss: 0.0181\n",
      "4/5 | step: 200/ 469 | loss: 0.0121\n",
      "4/5 | step: 220/ 469 | loss: 0.0267\n",
      "4/5 | step: 240/ 469 | loss: 0.0206\n",
      "4/5 | step: 260/ 469 | loss: 0.0371\n",
      "4/5 | step: 280/ 469 | loss: 0.0293\n",
      "4/5 | step: 300/ 469 | loss: 0.0334\n",
      "4/5 | step: 320/ 469 | loss: 0.0234\n",
      "4/5 | step: 340/ 469 | loss: 0.0520\n",
      "4/5 | step: 360/ 469 | loss: 0.0410\n",
      "4/5 | step: 380/ 469 | loss: 0.0217\n",
      "4/5 | step: 400/ 469 | loss: 0.0376\n",
      "4/5 | step: 420/ 469 | loss: 0.0473\n",
      "4/5 | step: 440/ 469 | loss: 0.0167\n",
      "4/5 | step: 460/ 469 | loss: 0.0617\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "load_model=True\n",
    "\n",
    "def load_checkpoint(checkpoint):\n",
    "    print('Loading checkpoint..')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])    \n",
    "\n",
    "    \n",
    "if load_model:\n",
    "    load_checkpoint(torch.load('my_checkpoint.pth.tar'))    \n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    checkpoint={'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "    if epoch%2==0:  # Save every two epochs\n",
    "        save_checkpoint(checkpoint)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i, (data,labels) in enumerate(train_loader):\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device)\n",
    "        prediction=model(data)\n",
    "        loss_=loss(prediction,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%20==0:\n",
    "            print(f'{epoch}/{EPOCHS} | step: {i}/ {len(train_loader)} | loss: {loss_.item():.4f}')   \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
