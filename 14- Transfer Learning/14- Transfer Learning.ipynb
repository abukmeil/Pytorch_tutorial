{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transfer Learning</h1>\n",
    "\n",
    "<h3 style=\"color: yellow;\">This tutorial covers transfer learning and how it can be applied in PyTorch.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Transfer learning is an ML approach where a model developed for one task is reused as a starting point for another model designed for a different task.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">For instance, if we have a model built for the classification of n classes of vehicles, we can modify this model by adding a layer on top to construct a new model for a two-class classification (such as Car/Truck).</h3>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src='translearn.png', width =600>\n",
    "</div>\n",
    "\n",
    "<h3 style=\"color: yellow;\">In general, transfer learning is a popular method in ML. It facilitates the swift creation of new models, thereby conserving time and minimizing trainable parameters for more extensive tasks.</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Resnet-18 finetuning on Hymenoptera dataset</h1>\n",
    "<h3 style=\"color: yellow;\">This tutorial utilizes the Hymenoptera (insect) dataset, which is a small subset of ImageNet.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Our objective is to fine-tune Resnet-18 for binary classification. Specifically, we are adapting a deep learning model for the classification of ants and bees.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">The dataset consists of 244 training images for both ants and bees, and 153 validation images for each class.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Given its size, the dataset is quite limited for training a model from scratch.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">However, by employing transfer learning, we aim to achieve reasonable generalization.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPU\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet -18 have been trained on ImageNet dataset which has 1000 classes.\n",
    "# The following are dataset statistics for each channel\n",
    "mean=np.array([0.485,0.456,0.406])\n",
    "std=np.array([0.229,0.224,0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transforms\n",
    "data_tansforms={'train':transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean,std)]),\n",
    "                'val':transforms.Compose([transforms.Resize(256),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean,std)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir='/home/mohanad/learn/Pytorch/14- Transfer Learning/data/hymenoptera_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets, we use Imagefolder because the data is organized in folders locally\n",
    "image_datasets={x:datasets.ImageFolder(os.path.join(data_dir,x),data_tansforms[x]) for x in ['train','val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images shape is: torch.Size([4, 3, 224, 224])\n",
      "The labels shape is: torch.Size([4])\n",
      "\n",
      "dd\n"
     ]
    }
   ],
   "source": [
    "# Define the dataloaders\n",
    "dataloaders={x:DataLoader(image_datasets[x],batch_size=4,shuffle=True,num_workers=4) for x in ['train','val']}\n",
    "\n",
    "iter_=iter(dataloaders['train'])\n",
    "images, labels=next(iter_)\n",
    "print(f'The images shape is: {images.shape}')\n",
    "print(f'The labels shape is: {labels.shape}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set size is: 244\n",
      "The testing set size is: 153\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the datasets\n",
    "dataset_sizes={x:len(image_datasets[x]) for x in ['train','val']}\n",
    "print(f'The training set size is: {dataset_sizes[\"train\"]}')\n",
    "print(f'The testing set size is: {dataset_sizes[\"val\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path for teh first sample is: /home/mohanad/learn/Pytorch/14- Transfer Learning/data/hymenoptera_data/train/ants/0013035.jpg\n",
      "The classes names are: ['ants', 'bees']\n"
     ]
    }
   ],
   "source": [
    " # This is a dataset object contains the path for each sample\n",
    "train_dataset=image_datasets['train']\n",
    "print(f'The path for teh first sample is: {train_dataset.samples[0][0]}')\n",
    "print(f'The classes names are: {train_dataset.classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,loss,optimizer,scheduler,num_epochs=25):\n",
    "    start=time.time()\n",
    "    best_acc=0.0\n",
    "    # best model weights\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch:{epoch+1}/{num_epochs}')\n",
    "        print('-'*10)\n",
    "        # We have a training and validation phase at each epoch\n",
    "        for phase in ['train','val']:\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss=0.0\n",
    "            running_corrects=0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                images=images.to(device)\n",
    "                labels=labels.to(device)\n",
    "            # tracking history only if in training phase\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs=model(images)\n",
    "                    _,prediction=torch.max(outputs,1)\n",
    "                    loss_=loss(outputs,labels)\n",
    "            # Backward + optimize only if in training phase\n",
    "                    if phase=='train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss_.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    # Statistics\n",
    "                    running_loss+=loss_.item()*images.size(0)\n",
    "                    running_corrects+=torch.sum(prediction==labels.data)\n",
    "            \n",
    "            # scheduler\n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss=running_loss/dataset_sizes[phase]\n",
    "            epoch_acc=running_corrects.double()/dataset_sizes[phase]\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            # Saving the model with best accuracy on validation\n",
    "            \n",
    "            if phase=='val' and epoch_acc>best_acc:\n",
    "                best_acc=epoch_acc\n",
    "                best_model_wts=copy.deepcopy(model.state_dict())\n",
    "        print('')\n",
    "    time_elapsed=time.time()-start\n",
    "    print(f'Training complete in {time_elapsed//60:.0f}m :{time_elapsed%60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Let us use transfer learning\n",
    "# Setting the model\n",
    "model=models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 1, Layer Name: bn1.weight, Shape: torch.Size([64])\n",
      "Index: 2, Layer Name: bn1.bias, Shape: torch.Size([64])\n",
      "Index: 3, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 4, Layer Name: layer1.0.bn1.weight, Shape: torch.Size([64])\n",
      "Index: 5, Layer Name: layer1.0.bn1.bias, Shape: torch.Size([64])\n",
      "Index: 6, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 7, Layer Name: layer1.0.bn2.weight, Shape: torch.Size([64])\n",
      "Index: 8, Layer Name: layer1.0.bn2.bias, Shape: torch.Size([64])\n",
      "Index: 9, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 10, Layer Name: layer1.1.bn1.weight, Shape: torch.Size([64])\n",
      "Index: 11, Layer Name: layer1.1.bn1.bias, Shape: torch.Size([64])\n",
      "Index: 12, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 13, Layer Name: layer1.1.bn2.weight, Shape: torch.Size([64])\n",
      "Index: 14, Layer Name: layer1.1.bn2.bias, Shape: torch.Size([64])\n",
      "Index: 15, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 16, Layer Name: layer2.0.bn1.weight, Shape: torch.Size([128])\n",
      "Index: 17, Layer Name: layer2.0.bn1.bias, Shape: torch.Size([128])\n",
      "Index: 18, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 19, Layer Name: layer2.0.bn2.weight, Shape: torch.Size([128])\n",
      "Index: 20, Layer Name: layer2.0.bn2.bias, Shape: torch.Size([128])\n",
      "Index: 21, Layer Name: layer2.0.downsample.0.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Index: 22, Layer Name: layer2.0.downsample.1.weight, Shape: torch.Size([128])\n",
      "Index: 23, Layer Name: layer2.0.downsample.1.bias, Shape: torch.Size([128])\n",
      "Index: 24, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 25, Layer Name: layer2.1.bn1.weight, Shape: torch.Size([128])\n",
      "Index: 26, Layer Name: layer2.1.bn1.bias, Shape: torch.Size([128])\n",
      "Index: 27, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 28, Layer Name: layer2.1.bn2.weight, Shape: torch.Size([128])\n",
      "Index: 29, Layer Name: layer2.1.bn2.bias, Shape: torch.Size([128])\n",
      "Index: 30, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 31, Layer Name: layer3.0.bn1.weight, Shape: torch.Size([256])\n",
      "Index: 32, Layer Name: layer3.0.bn1.bias, Shape: torch.Size([256])\n",
      "Index: 33, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 34, Layer Name: layer3.0.bn2.weight, Shape: torch.Size([256])\n",
      "Index: 35, Layer Name: layer3.0.bn2.bias, Shape: torch.Size([256])\n",
      "Index: 36, Layer Name: layer3.0.downsample.0.weight, Shape: torch.Size([256, 128, 1, 1])\n",
      "Index: 37, Layer Name: layer3.0.downsample.1.weight, Shape: torch.Size([256])\n",
      "Index: 38, Layer Name: layer3.0.downsample.1.bias, Shape: torch.Size([256])\n",
      "Index: 39, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 40, Layer Name: layer3.1.bn1.weight, Shape: torch.Size([256])\n",
      "Index: 41, Layer Name: layer3.1.bn1.bias, Shape: torch.Size([256])\n",
      "Index: 42, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 43, Layer Name: layer3.1.bn2.weight, Shape: torch.Size([256])\n",
      "Index: 44, Layer Name: layer3.1.bn2.bias, Shape: torch.Size([256])\n",
      "Index: 45, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 46, Layer Name: layer4.0.bn1.weight, Shape: torch.Size([512])\n",
      "Index: 47, Layer Name: layer4.0.bn1.bias, Shape: torch.Size([512])\n",
      "Index: 48, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 49, Layer Name: layer4.0.bn2.weight, Shape: torch.Size([512])\n",
      "Index: 50, Layer Name: layer4.0.bn2.bias, Shape: torch.Size([512])\n",
      "Index: 51, Layer Name: layer4.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1])\n",
      "Index: 52, Layer Name: layer4.0.downsample.1.weight, Shape: torch.Size([512])\n",
      "Index: 53, Layer Name: layer4.0.downsample.1.bias, Shape: torch.Size([512])\n",
      "Index: 54, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 55, Layer Name: layer4.1.bn1.weight, Shape: torch.Size([512])\n",
      "Index: 56, Layer Name: layer4.1.bn1.bias, Shape: torch.Size([512])\n",
      "Index: 57, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 58, Layer Name: layer4.1.bn2.weight, Shape: torch.Size([512])\n",
      "Index: 59, Layer Name: layer4.1.bn2.bias, Shape: torch.Size([512])\n",
      "Index: 60, Layer Name: fc.weight, Shape: torch.Size([1000, 512])\n",
      "Index: 61, Layer Name: fc.bias, Shape: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Print all model parameters\n",
    "\n",
    "for idx,(name,param) in enumerate(model.named_parameters()):\n",
    "    print(f\"Index: {idx}, Layer Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "layer1.0.conv1\n",
      "layer1.0.bn1\n",
      "layer1.0.conv2\n",
      "layer1.0.bn2\n",
      "layer1.1.conv1\n",
      "layer1.1.bn1\n",
      "layer1.1.conv2\n",
      "layer1.1.bn2\n",
      "layer2.0.conv1\n",
      "layer2.0.bn1\n",
      "layer2.0.conv2\n",
      "layer2.0.bn2\n",
      "layer2.0.downsample.0\n",
      "layer2.0.downsample.1\n",
      "layer2.1.conv1\n",
      "layer2.1.bn1\n",
      "layer2.1.conv2\n",
      "layer2.1.bn2\n",
      "layer3.0.conv1\n",
      "layer3.0.bn1\n",
      "layer3.0.conv2\n",
      "layer3.0.bn2\n",
      "layer3.0.downsample.0\n",
      "layer3.0.downsample.1\n",
      "layer3.1.conv1\n",
      "layer3.1.bn1\n",
      "layer3.1.conv2\n",
      "layer3.1.bn2\n",
      "layer4.0.conv1\n",
      "layer4.0.bn1\n",
      "layer4.0.conv2\n",
      "layer4.0.bn2\n",
      "layer4.0.downsample.0\n",
      "layer4.0.downsample.1\n",
      "layer4.1.conv1\n",
      "layer4.1.bn1\n",
      "layer4.1.conv2\n",
      "layer4.1.bn2\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the named model paarameters to print the layers that have weights\n",
    "for name,module in model.named_modules():\n",
    "    if hasattr(module,'weight') and hasattr(module.weight, 'shape'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 3, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 6, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 9, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 12, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 15, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 18, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 24, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 27, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 30, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 33, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 39, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 42, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 45, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 48, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 54, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 57, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Print only the layers that perform convolution operations\n",
    "for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "    if 'conv' in name:\n",
    "        print(f\"Index: {idx}, Layer Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of input features is: 512\n"
     ]
    }
   ],
   "source": [
    "# Back to  continue with transfere lerning\n",
    "# get the number of input feature from the last layer\n",
    "num_features=model.fc.in_features\n",
    "print(f'The number of input features is: {num_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new layer with 2 output features in the top of the fc layer\n",
    "model.fc=nn.Linear(num_features,2)  # the will ovverride the old FC layer and create a new one\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 106.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=images[0].shape)  # images[0] is the first image in the batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7676 Acc: 0.6230\n",
      "val Loss: 0.2142 Acc: 0.9020\n",
      "\n",
      "Epoch:2/100\n",
      "----------\n",
      "train Loss: 0.5112 Acc: 0.7951\n",
      "val Loss: 0.3833 Acc: 0.8497\n",
      "\n",
      "Epoch:3/100\n",
      "----------\n",
      "train Loss: 0.4796 Acc: 0.7828\n",
      "val Loss: 0.3724 Acc: 0.8627\n",
      "\n",
      "Epoch:4/100\n",
      "----------\n",
      "train Loss: 0.4580 Acc: 0.8402\n",
      "val Loss: 0.4522 Acc: 0.8105\n",
      "\n",
      "Epoch:5/100\n",
      "----------\n",
      "train Loss: 0.5138 Acc: 0.7951\n",
      "val Loss: 0.5013 Acc: 0.8105\n",
      "\n",
      "Epoch:6/100\n",
      "----------\n",
      "train Loss: 0.4753 Acc: 0.8320\n",
      "val Loss: 0.2687 Acc: 0.9020\n",
      "\n",
      "Epoch:7/100\n",
      "----------\n",
      "train Loss: 0.5137 Acc: 0.8074\n",
      "val Loss: 0.5365 Acc: 0.8301\n",
      "\n",
      "Epoch:8/100\n",
      "----------\n",
      "train Loss: 0.5418 Acc: 0.7992\n",
      "val Loss: 0.2300 Acc: 0.9020\n",
      "\n",
      "Epoch:9/100\n",
      "----------\n",
      "train Loss: 0.3707 Acc: 0.8361\n",
      "val Loss: 0.7169 Acc: 0.7712\n",
      "\n",
      "Epoch:10/100\n",
      "----------\n",
      "train Loss: 0.4914 Acc: 0.8320\n",
      "val Loss: 0.2983 Acc: 0.8758\n",
      "\n",
      "Epoch:11/100\n",
      "----------\n",
      "train Loss: 0.3601 Acc: 0.8320\n",
      "val Loss: 0.2763 Acc: 0.9085\n",
      "\n",
      "Epoch:12/100\n",
      "----------\n",
      "train Loss: 0.3416 Acc: 0.8361\n",
      "val Loss: 0.2701 Acc: 0.8954\n",
      "\n",
      "Epoch:13/100\n",
      "----------\n",
      "train Loss: 0.3508 Acc: 0.8279\n",
      "val Loss: 0.2707 Acc: 0.8889\n",
      "\n",
      "Epoch:14/100\n",
      "----------\n",
      "train Loss: 0.3183 Acc: 0.8730\n",
      "val Loss: 0.2580 Acc: 0.9085\n",
      "\n",
      "Epoch:15/100\n",
      "----------\n",
      "train Loss: 0.3065 Acc: 0.8484\n",
      "val Loss: 0.2804 Acc: 0.8954\n",
      "\n",
      "Epoch:16/100\n",
      "----------\n",
      "train Loss: 0.3190 Acc: 0.8566\n",
      "val Loss: 0.2824 Acc: 0.8954\n",
      "\n",
      "Epoch:17/100\n",
      "----------\n",
      "train Loss: 0.2185 Acc: 0.8975\n",
      "val Loss: 0.2532 Acc: 0.9216\n",
      "\n",
      "Epoch:18/100\n",
      "----------\n",
      "train Loss: 0.2576 Acc: 0.8730\n",
      "val Loss: 0.2352 Acc: 0.9216\n",
      "\n",
      "Epoch:19/100\n",
      "----------\n",
      "train Loss: 0.3493 Acc: 0.8402\n",
      "val Loss: 0.2664 Acc: 0.9020\n",
      "\n",
      "Epoch:20/100\n",
      "----------\n",
      "train Loss: 0.2454 Acc: 0.8934\n",
      "val Loss: 0.2338 Acc: 0.9085\n",
      "\n",
      "Epoch:21/100\n",
      "----------\n",
      "train Loss: 0.2248 Acc: 0.9016\n",
      "val Loss: 0.2664 Acc: 0.9150\n",
      "\n",
      "Epoch:22/100\n",
      "----------\n",
      "train Loss: 0.2794 Acc: 0.8811\n",
      "val Loss: 0.2633 Acc: 0.9085\n",
      "\n",
      "Epoch:23/100\n",
      "----------\n",
      "train Loss: 0.2771 Acc: 0.8566\n",
      "val Loss: 0.2455 Acc: 0.9085\n",
      "\n",
      "Epoch:24/100\n",
      "----------\n",
      "train Loss: 0.2076 Acc: 0.9139\n",
      "val Loss: 0.2469 Acc: 0.9150\n",
      "\n",
      "Epoch:25/100\n",
      "----------\n",
      "train Loss: 0.2504 Acc: 0.8770\n",
      "val Loss: 0.2447 Acc: 0.9150\n",
      "\n",
      "Epoch:26/100\n",
      "----------\n",
      "train Loss: 0.1974 Acc: 0.9221\n",
      "val Loss: 0.2532 Acc: 0.9085\n",
      "\n",
      "Epoch:27/100\n",
      "----------\n",
      "train Loss: 0.2799 Acc: 0.8852\n",
      "val Loss: 0.2311 Acc: 0.9150\n",
      "\n",
      "Epoch:28/100\n",
      "----------\n",
      "train Loss: 0.2162 Acc: 0.8975\n",
      "val Loss: 0.2603 Acc: 0.9150\n",
      "\n",
      "Epoch:29/100\n",
      "----------\n",
      "train Loss: 0.2387 Acc: 0.9057\n",
      "val Loss: 0.2351 Acc: 0.9216\n",
      "\n",
      "Epoch:30/100\n",
      "----------\n",
      "train Loss: 0.2945 Acc: 0.8689\n",
      "val Loss: 0.2470 Acc: 0.9085\n",
      "\n",
      "Epoch:31/100\n",
      "----------\n",
      "train Loss: 0.2464 Acc: 0.9016\n",
      "val Loss: 0.2440 Acc: 0.9085\n",
      "\n",
      "Epoch:32/100\n",
      "----------\n",
      "train Loss: 0.2680 Acc: 0.8852\n",
      "val Loss: 0.2386 Acc: 0.9150\n",
      "\n",
      "Epoch:33/100\n",
      "----------\n",
      "train Loss: 0.2159 Acc: 0.9221\n",
      "val Loss: 0.2443 Acc: 0.9085\n",
      "\n",
      "Epoch:34/100\n",
      "----------\n",
      "train Loss: 0.2677 Acc: 0.8730\n",
      "val Loss: 0.2530 Acc: 0.9150\n",
      "\n",
      "Epoch:35/100\n",
      "----------\n",
      "train Loss: 0.2220 Acc: 0.9180\n",
      "val Loss: 0.2495 Acc: 0.9150\n",
      "\n",
      "Epoch:36/100\n",
      "----------\n",
      "train Loss: 0.2706 Acc: 0.8770\n",
      "val Loss: 0.2458 Acc: 0.9085\n",
      "\n",
      "Epoch:37/100\n",
      "----------\n",
      "train Loss: 0.2769 Acc: 0.8811\n",
      "val Loss: 0.2436 Acc: 0.9150\n",
      "\n",
      "Epoch:38/100\n",
      "----------\n",
      "train Loss: 0.2414 Acc: 0.8852\n",
      "val Loss: 0.2549 Acc: 0.9085\n",
      "\n",
      "Epoch:39/100\n",
      "----------\n",
      "train Loss: 0.2465 Acc: 0.8975\n",
      "val Loss: 0.2338 Acc: 0.9281\n",
      "\n",
      "Epoch:40/100\n",
      "----------\n",
      "train Loss: 0.3731 Acc: 0.8607\n",
      "val Loss: 0.2677 Acc: 0.8954\n",
      "\n",
      "Epoch:41/100\n",
      "----------\n",
      "train Loss: 0.2865 Acc: 0.8852\n",
      "val Loss: 0.2592 Acc: 0.9150\n",
      "\n",
      "Epoch:42/100\n",
      "----------\n",
      "train Loss: 0.2564 Acc: 0.9016\n",
      "val Loss: 0.2354 Acc: 0.9150\n",
      "\n",
      "Epoch:43/100\n",
      "----------\n",
      "train Loss: 0.2563 Acc: 0.8893\n",
      "val Loss: 0.2293 Acc: 0.9216\n",
      "\n",
      "Epoch:44/100\n",
      "----------\n",
      "train Loss: 0.2299 Acc: 0.9057\n",
      "val Loss: 0.2434 Acc: 0.9085\n",
      "\n",
      "Epoch:45/100\n",
      "----------\n",
      "train Loss: 0.2041 Acc: 0.9221\n",
      "val Loss: 0.2399 Acc: 0.9085\n",
      "\n",
      "Epoch:46/100\n",
      "----------\n",
      "train Loss: 0.3047 Acc: 0.8648\n",
      "val Loss: 0.2637 Acc: 0.8954\n",
      "\n",
      "Epoch:47/100\n",
      "----------\n",
      "train Loss: 0.2639 Acc: 0.8730\n",
      "val Loss: 0.2718 Acc: 0.9020\n",
      "\n",
      "Epoch:48/100\n",
      "----------\n",
      "train Loss: 0.2439 Acc: 0.8893\n",
      "val Loss: 0.2425 Acc: 0.9216\n",
      "\n",
      "Epoch:49/100\n",
      "----------\n",
      "train Loss: 0.2643 Acc: 0.8730\n",
      "val Loss: 0.2383 Acc: 0.9216\n",
      "\n",
      "Epoch:50/100\n",
      "----------\n",
      "train Loss: 0.2341 Acc: 0.9098\n",
      "val Loss: 0.2363 Acc: 0.9085\n",
      "\n",
      "Epoch:51/100\n",
      "----------\n",
      "train Loss: 0.2160 Acc: 0.8934\n",
      "val Loss: 0.2490 Acc: 0.9085\n",
      "\n",
      "Epoch:52/100\n",
      "----------\n",
      "train Loss: 0.2883 Acc: 0.8811\n",
      "val Loss: 0.2536 Acc: 0.9150\n",
      "\n",
      "Epoch:53/100\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9221\n",
      "val Loss: 0.2580 Acc: 0.9020\n",
      "\n",
      "Epoch:54/100\n",
      "----------\n",
      "train Loss: 0.2345 Acc: 0.8975\n",
      "val Loss: 0.2689 Acc: 0.9085\n",
      "\n",
      "Epoch:55/100\n",
      "----------\n",
      "train Loss: 0.2614 Acc: 0.8852\n",
      "val Loss: 0.2341 Acc: 0.9085\n",
      "\n",
      "Epoch:56/100\n",
      "----------\n",
      "train Loss: 0.2848 Acc: 0.8852\n",
      "val Loss: 0.2524 Acc: 0.9150\n",
      "\n",
      "Epoch:57/100\n",
      "----------\n",
      "train Loss: 0.2596 Acc: 0.8852\n",
      "val Loss: 0.2400 Acc: 0.9150\n",
      "\n",
      "Epoch:58/100\n",
      "----------\n",
      "train Loss: 0.3028 Acc: 0.8689\n",
      "val Loss: 0.2434 Acc: 0.9150\n",
      "\n",
      "Epoch:59/100\n",
      "----------\n",
      "train Loss: 0.2532 Acc: 0.8893\n",
      "val Loss: 0.2422 Acc: 0.9216\n",
      "\n",
      "Epoch:60/100\n",
      "----------\n",
      "train Loss: 0.2803 Acc: 0.8689\n",
      "val Loss: 0.2880 Acc: 0.8954\n",
      "\n",
      "Epoch:61/100\n",
      "----------\n",
      "train Loss: 0.2322 Acc: 0.8934\n",
      "val Loss: 0.2635 Acc: 0.8954\n",
      "\n",
      "Epoch:62/100\n",
      "----------\n",
      "train Loss: 0.2774 Acc: 0.8811\n",
      "val Loss: 0.2473 Acc: 0.9216\n",
      "\n",
      "Epoch:63/100\n",
      "----------\n",
      "train Loss: 0.2450 Acc: 0.8934\n",
      "val Loss: 0.2406 Acc: 0.9150\n",
      "\n",
      "Epoch:64/100\n",
      "----------\n",
      "train Loss: 0.2383 Acc: 0.8934\n",
      "val Loss: 0.2410 Acc: 0.9085\n",
      "\n",
      "Epoch:65/100\n",
      "----------\n",
      "train Loss: 0.2136 Acc: 0.9180\n",
      "val Loss: 0.2380 Acc: 0.9216\n",
      "\n",
      "Epoch:66/100\n",
      "----------\n",
      "train Loss: 0.2427 Acc: 0.9057\n",
      "val Loss: 0.2706 Acc: 0.9020\n",
      "\n",
      "Epoch:67/100\n",
      "----------\n",
      "train Loss: 0.3287 Acc: 0.8525\n",
      "val Loss: 0.2403 Acc: 0.9150\n",
      "\n",
      "Epoch:68/100\n",
      "----------\n",
      "train Loss: 0.2498 Acc: 0.8689\n",
      "val Loss: 0.2356 Acc: 0.9150\n",
      "\n",
      "Epoch:69/100\n",
      "----------\n",
      "train Loss: 0.2533 Acc: 0.8893\n",
      "val Loss: 0.2512 Acc: 0.9085\n",
      "\n",
      "Epoch:70/100\n",
      "----------\n",
      "train Loss: 0.3110 Acc: 0.8648\n",
      "val Loss: 0.2514 Acc: 0.9150\n",
      "\n",
      "Epoch:71/100\n",
      "----------\n",
      "train Loss: 0.2016 Acc: 0.9262\n",
      "val Loss: 0.2303 Acc: 0.9216\n",
      "\n",
      "Epoch:72/100\n",
      "----------\n",
      "train Loss: 0.2411 Acc: 0.8934\n",
      "val Loss: 0.2354 Acc: 0.9150\n",
      "\n",
      "Epoch:73/100\n",
      "----------\n",
      "train Loss: 0.2843 Acc: 0.8811\n",
      "val Loss: 0.2317 Acc: 0.9216\n",
      "\n",
      "Epoch:74/100\n",
      "----------\n",
      "train Loss: 0.1993 Acc: 0.9057\n",
      "val Loss: 0.2342 Acc: 0.9150\n",
      "\n",
      "Epoch:75/100\n",
      "----------\n",
      "train Loss: 0.2906 Acc: 0.8893\n",
      "val Loss: 0.2782 Acc: 0.9020\n",
      "\n",
      "Epoch:76/100\n",
      "----------\n",
      "train Loss: 0.2389 Acc: 0.9139\n",
      "val Loss: 0.2499 Acc: 0.9085\n",
      "\n",
      "Epoch:77/100\n",
      "----------\n",
      "train Loss: 0.2512 Acc: 0.9016\n",
      "val Loss: 0.2424 Acc: 0.9150\n",
      "\n",
      "Epoch:78/100\n",
      "----------\n",
      "train Loss: 0.2298 Acc: 0.8893\n",
      "val Loss: 0.2375 Acc: 0.9150\n",
      "\n",
      "Epoch:79/100\n",
      "----------\n",
      "train Loss: 0.2693 Acc: 0.8770\n",
      "val Loss: 0.2457 Acc: 0.9216\n",
      "\n",
      "Epoch:80/100\n",
      "----------\n",
      "train Loss: 0.2713 Acc: 0.8893\n",
      "val Loss: 0.2552 Acc: 0.9150\n",
      "\n",
      "Epoch:81/100\n",
      "----------\n",
      "train Loss: 0.3171 Acc: 0.8730\n",
      "val Loss: 0.2666 Acc: 0.8954\n",
      "\n",
      "Epoch:82/100\n",
      "----------\n",
      "train Loss: 0.1787 Acc: 0.9508\n",
      "val Loss: 0.2447 Acc: 0.9020\n",
      "\n",
      "Epoch:83/100\n",
      "----------\n",
      "train Loss: 0.3262 Acc: 0.8648\n",
      "val Loss: 0.2525 Acc: 0.9150\n",
      "\n",
      "Epoch:84/100\n",
      "----------\n",
      "train Loss: 0.1670 Acc: 0.9385\n",
      "val Loss: 0.2480 Acc: 0.9085\n",
      "\n",
      "Epoch:85/100\n",
      "----------\n",
      "train Loss: 0.2034 Acc: 0.9057\n",
      "val Loss: 0.2341 Acc: 0.9085\n",
      "\n",
      "Epoch:86/100\n",
      "----------\n",
      "train Loss: 0.1713 Acc: 0.9385\n",
      "val Loss: 0.2606 Acc: 0.8954\n",
      "\n",
      "Epoch:87/100\n",
      "----------\n",
      "train Loss: 0.1941 Acc: 0.9385\n",
      "val Loss: 0.2287 Acc: 0.9150\n",
      "\n",
      "Epoch:88/100\n",
      "----------\n",
      "train Loss: 0.2602 Acc: 0.8934\n",
      "val Loss: 0.2326 Acc: 0.9085\n",
      "\n",
      "Epoch:89/100\n",
      "----------\n",
      "train Loss: 0.2271 Acc: 0.9057\n",
      "val Loss: 0.2510 Acc: 0.9150\n",
      "\n",
      "Epoch:90/100\n",
      "----------\n",
      "train Loss: 0.2530 Acc: 0.8893\n",
      "val Loss: 0.2371 Acc: 0.9150\n",
      "\n",
      "Epoch:91/100\n",
      "----------\n",
      "train Loss: 0.3515 Acc: 0.8525\n",
      "val Loss: 0.2398 Acc: 0.9216\n",
      "\n",
      "Epoch:92/100\n",
      "----------\n",
      "train Loss: 0.2747 Acc: 0.8689\n",
      "val Loss: 0.2445 Acc: 0.9085\n",
      "\n",
      "Epoch:93/100\n",
      "----------\n",
      "train Loss: 0.2686 Acc: 0.8648\n",
      "val Loss: 0.2464 Acc: 0.9216\n",
      "\n",
      "Epoch:94/100\n",
      "----------\n",
      "train Loss: 0.2477 Acc: 0.8975\n",
      "val Loss: 0.2484 Acc: 0.9020\n",
      "\n",
      "Epoch:95/100\n",
      "----------\n",
      "train Loss: 0.3882 Acc: 0.8320\n",
      "val Loss: 0.2861 Acc: 0.8954\n",
      "\n",
      "Epoch:96/100\n",
      "----------\n",
      "train Loss: 0.2213 Acc: 0.9057\n",
      "val Loss: 0.2394 Acc: 0.9085\n",
      "\n",
      "Epoch:97/100\n",
      "----------\n",
      "train Loss: 0.3065 Acc: 0.8566\n",
      "val Loss: 0.2410 Acc: 0.9150\n",
      "\n",
      "Epoch:98/100\n",
      "----------\n",
      "train Loss: 0.3306 Acc: 0.8689\n",
      "val Loss: 0.2521 Acc: 0.9150\n",
      "\n",
      "Epoch:99/100\n",
      "----------\n",
      "train Loss: 0.2453 Acc: 0.8934\n",
      "val Loss: 0.2586 Acc: 0.8954\n",
      "\n",
      "Epoch:100/100\n",
      "----------\n",
      "train Loss: 0.3247 Acc: 0.8607\n",
      "val Loss: 0.2361 Acc: 0.9216\n",
      "\n",
      "Training complete in 2m :22s\n",
      "Best val Acc: 0.9281\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "# Define the loss function\n",
    "loss=nn.CrossEntropyLoss()\n",
    "# Define th eOptimzer\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.0001,momentum=0.9)\n",
    "# Define the scheduler for LR Update\n",
    "step_lr_scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)\n",
    "# Calling the training function\n",
    "model=train_model(model,loss,optimizer,step_lr_scheduler,num_epochs=EPOCHS)\n",
    "\n",
    "# The method above is called fine-tuning of all model parameters, where we adjust the entire model's parameters using a lower learning rate (LR).\n",
    "\n",
    "# Another option is to freeze the parameters of the entire model and fine-tune only the last layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> The above implementation fine-tunes the model by retraining all the model weights with a small LR. </h2>\n",
    "\n",
    "<h2>In what follows, we present an alternative approach: freezing all model weights except for the last layer, which we then fine-tune and retrain. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model=models.resnet18(pretrained=True) # The optimized weight trained in ImageNet\n",
    "model.to(device)\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=images[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers in the network as a second option of the model pretraining\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can keep unfreeze the last two  layers\n",
    "# The parameters of the layers are typically organized as: (weight, bias), hence we'll need to \"unfreeze\" 4 parameters for 2 layers\n",
    "#parameters = list(model.parameters())\n",
    "#parameters[-4].requires_grad = True  # Unfreeze weights of the second last layer\n",
    "#parameters[-3].requires_grad = True  # Unfreeze bias of the second last layer\n",
    "#parameters[-2].requires_grad = True  # Unfreeze weights of the last layer\n",
    "#parameters[-1].requires_grad = True  # Unfreeze bias of the last layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last convolutional layer of the last convolutional block\n",
    "#model.layer4[1].conv2.weight.requires_grad = True # Note: Not all models have the same architecture or have a bias layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last convolutional layer of each convolutional block\n",
    "model.layer1[1].conv2.weight.requires_grad = True\n",
    "model.layer2[1].conv2.weight.requires_grad = True\n",
    "model.layer3[1].conv2.weight.requires_grad = True\n",
    "model.layer4[1].conv2.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 1, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 2, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 3, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 4, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 5, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 6, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 7, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 8, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 9, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 10, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 11, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 12, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 13, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 14, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 15, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 16, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 17, Layer Name: fc.weight, Shape: torch.Size([1000, 512])\n",
      "Index: 18, Layer Name: fc.bias, Shape: torch.Size([1000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print only the layers that perform convolution and fc operations\n",
    "index = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if \"conv\" in name or 'fc' in name:\n",
    "        print(f\"Index: {index}, Layer Name: {name}, Shape: {param.shape}\")\n",
    "        index += 1\n",
    "print('')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of input features is: 512\n",
      "Epoch:1/100\n",
      "----------\n",
      "train Loss: 0.6250 Acc: 0.6230\n",
      "val Loss: 0.5135 Acc: 0.7778\n",
      "\n",
      "Epoch:2/100\n",
      "----------\n",
      "train Loss: 0.5738 Acc: 0.7254\n",
      "val Loss: 0.4151 Acc: 0.8562\n",
      "\n",
      "Epoch:3/100\n",
      "----------\n",
      "train Loss: 0.4918 Acc: 0.7951\n",
      "val Loss: 0.3711 Acc: 0.8693\n",
      "\n",
      "Epoch:4/100\n",
      "----------\n",
      "train Loss: 0.4687 Acc: 0.8197\n",
      "val Loss: 0.3225 Acc: 0.8954\n",
      "\n",
      "Epoch:5/100\n",
      "----------\n",
      "train Loss: 0.4221 Acc: 0.8279\n",
      "val Loss: 0.2918 Acc: 0.9150\n",
      "\n",
      "Epoch:6/100\n",
      "----------\n",
      "train Loss: 0.4131 Acc: 0.8074\n",
      "val Loss: 0.2707 Acc: 0.9150\n",
      "\n",
      "Epoch:7/100\n",
      "----------\n",
      "train Loss: 0.4281 Acc: 0.7910\n",
      "val Loss: 0.2629 Acc: 0.9281\n",
      "\n",
      "Epoch:8/100\n",
      "----------\n",
      "train Loss: 0.4111 Acc: 0.8197\n",
      "val Loss: 0.2499 Acc: 0.9085\n",
      "\n",
      "Epoch:9/100\n",
      "----------\n",
      "train Loss: 0.4180 Acc: 0.7910\n",
      "val Loss: 0.2374 Acc: 0.9216\n",
      "\n",
      "Epoch:10/100\n",
      "----------\n",
      "train Loss: 0.3496 Acc: 0.8484\n",
      "val Loss: 0.2409 Acc: 0.9281\n",
      "\n",
      "Epoch:11/100\n",
      "----------\n",
      "train Loss: 0.3670 Acc: 0.8279\n",
      "val Loss: 0.2352 Acc: 0.9281\n",
      "\n",
      "Epoch:12/100\n",
      "----------\n",
      "train Loss: 0.3681 Acc: 0.8484\n",
      "val Loss: 0.2342 Acc: 0.9346\n",
      "\n",
      "Epoch:13/100\n",
      "----------\n",
      "train Loss: 0.3879 Acc: 0.8156\n",
      "val Loss: 0.2216 Acc: 0.9216\n",
      "\n",
      "Epoch:14/100\n",
      "----------\n",
      "train Loss: 0.3790 Acc: 0.8402\n",
      "val Loss: 0.2247 Acc: 0.9412\n",
      "\n",
      "Epoch:15/100\n",
      "----------\n",
      "train Loss: 0.4319 Acc: 0.8115\n",
      "val Loss: 0.2338 Acc: 0.9346\n",
      "\n",
      "Epoch:16/100\n",
      "----------\n",
      "train Loss: 0.3593 Acc: 0.8525\n",
      "val Loss: 0.2296 Acc: 0.9281\n",
      "\n",
      "Epoch:17/100\n",
      "----------\n",
      "train Loss: 0.3613 Acc: 0.8361\n",
      "val Loss: 0.2302 Acc: 0.9346\n",
      "\n",
      "Epoch:18/100\n",
      "----------\n",
      "train Loss: 0.3416 Acc: 0.8484\n",
      "val Loss: 0.2298 Acc: 0.9281\n",
      "\n",
      "Epoch:19/100\n",
      "----------\n",
      "train Loss: 0.4178 Acc: 0.7869\n",
      "val Loss: 0.2266 Acc: 0.9216\n",
      "\n",
      "Epoch:20/100\n",
      "----------\n",
      "train Loss: 0.3816 Acc: 0.8115\n",
      "val Loss: 0.2270 Acc: 0.9346\n",
      "\n",
      "Epoch:21/100\n",
      "----------\n",
      "train Loss: 0.3543 Acc: 0.8402\n",
      "val Loss: 0.2274 Acc: 0.9346\n",
      "\n",
      "Epoch:22/100\n",
      "----------\n",
      "train Loss: 0.3529 Acc: 0.8361\n",
      "val Loss: 0.2271 Acc: 0.9346\n",
      "\n",
      "Epoch:23/100\n",
      "----------\n",
      "train Loss: 0.3439 Acc: 0.8607\n",
      "val Loss: 0.2317 Acc: 0.9216\n",
      "\n",
      "Epoch:24/100\n",
      "----------\n",
      "train Loss: 0.3316 Acc: 0.8811\n",
      "val Loss: 0.2396 Acc: 0.9281\n",
      "\n",
      "Epoch:25/100\n",
      "----------\n",
      "train Loss: 0.3648 Acc: 0.8402\n",
      "val Loss: 0.2275 Acc: 0.9150\n",
      "\n",
      "Epoch:26/100\n",
      "----------\n",
      "train Loss: 0.3411 Acc: 0.8443\n",
      "val Loss: 0.2281 Acc: 0.9150\n",
      "\n",
      "Epoch:27/100\n",
      "----------\n",
      "train Loss: 0.4324 Acc: 0.7910\n",
      "val Loss: 0.2209 Acc: 0.9281\n",
      "\n",
      "Epoch:28/100\n",
      "----------\n",
      "train Loss: 0.3174 Acc: 0.8402\n",
      "val Loss: 0.2272 Acc: 0.9150\n",
      "\n",
      "Epoch:29/100\n",
      "----------\n",
      "train Loss: 0.3852 Acc: 0.8525\n",
      "val Loss: 0.2262 Acc: 0.9281\n",
      "\n",
      "Epoch:30/100\n",
      "----------\n",
      "train Loss: 0.3221 Acc: 0.8689\n",
      "val Loss: 0.2232 Acc: 0.9346\n",
      "\n",
      "Epoch:31/100\n",
      "----------\n",
      "train Loss: 0.3522 Acc: 0.8525\n",
      "val Loss: 0.2374 Acc: 0.9346\n",
      "\n",
      "Epoch:32/100\n",
      "----------\n",
      "train Loss: 0.3873 Acc: 0.8484\n",
      "val Loss: 0.2135 Acc: 0.9216\n",
      "\n",
      "Epoch:33/100\n",
      "----------\n",
      "train Loss: 0.3744 Acc: 0.8279\n",
      "val Loss: 0.2284 Acc: 0.9216\n",
      "\n",
      "Epoch:34/100\n",
      "----------\n",
      "train Loss: 0.3779 Acc: 0.8197\n",
      "val Loss: 0.2291 Acc: 0.9216\n",
      "\n",
      "Epoch:35/100\n",
      "----------\n",
      "train Loss: 0.3530 Acc: 0.8443\n",
      "val Loss: 0.2275 Acc: 0.9346\n",
      "\n",
      "Epoch:36/100\n",
      "----------\n",
      "train Loss: 0.3796 Acc: 0.8361\n",
      "val Loss: 0.2579 Acc: 0.9281\n",
      "\n",
      "Epoch:37/100\n",
      "----------\n",
      "train Loss: 0.3834 Acc: 0.8197\n",
      "val Loss: 0.2255 Acc: 0.9281\n",
      "\n",
      "Epoch:38/100\n",
      "----------\n",
      "train Loss: 0.3277 Acc: 0.8525\n",
      "val Loss: 0.2285 Acc: 0.9216\n",
      "\n",
      "Epoch:39/100\n",
      "----------\n",
      "train Loss: 0.3939 Acc: 0.8074\n",
      "val Loss: 0.2357 Acc: 0.9346\n",
      "\n",
      "Epoch:40/100\n",
      "----------\n",
      "train Loss: 0.3708 Acc: 0.8484\n",
      "val Loss: 0.2268 Acc: 0.9281\n",
      "\n",
      "Epoch:41/100\n",
      "----------\n",
      "train Loss: 0.3971 Acc: 0.8320\n",
      "val Loss: 0.2308 Acc: 0.9346\n",
      "\n",
      "Epoch:42/100\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8279\n",
      "val Loss: 0.2347 Acc: 0.9281\n",
      "\n",
      "Epoch:43/100\n",
      "----------\n",
      "train Loss: 0.3396 Acc: 0.8443\n",
      "val Loss: 0.2330 Acc: 0.9281\n",
      "\n",
      "Epoch:44/100\n",
      "----------\n",
      "train Loss: 0.3778 Acc: 0.8279\n",
      "val Loss: 0.2311 Acc: 0.9216\n",
      "\n",
      "Epoch:45/100\n",
      "----------\n",
      "train Loss: 0.3743 Acc: 0.8279\n",
      "val Loss: 0.2282 Acc: 0.9346\n",
      "\n",
      "Epoch:46/100\n",
      "----------\n",
      "train Loss: 0.3643 Acc: 0.8402\n",
      "val Loss: 0.2358 Acc: 0.9281\n",
      "\n",
      "Epoch:47/100\n",
      "----------\n",
      "train Loss: 0.3649 Acc: 0.8443\n",
      "val Loss: 0.2346 Acc: 0.9150\n",
      "\n",
      "Epoch:48/100\n",
      "----------\n",
      "train Loss: 0.3547 Acc: 0.8484\n",
      "val Loss: 0.2272 Acc: 0.9216\n",
      "\n",
      "Epoch:49/100\n",
      "----------\n",
      "train Loss: 0.3090 Acc: 0.8689\n",
      "val Loss: 0.2171 Acc: 0.9412\n",
      "\n",
      "Epoch:50/100\n",
      "----------\n",
      "train Loss: 0.3356 Acc: 0.8730\n",
      "val Loss: 0.2236 Acc: 0.9216\n",
      "\n",
      "Epoch:51/100\n",
      "----------\n",
      "train Loss: 0.3461 Acc: 0.8648\n",
      "val Loss: 0.2220 Acc: 0.9281\n",
      "\n",
      "Epoch:52/100\n",
      "----------\n",
      "train Loss: 0.3686 Acc: 0.8197\n",
      "val Loss: 0.2240 Acc: 0.9281\n",
      "\n",
      "Epoch:53/100\n",
      "----------\n",
      "train Loss: 0.4221 Acc: 0.7951\n",
      "val Loss: 0.2267 Acc: 0.9281\n",
      "\n",
      "Epoch:54/100\n",
      "----------\n",
      "train Loss: 0.3861 Acc: 0.8402\n",
      "val Loss: 0.2313 Acc: 0.9346\n",
      "\n",
      "Epoch:55/100\n",
      "----------\n",
      "train Loss: 0.3567 Acc: 0.8484\n",
      "val Loss: 0.2426 Acc: 0.9346\n",
      "\n",
      "Epoch:56/100\n",
      "----------\n",
      "train Loss: 0.3638 Acc: 0.8197\n",
      "val Loss: 0.2323 Acc: 0.9346\n",
      "\n",
      "Epoch:57/100\n",
      "----------\n",
      "train Loss: 0.3368 Acc: 0.8607\n",
      "val Loss: 0.2209 Acc: 0.9281\n",
      "\n",
      "Epoch:58/100\n",
      "----------\n",
      "train Loss: 0.3270 Acc: 0.8648\n",
      "val Loss: 0.2272 Acc: 0.9281\n",
      "\n",
      "Epoch:59/100\n",
      "----------\n",
      "train Loss: 0.4058 Acc: 0.8156\n",
      "val Loss: 0.2272 Acc: 0.9281\n",
      "\n",
      "Epoch:60/100\n",
      "----------\n",
      "train Loss: 0.3704 Acc: 0.8484\n",
      "val Loss: 0.2263 Acc: 0.9346\n",
      "\n",
      "Epoch:61/100\n",
      "----------\n",
      "train Loss: 0.3545 Acc: 0.8279\n",
      "val Loss: 0.2345 Acc: 0.9281\n",
      "\n",
      "Epoch:62/100\n",
      "----------\n",
      "train Loss: 0.3612 Acc: 0.8279\n",
      "val Loss: 0.2277 Acc: 0.9281\n",
      "\n",
      "Epoch:63/100\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.8443\n",
      "val Loss: 0.2261 Acc: 0.9346\n",
      "\n",
      "Epoch:64/100\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8689\n",
      "val Loss: 0.2223 Acc: 0.9281\n",
      "\n",
      "Epoch:65/100\n",
      "----------\n",
      "train Loss: 0.3533 Acc: 0.8320\n",
      "val Loss: 0.2364 Acc: 0.9216\n",
      "\n",
      "Epoch:66/100\n",
      "----------\n",
      "train Loss: 0.3394 Acc: 0.8443\n",
      "val Loss: 0.2253 Acc: 0.9216\n",
      "\n",
      "Epoch:67/100\n",
      "----------\n",
      "train Loss: 0.3291 Acc: 0.8566\n",
      "val Loss: 0.2269 Acc: 0.9216\n",
      "\n",
      "Epoch:68/100\n",
      "----------\n",
      "train Loss: 0.3363 Acc: 0.8566\n",
      "val Loss: 0.2358 Acc: 0.9085\n",
      "\n",
      "Epoch:69/100\n",
      "----------\n",
      "train Loss: 0.3330 Acc: 0.8484\n",
      "val Loss: 0.2357 Acc: 0.9020\n",
      "\n",
      "Epoch:70/100\n",
      "----------\n",
      "train Loss: 0.3589 Acc: 0.8197\n",
      "val Loss: 0.2304 Acc: 0.9346\n",
      "\n",
      "Epoch:71/100\n",
      "----------\n",
      "train Loss: 0.3478 Acc: 0.8484\n",
      "val Loss: 0.2300 Acc: 0.9281\n",
      "\n",
      "Epoch:72/100\n",
      "----------\n",
      "train Loss: 0.4078 Acc: 0.7910\n",
      "val Loss: 0.2237 Acc: 0.9412\n",
      "\n",
      "Epoch:73/100\n",
      "----------\n",
      "train Loss: 0.3769 Acc: 0.8197\n",
      "val Loss: 0.2358 Acc: 0.9281\n",
      "\n",
      "Epoch:74/100\n",
      "----------\n",
      "train Loss: 0.4128 Acc: 0.7951\n",
      "val Loss: 0.2329 Acc: 0.9150\n",
      "\n",
      "Epoch:75/100\n",
      "----------\n",
      "train Loss: 0.3629 Acc: 0.8443\n",
      "val Loss: 0.2270 Acc: 0.9281\n",
      "\n",
      "Epoch:76/100\n",
      "----------\n",
      "train Loss: 0.3893 Acc: 0.8361\n",
      "val Loss: 0.2183 Acc: 0.9281\n",
      "\n",
      "Epoch:77/100\n",
      "----------\n",
      "train Loss: 0.3464 Acc: 0.8566\n",
      "val Loss: 0.2367 Acc: 0.9346\n",
      "\n",
      "Epoch:78/100\n",
      "----------\n",
      "train Loss: 0.3145 Acc: 0.8648\n",
      "val Loss: 0.2186 Acc: 0.9346\n",
      "\n",
      "Epoch:79/100\n",
      "----------\n",
      "train Loss: 0.3726 Acc: 0.8238\n",
      "val Loss: 0.2330 Acc: 0.9412\n",
      "\n",
      "Epoch:80/100\n",
      "----------\n",
      "train Loss: 0.3751 Acc: 0.8443\n",
      "val Loss: 0.2207 Acc: 0.9281\n",
      "\n",
      "Epoch:81/100\n",
      "----------\n",
      "train Loss: 0.3922 Acc: 0.8033\n",
      "val Loss: 0.2276 Acc: 0.9346\n",
      "\n",
      "Epoch:82/100\n",
      "----------\n",
      "train Loss: 0.3692 Acc: 0.8484\n",
      "val Loss: 0.2336 Acc: 0.9346\n",
      "\n",
      "Epoch:83/100\n",
      "----------\n",
      "train Loss: 0.3355 Acc: 0.8566\n",
      "val Loss: 0.2313 Acc: 0.9216\n",
      "\n",
      "Epoch:84/100\n",
      "----------\n",
      "train Loss: 0.3498 Acc: 0.8443\n",
      "val Loss: 0.2341 Acc: 0.9412\n",
      "\n",
      "Epoch:85/100\n",
      "----------\n",
      "train Loss: 0.3694 Acc: 0.8197\n",
      "val Loss: 0.2290 Acc: 0.9346\n",
      "\n",
      "Epoch:86/100\n",
      "----------\n",
      "train Loss: 0.3827 Acc: 0.8402\n",
      "val Loss: 0.2204 Acc: 0.9216\n",
      "\n",
      "Epoch:87/100\n",
      "----------\n",
      "train Loss: 0.3365 Acc: 0.8607\n",
      "val Loss: 0.2217 Acc: 0.9281\n",
      "\n",
      "Epoch:88/100\n",
      "----------\n",
      "train Loss: 0.3605 Acc: 0.8525\n",
      "val Loss: 0.2251 Acc: 0.9216\n",
      "\n",
      "Epoch:89/100\n",
      "----------\n",
      "train Loss: 0.3368 Acc: 0.8443\n",
      "val Loss: 0.2249 Acc: 0.9346\n",
      "\n",
      "Epoch:90/100\n",
      "----------\n",
      "train Loss: 0.3672 Acc: 0.8238\n",
      "val Loss: 0.2339 Acc: 0.9216\n",
      "\n",
      "Epoch:91/100\n",
      "----------\n",
      "train Loss: 0.3415 Acc: 0.8484\n",
      "val Loss: 0.2191 Acc: 0.9346\n",
      "\n",
      "Epoch:92/100\n",
      "----------\n",
      "train Loss: 0.3361 Acc: 0.8607\n",
      "val Loss: 0.2221 Acc: 0.9412\n",
      "\n",
      "Epoch:93/100\n",
      "----------\n",
      "train Loss: 0.3802 Acc: 0.8238\n",
      "val Loss: 0.2369 Acc: 0.9281\n",
      "\n",
      "Epoch:94/100\n",
      "----------\n",
      "train Loss: 0.4094 Acc: 0.8115\n",
      "val Loss: 0.2284 Acc: 0.9216\n",
      "\n",
      "Epoch:95/100\n",
      "----------\n",
      "train Loss: 0.2999 Acc: 0.8893\n",
      "val Loss: 0.2221 Acc: 0.9346\n",
      "\n",
      "Epoch:96/100\n",
      "----------\n",
      "train Loss: 0.3378 Acc: 0.8484\n",
      "val Loss: 0.2224 Acc: 0.9216\n",
      "\n",
      "Epoch:97/100\n",
      "----------\n",
      "train Loss: 0.3659 Acc: 0.8361\n",
      "val Loss: 0.2345 Acc: 0.9346\n",
      "\n",
      "Epoch:98/100\n",
      "----------\n",
      "train Loss: 0.3119 Acc: 0.8852\n",
      "val Loss: 0.2299 Acc: 0.9216\n",
      "\n",
      "Epoch:99/100\n",
      "----------\n",
      "train Loss: 0.3157 Acc: 0.8689\n",
      "val Loss: 0.2252 Acc: 0.9412\n",
      "\n",
      "Epoch:100/100\n",
      "----------\n",
      "train Loss: 0.3794 Acc: 0.8484\n",
      "val Loss: 0.2312 Acc: 0.9346\n",
      "\n",
      "Training complete in 2m :13s\n",
      "Best val Acc: 0.9412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the number of input feature from the last layer\n",
    "num_features=model.fc.in_features # fc is the last layer in the model\n",
    "print(f'The number of input features is: {num_features}')\n",
    "\n",
    "\n",
    "# Create a new layer and assign it to teh last layer\n",
    "model.fc=nn.Linear(num_features,2) # we inserted a new fully connected layer with a dimensionality of 2 is the number of classes\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "loss=nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001)\n",
    "\n",
    "NUM_EPOCHS=100\n",
    "\n",
    "# scheduler for LR updates\n",
    "step_lr_sceduler=optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1) # the LR will be reduced by a factor of 10 percent every 10 epochs\n",
    "\n",
    "# Calling training function\n",
    "model=train_model(model,loss,optimizer,step_lr_sceduler,num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fine-tuning the CIFAR-10 datase</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a new project\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GPU\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "N_CHANNELS=3\n",
    "N_CLASSES=10\n",
    "LR=1e-4\n",
    "BATCH_SIZE=8\n",
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_dataset=datasets.CIFAR10(root='dataset/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained VGG model\n",
    "model=models.vgg16(pretrained=True)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has been observed that the VGG model utilizes pairs of max-pooling layers, reducing the input image size by half.\n",
    "# The final layer before the classifier block is an average pooling layer.\n",
    "# The avgpooling layer will be modified to have a 1x1 kernel size to accommodate the input image size of CIFAR10.\n",
    "# The last layer of the classifier must be adjusted to match the number of CIFAR10 classes, instead of the 1000 classes in ImageNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): Identity()\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Suppose that we want to remove the avgpooling\n",
    "class Identity(nn.Module):  # we gonna replace teh average pooling layer with an identity layer \n",
    "    def __init__(self):\n",
    "        super(Identity,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "model=models.vgg16(pretrained=True)\n",
    "model.avgpool=Identity()\n",
    "# If there are multiple average pooling layers in the model, we can selectively replace them using indexed assignment.\n",
    "# For example, to replace the first avgpool layer, use: model.avgpool[0] = _Identity() \n",
    "# Similarly, for the second one, use: model.avgpool[1] = _Identity(), and so on.\n",
    "model.classifier=nn.Linear(512,10) # if we select model.classifier[0], then we select only the first layer in the classifier module\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.classifier=nn.Sequential(nn.Linear(512,100),\\n                               nn.Dropout(p=0.8)\\n                               nn.Linear(100,10))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To replace all layers in the classifier block with Identity layers, iterate through them and assign an Identity layer to each.\n",
    "'''\n",
    "for i in range(1,6):\n",
    "    model.classifier[i]=Identity()\n",
    "'''\n",
    "\n",
    "# Alternatively, we can extend the classifier block by adding a Sequential layer with desired sub-layers.\n",
    "'''\n",
    "model.classifier=nn.Sequential(nn.Linear(512,100),\n",
    "                               nn.Dropout(p=0.8)\n",
    "                               nn.Linear(100,10))\n",
    "'''\n",
    "\n",
    "# To keep the classifier block simple, we can replace it with just one layer as shown in the above cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss at epoch 1 is: 0.66970\n",
      "The average loss at epoch 2 is: 0.36358\n",
      "The average loss at epoch 3 is: 0.23830\n",
      "The average loss at epoch 4 is: 0.16289\n",
      "The average loss at epoch 5 is: 0.12233\n",
      "The average loss at epoch 6 is: 0.09975\n",
      "The average loss at epoch 7 is: 0.08491\n",
      "The average loss at epoch 8 is: 0.07559\n",
      "The average loss at epoch 9 is: 0.07048\n",
      "The average loss at epoch 10 is: 0.06368\n",
      "The average loss at epoch 11 is: 0.06177\n",
      "The average loss at epoch 12 is: 0.05712\n",
      "The average loss at epoch 13 is: 0.05761\n",
      "The average loss at epoch 14 is: 0.06038\n",
      "The average loss at epoch 15 is: 0.05587\n",
      "The average loss at epoch 16 is: 0.05105\n",
      "The average loss at epoch 17 is: 0.05343\n",
      "The average loss at epoch 18 is: 0.05100\n",
      "The average loss at epoch 19 is: 0.06446\n",
      "The average loss at epoch 20 is: 0.04535\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    losses=[]\n",
    "    for idx,(images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Move data in the GPU\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs=model(images)\n",
    "        loss_=loss(outputs,labels)\n",
    "        losses.append(loss_.item())\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "\n",
    "        # Gradient descent or Adam step to update the parameters\n",
    "        optimizer.step()\n",
    "    print(f'The average loss at epoch {epoch+1} is: {sum(losses)/len(losses):.5f}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 49663 / 50000 with accuracy 99.33\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predictions = outputs.max(1)\n",
    "            num_correct += (predictions == labels).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "check_accuracy(train_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Finetuning based on freezing is faster</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): Identity()\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Suppose we want to remove the avgpooling\n",
    "class Identity(nn.Module):  # we gonna replace teh average pooling layer with an identity layer \n",
    "    def __init__(self):\n",
    "        super(Identity,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "model=models.vgg16(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "\n",
    "model.avgpool=Identity()\n",
    "model.classifier=nn.Sequential(nn.Linear(512,100),\n",
    "                              nn.ReLU(),\n",
    "                            nn.Linear(100,10))\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss at epoch 1 is: 1.38610\n",
      "The average loss at epoch 2 is: 1.22174\n",
      "The average loss at epoch 3 is: 1.18008\n",
      "The average loss at epoch 4 is: 1.15680\n",
      "The average loss at epoch 5 is: 1.13718\n",
      "The average loss at epoch 6 is: 1.12068\n",
      "The average loss at epoch 7 is: 1.10719\n",
      "The average loss at epoch 8 is: 1.09706\n",
      "The average loss at epoch 9 is: 1.09167\n",
      "The average loss at epoch 10 is: 1.07837\n",
      "The average loss at epoch 11 is: 1.07156\n",
      "The average loss at epoch 12 is: 1.06552\n",
      "The average loss at epoch 13 is: 1.05667\n",
      "The average loss at epoch 14 is: 1.04887\n",
      "The average loss at epoch 15 is: 1.04535\n",
      "The average loss at epoch 16 is: 1.03861\n",
      "The average loss at epoch 17 is: 1.03005\n",
      "The average loss at epoch 18 is: 1.02920\n",
      "The average loss at epoch 19 is: 1.02104\n",
      "The average loss at epoch 20 is: 1.01634\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    losses=[]\n",
    "    for idx,(images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Move ddata in the GPU\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs=model(images)\n",
    "        loss_=loss(outputs,labels)\n",
    "        losses.append(loss_.item())\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "\n",
    "        # Gradient descent or adam step to update the parameters\n",
    "        optimizer.step()\n",
    "    print(f'The average loss at epoch {epoch+1} is: {sum(losses)/len(losses):.5f}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
