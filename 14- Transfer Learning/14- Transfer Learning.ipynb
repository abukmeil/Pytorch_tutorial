{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transfer Learning</h1>\n",
    "\n",
    "<h3 style=\"color: yellow;\">This tutorial covers transfer learning and how it can be applied in PyTorch.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Transfer learning is an ML method where a model developed for one task is reused as a starting point for another model designed for a different task.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">For instance, if we have a model built for the classification of n classes of vehicles, we can modify this model by adding a layer on top to construct a new model for a two-class classification (such as Car/Truck).</h3>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src='translearn.png', width =600>\n",
    "</div>\n",
    "\n",
    "<h3 style=\"color: yellow;\">In general, transfer learning is a popular method in ML. It facilitates the swift creation of new models, thereby conserving time and minimizing trainable parameters for more extensive tasks.</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Resnet-18 finetuning on Hymenoptera dataset</h1>\n",
    "<h3 style=\"color: yellow;\">This tutorial utilizes the Hymenoptera (insect) dataset, which is a small subset of ImageNet.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Our objective is to fine-tune Resnet-18 for binary classification. Specifically, we are adapting a deep learning model for the classification of ants and bees.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">The dataset consists of 244 training images for both ants and bees, and 153 validation images for each class.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Given its size, the dataset is quite limited for training a model from scratch.</h3>\n",
    "\n",
    "<h3 style=\"color: yellow;\">However, by employing transfer learning, we aim to achieve reasonable generalization.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/lib/python3/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPU\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet -18 have been trained on ImageNet dataset which has 1000 classes.\n",
    "# The following are dataset statistics for each channel\n",
    "mean=np.array([0.485,0.456,0.406])\n",
    "std=np.array([0.229,0.224,0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transforms\n",
    "data_tansforms={'train':transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean,std)]),\n",
    "                'val':transforms.Compose([transforms.Resize(256),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean,std)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir='/home/mohanad/learn/Pytorch/14- Transfer Learning/data/hymenoptera_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets\n",
    "image_datasets={x:datasets.ImageFolder(os.path.join(data_dir,x),data_tansforms[x]) for x in ['train','val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images shape is: torch.Size([4, 3, 224, 224])\n",
      "The labels shape is: torch.Size([4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataloaders\n",
    "dataloaders={x:DataLoader(image_datasets[x],batch_size=4,shuffle=True,num_workers=4) for x in ['train','val']}\n",
    "\n",
    "iter_=iter(dataloaders['train'])\n",
    "images, labels=next(iter_)\n",
    "print(f'The images shape is: {images.shape}')\n",
    "print(f'The labels shape is: {labels.shape}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set size is: 244\n",
      "The testing set size is: 153\n"
     ]
    }
   ],
   "source": [
    "# Print teh size of the datasets\n",
    "dataset_sizes={x:len(image_datasets[x]) for x in ['train','val']}\n",
    "print(f'The training set size is: {dataset_sizes[\"train\"]}')\n",
    "print(f'The testing set size is: {dataset_sizes[\"val\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path for teh first sample is: /home/mohanad/learn/Pytorch/14- Transfer Learning/data/hymenoptera_data/train/ants/0013035.jpg\n",
      "The classes names are: ['ants', 'bees']\n"
     ]
    }
   ],
   "source": [
    " # This is a dataset object contains the path for each sample\n",
    "train_dataset=image_datasets['train']\n",
    "print(f'The path for teh first sample is: {train_dataset.samples[0][0]}')\n",
    "print(f'The classes names are: {train_dataset.classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,loss,optimizer,scheduler,num_epochs=25):\n",
    "    start=time.time()\n",
    "    best_acc=0.0\n",
    "    # best model weights\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch:{epoch+1}/{num_epochs}')\n",
    "        print('-'*10)\n",
    "        # We have a training and validation phase at each epoch\n",
    "        for phase in ['train','val']:\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss=0.0\n",
    "            running_corrects=0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                images=images.to(device)\n",
    "                labels=labels.to(device)\n",
    "            # tracking history only if in training phase\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs=model(images)\n",
    "                    _,prediction=torch.max(outputs,1)\n",
    "                    loss_=loss(outputs,labels)\n",
    "            # Backward + optimize only if in training phase\n",
    "                    if phase=='train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss_.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    # Statistics\n",
    "                    running_loss+=loss_.item()*images.size(0)\n",
    "                    running_corrects+=torch.sum(prediction==labels.data)\n",
    "            \n",
    "            # scheduler\n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss=running_loss/dataset_sizes[phase]\n",
    "            epoch_acc=running_corrects.double()/dataset_sizes[phase]\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            # Saving the model with best accuracy on validation\n",
    "            \n",
    "            if phase=='val' and epoch_acc>best_acc:\n",
    "                best_acc=epoch_acc\n",
    "                best_model_wts=copy.deepcopy(model.state_dict())\n",
    "        print('')\n",
    "    time_elapsed=time.time()-start\n",
    "    print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use transfer learning\n",
    "# Setting the model\n",
    "model=models.resnet18(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 1, Layer Name: bn1.weight, Shape: torch.Size([64])\n",
      "Index: 2, Layer Name: bn1.bias, Shape: torch.Size([64])\n",
      "Index: 3, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 4, Layer Name: layer1.0.bn1.weight, Shape: torch.Size([64])\n",
      "Index: 5, Layer Name: layer1.0.bn1.bias, Shape: torch.Size([64])\n",
      "Index: 6, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 7, Layer Name: layer1.0.bn2.weight, Shape: torch.Size([64])\n",
      "Index: 8, Layer Name: layer1.0.bn2.bias, Shape: torch.Size([64])\n",
      "Index: 9, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 10, Layer Name: layer1.1.bn1.weight, Shape: torch.Size([64])\n",
      "Index: 11, Layer Name: layer1.1.bn1.bias, Shape: torch.Size([64])\n",
      "Index: 12, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 13, Layer Name: layer1.1.bn2.weight, Shape: torch.Size([64])\n",
      "Index: 14, Layer Name: layer1.1.bn2.bias, Shape: torch.Size([64])\n",
      "Index: 15, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 16, Layer Name: layer2.0.bn1.weight, Shape: torch.Size([128])\n",
      "Index: 17, Layer Name: layer2.0.bn1.bias, Shape: torch.Size([128])\n",
      "Index: 18, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 19, Layer Name: layer2.0.bn2.weight, Shape: torch.Size([128])\n",
      "Index: 20, Layer Name: layer2.0.bn2.bias, Shape: torch.Size([128])\n",
      "Index: 21, Layer Name: layer2.0.downsample.0.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Index: 22, Layer Name: layer2.0.downsample.1.weight, Shape: torch.Size([128])\n",
      "Index: 23, Layer Name: layer2.0.downsample.1.bias, Shape: torch.Size([128])\n",
      "Index: 24, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 25, Layer Name: layer2.1.bn1.weight, Shape: torch.Size([128])\n",
      "Index: 26, Layer Name: layer2.1.bn1.bias, Shape: torch.Size([128])\n",
      "Index: 27, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 28, Layer Name: layer2.1.bn2.weight, Shape: torch.Size([128])\n",
      "Index: 29, Layer Name: layer2.1.bn2.bias, Shape: torch.Size([128])\n",
      "Index: 30, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 31, Layer Name: layer3.0.bn1.weight, Shape: torch.Size([256])\n",
      "Index: 32, Layer Name: layer3.0.bn1.bias, Shape: torch.Size([256])\n",
      "Index: 33, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 34, Layer Name: layer3.0.bn2.weight, Shape: torch.Size([256])\n",
      "Index: 35, Layer Name: layer3.0.bn2.bias, Shape: torch.Size([256])\n",
      "Index: 36, Layer Name: layer3.0.downsample.0.weight, Shape: torch.Size([256, 128, 1, 1])\n",
      "Index: 37, Layer Name: layer3.0.downsample.1.weight, Shape: torch.Size([256])\n",
      "Index: 38, Layer Name: layer3.0.downsample.1.bias, Shape: torch.Size([256])\n",
      "Index: 39, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 40, Layer Name: layer3.1.bn1.weight, Shape: torch.Size([256])\n",
      "Index: 41, Layer Name: layer3.1.bn1.bias, Shape: torch.Size([256])\n",
      "Index: 42, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 43, Layer Name: layer3.1.bn2.weight, Shape: torch.Size([256])\n",
      "Index: 44, Layer Name: layer3.1.bn2.bias, Shape: torch.Size([256])\n",
      "Index: 45, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 46, Layer Name: layer4.0.bn1.weight, Shape: torch.Size([512])\n",
      "Index: 47, Layer Name: layer4.0.bn1.bias, Shape: torch.Size([512])\n",
      "Index: 48, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 49, Layer Name: layer4.0.bn2.weight, Shape: torch.Size([512])\n",
      "Index: 50, Layer Name: layer4.0.bn2.bias, Shape: torch.Size([512])\n",
      "Index: 51, Layer Name: layer4.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1])\n",
      "Index: 52, Layer Name: layer4.0.downsample.1.weight, Shape: torch.Size([512])\n",
      "Index: 53, Layer Name: layer4.0.downsample.1.bias, Shape: torch.Size([512])\n",
      "Index: 54, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 55, Layer Name: layer4.1.bn1.weight, Shape: torch.Size([512])\n",
      "Index: 56, Layer Name: layer4.1.bn1.bias, Shape: torch.Size([512])\n",
      "Index: 57, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 58, Layer Name: layer4.1.bn2.weight, Shape: torch.Size([512])\n",
      "Index: 59, Layer Name: layer4.1.bn2.bias, Shape: torch.Size([512])\n",
      "Index: 60, Layer Name: fc.weight, Shape: torch.Size([1000, 512])\n",
      "Index: 61, Layer Name: fc.bias, Shape: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Print all model parameters\n",
    "\n",
    "for idx,(name,param) in enumerate(model.named_parameters()):\n",
    "    print(f\"Index: {idx}, Layer Name: {name}, Shape: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "layer1.0.conv1\n",
      "layer1.0.bn1\n",
      "layer1.0.conv2\n",
      "layer1.0.bn2\n",
      "layer1.1.conv1\n",
      "layer1.1.bn1\n",
      "layer1.1.conv2\n",
      "layer1.1.bn2\n",
      "layer2.0.conv1\n",
      "layer2.0.bn1\n",
      "layer2.0.conv2\n",
      "layer2.0.bn2\n",
      "layer2.0.downsample.0\n",
      "layer2.0.downsample.1\n",
      "layer2.1.conv1\n",
      "layer2.1.bn1\n",
      "layer2.1.conv2\n",
      "layer2.1.bn2\n",
      "layer3.0.conv1\n",
      "layer3.0.bn1\n",
      "layer3.0.conv2\n",
      "layer3.0.bn2\n",
      "layer3.0.downsample.0\n",
      "layer3.0.downsample.1\n",
      "layer3.1.conv1\n",
      "layer3.1.bn1\n",
      "layer3.1.conv2\n",
      "layer3.1.bn2\n",
      "layer4.0.conv1\n",
      "layer4.0.bn1\n",
      "layer4.0.conv2\n",
      "layer4.0.bn2\n",
      "layer4.0.downsample.0\n",
      "layer4.0.downsample.1\n",
      "layer4.1.conv1\n",
      "layer4.1.bn1\n",
      "layer4.1.conv2\n",
      "layer4.1.bn2\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "# Iterate over teh named model paarameters to print the layers that have weights\n",
    "for name,module in model.named_modules():\n",
    "    if hasattr(module,'weight') and hasattr(module.weight, 'shape'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 3, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 6, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 9, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 12, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 15, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 18, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 24, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 27, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 30, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 33, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 39, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 42, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 45, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 48, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 54, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 57, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Print only the layers that perform convolution operations\n",
    "for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "    if 'conv' in name:\n",
    "        print(f\"Index: {idx}, Layer Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of input features is: 512\n"
     ]
    }
   ],
   "source": [
    "# Back to  continue with transfere lerning\n",
    "# get the number of input feature from the last layer\n",
    "num_features=model.fc.in_features\n",
    "print(f'The number of input features is: {num_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new layer with 2 output features in the top of the fc layer\n",
    "model.fc=nn.Linear(num_features,2)  # this will neglect the old FC layer and create a new one\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 106.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=images[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/100\n",
      "----------\n",
      "train Loss: 0.5737 Acc: 0.6885\n",
      "val Loss: 0.1987 Acc: 0.9216\n",
      "\n",
      "Epoch:2/100\n",
      "----------\n",
      "train Loss: 0.4646 Acc: 0.7828\n",
      "val Loss: 0.4011 Acc: 0.8824\n",
      "\n",
      "Epoch:3/100\n",
      "----------\n",
      "train Loss: 0.5883 Acc: 0.7541\n",
      "val Loss: 0.2574 Acc: 0.9020\n",
      "\n",
      "Epoch:4/100\n",
      "----------\n",
      "train Loss: 0.5281 Acc: 0.7828\n",
      "val Loss: 0.2201 Acc: 0.9216\n",
      "\n",
      "Epoch:5/100\n",
      "----------\n",
      "train Loss: 0.5330 Acc: 0.7910\n",
      "val Loss: 0.2849 Acc: 0.8954\n",
      "\n",
      "Epoch:6/100\n",
      "----------\n",
      "train Loss: 0.4466 Acc: 0.8197\n",
      "val Loss: 0.2628 Acc: 0.9085\n",
      "\n",
      "Epoch:7/100\n",
      "----------\n",
      "train Loss: 0.4346 Acc: 0.8361\n",
      "val Loss: 0.2580 Acc: 0.9150\n",
      "\n",
      "Epoch:8/100\n",
      "----------\n",
      "train Loss: 0.4548 Acc: 0.7910\n",
      "val Loss: 0.2250 Acc: 0.9216\n",
      "\n",
      "Epoch:9/100\n",
      "----------\n",
      "train Loss: 0.5697 Acc: 0.7705\n",
      "val Loss: 0.2704 Acc: 0.8889\n",
      "\n",
      "Epoch:10/100\n",
      "----------\n",
      "train Loss: 0.5441 Acc: 0.7951\n",
      "val Loss: 0.4711 Acc: 0.8693\n",
      "\n",
      "Epoch:11/100\n",
      "----------\n",
      "train Loss: 0.3864 Acc: 0.8443\n",
      "val Loss: 0.2687 Acc: 0.9085\n",
      "\n",
      "Epoch:12/100\n",
      "----------\n",
      "train Loss: 0.4041 Acc: 0.8402\n",
      "val Loss: 0.2594 Acc: 0.9281\n",
      "\n",
      "Epoch:13/100\n",
      "----------\n",
      "train Loss: 0.4045 Acc: 0.8279\n",
      "val Loss: 0.3231 Acc: 0.8954\n",
      "\n",
      "Epoch:14/100\n",
      "----------\n",
      "train Loss: 0.2861 Acc: 0.8689\n",
      "val Loss: 0.2700 Acc: 0.9150\n",
      "\n",
      "Epoch:15/100\n",
      "----------\n",
      "train Loss: 0.2714 Acc: 0.8852\n",
      "val Loss: 0.2572 Acc: 0.9281\n",
      "\n",
      "Epoch:16/100\n",
      "----------\n",
      "train Loss: 0.2114 Acc: 0.8975\n",
      "val Loss: 0.2647 Acc: 0.9216\n",
      "\n",
      "Epoch:17/100\n",
      "----------\n",
      "train Loss: 0.2518 Acc: 0.8975\n",
      "val Loss: 0.2518 Acc: 0.9281\n",
      "\n",
      "Epoch:18/100\n",
      "----------\n",
      "train Loss: 0.2380 Acc: 0.9098\n",
      "val Loss: 0.2362 Acc: 0.9281\n",
      "\n",
      "Epoch:19/100\n",
      "----------\n",
      "train Loss: 0.3075 Acc: 0.8730\n",
      "val Loss: 0.2106 Acc: 0.9281\n",
      "\n",
      "Epoch:20/100\n",
      "----------\n",
      "train Loss: 0.2198 Acc: 0.9221\n",
      "val Loss: 0.2166 Acc: 0.9346\n",
      "\n",
      "Epoch:21/100\n",
      "----------\n",
      "train Loss: 0.3099 Acc: 0.8566\n",
      "val Loss: 0.1958 Acc: 0.9346\n",
      "\n",
      "Epoch:22/100\n",
      "----------\n",
      "train Loss: 0.2654 Acc: 0.8648\n",
      "val Loss: 0.2030 Acc: 0.9412\n",
      "\n",
      "Epoch:23/100\n",
      "----------\n",
      "train Loss: 0.2087 Acc: 0.9139\n",
      "val Loss: 0.2131 Acc: 0.9346\n",
      "\n",
      "Epoch:24/100\n",
      "----------\n",
      "train Loss: 0.3768 Acc: 0.8566\n",
      "val Loss: 0.2128 Acc: 0.9412\n",
      "\n",
      "Epoch:25/100\n",
      "----------\n",
      "train Loss: 0.2570 Acc: 0.9098\n",
      "val Loss: 0.2032 Acc: 0.9216\n",
      "\n",
      "Epoch:26/100\n",
      "----------\n",
      "train Loss: 0.3683 Acc: 0.8443\n",
      "val Loss: 0.2095 Acc: 0.9346\n",
      "\n",
      "Epoch:27/100\n",
      "----------\n",
      "train Loss: 0.2479 Acc: 0.9016\n",
      "val Loss: 0.2417 Acc: 0.9150\n",
      "\n",
      "Epoch:28/100\n",
      "----------\n",
      "train Loss: 0.2811 Acc: 0.8811\n",
      "val Loss: 0.2116 Acc: 0.9346\n",
      "\n",
      "Epoch:29/100\n",
      "----------\n",
      "train Loss: 0.2905 Acc: 0.8811\n",
      "val Loss: 0.2064 Acc: 0.9281\n",
      "\n",
      "Epoch:30/100\n",
      "----------\n",
      "train Loss: 0.2884 Acc: 0.8607\n",
      "val Loss: 0.2021 Acc: 0.9346\n",
      "\n",
      "Epoch:31/100\n",
      "----------\n",
      "train Loss: 0.1935 Acc: 0.9016\n",
      "val Loss: 0.2063 Acc: 0.9412\n",
      "\n",
      "Epoch:32/100\n",
      "----------\n",
      "train Loss: 0.2929 Acc: 0.8566\n",
      "val Loss: 0.2383 Acc: 0.9281\n",
      "\n",
      "Epoch:33/100\n",
      "----------\n",
      "train Loss: 0.2433 Acc: 0.9057\n",
      "val Loss: 0.2085 Acc: 0.9281\n",
      "\n",
      "Epoch:34/100\n",
      "----------\n",
      "train Loss: 0.2244 Acc: 0.9139\n",
      "val Loss: 0.1965 Acc: 0.9346\n",
      "\n",
      "Epoch:35/100\n",
      "----------\n",
      "train Loss: 0.2865 Acc: 0.8770\n",
      "val Loss: 0.2349 Acc: 0.9281\n",
      "\n",
      "Epoch:36/100\n",
      "----------\n",
      "train Loss: 0.2412 Acc: 0.8852\n",
      "val Loss: 0.2056 Acc: 0.9412\n",
      "\n",
      "Epoch:37/100\n",
      "----------\n",
      "train Loss: 0.3175 Acc: 0.8893\n",
      "val Loss: 0.2083 Acc: 0.9412\n",
      "\n",
      "Epoch:38/100\n",
      "----------\n",
      "train Loss: 0.2535 Acc: 0.8811\n",
      "val Loss: 0.2036 Acc: 0.9412\n",
      "\n",
      "Epoch:39/100\n",
      "----------\n",
      "train Loss: 0.2685 Acc: 0.8893\n",
      "val Loss: 0.2238 Acc: 0.9216\n",
      "\n",
      "Epoch:40/100\n",
      "----------\n",
      "train Loss: 0.2011 Acc: 0.9221\n",
      "val Loss: 0.2248 Acc: 0.9346\n",
      "\n",
      "Epoch:41/100\n",
      "----------\n",
      "train Loss: 0.2274 Acc: 0.8811\n",
      "val Loss: 0.2120 Acc: 0.9281\n",
      "\n",
      "Epoch:42/100\n",
      "----------\n",
      "train Loss: 0.2270 Acc: 0.9016\n",
      "val Loss: 0.1990 Acc: 0.9412\n",
      "\n",
      "Epoch:43/100\n",
      "----------\n",
      "train Loss: 0.3388 Acc: 0.8607\n",
      "val Loss: 0.2078 Acc: 0.9346\n",
      "\n",
      "Epoch:44/100\n",
      "----------\n",
      "train Loss: 0.2425 Acc: 0.8852\n",
      "val Loss: 0.2072 Acc: 0.9346\n",
      "\n",
      "Epoch:45/100\n",
      "----------\n",
      "train Loss: 0.2141 Acc: 0.9180\n",
      "val Loss: 0.2038 Acc: 0.9346\n",
      "\n",
      "Epoch:46/100\n",
      "----------\n",
      "train Loss: 0.3216 Acc: 0.8689\n",
      "val Loss: 0.2215 Acc: 0.9281\n",
      "\n",
      "Epoch:47/100\n",
      "----------\n",
      "train Loss: 0.2669 Acc: 0.8852\n",
      "val Loss: 0.1993 Acc: 0.9477\n",
      "\n",
      "Epoch:48/100\n",
      "----------\n",
      "train Loss: 0.2419 Acc: 0.9139\n",
      "val Loss: 0.2117 Acc: 0.9346\n",
      "\n",
      "Epoch:49/100\n",
      "----------\n",
      "train Loss: 0.2696 Acc: 0.8893\n",
      "val Loss: 0.2042 Acc: 0.9281\n",
      "\n",
      "Epoch:50/100\n",
      "----------\n",
      "train Loss: 0.2064 Acc: 0.8975\n",
      "val Loss: 0.2289 Acc: 0.9216\n",
      "\n",
      "Epoch:51/100\n",
      "----------\n",
      "train Loss: 0.2413 Acc: 0.9057\n",
      "val Loss: 0.2006 Acc: 0.9412\n",
      "\n",
      "Epoch:52/100\n",
      "----------\n",
      "train Loss: 0.2843 Acc: 0.8648\n",
      "val Loss: 0.2031 Acc: 0.9346\n",
      "\n",
      "Epoch:53/100\n",
      "----------\n",
      "train Loss: 0.2211 Acc: 0.9139\n",
      "val Loss: 0.1964 Acc: 0.9412\n",
      "\n",
      "Epoch:54/100\n",
      "----------\n",
      "train Loss: 0.2815 Acc: 0.8893\n",
      "val Loss: 0.2095 Acc: 0.9281\n",
      "\n",
      "Epoch:55/100\n",
      "----------\n",
      "train Loss: 0.3445 Acc: 0.8402\n",
      "val Loss: 0.2006 Acc: 0.9346\n",
      "\n",
      "Epoch:56/100\n",
      "----------\n",
      "train Loss: 0.2291 Acc: 0.9057\n",
      "val Loss: 0.2381 Acc: 0.9281\n",
      "\n",
      "Epoch:57/100\n",
      "----------\n",
      "train Loss: 0.1794 Acc: 0.9467\n",
      "val Loss: 0.2892 Acc: 0.9150\n",
      "\n",
      "Epoch:58/100\n",
      "----------\n",
      "train Loss: 0.2298 Acc: 0.9180\n",
      "val Loss: 0.2117 Acc: 0.9281\n",
      "\n",
      "Epoch:59/100\n",
      "----------\n",
      "train Loss: 0.2701 Acc: 0.8852\n",
      "val Loss: 0.2111 Acc: 0.9281\n",
      "\n",
      "Epoch:60/100\n",
      "----------\n",
      "train Loss: 0.2388 Acc: 0.8893\n",
      "val Loss: 0.2068 Acc: 0.9216\n",
      "\n",
      "Epoch:61/100\n",
      "----------\n",
      "train Loss: 0.3315 Acc: 0.8484\n",
      "val Loss: 0.2152 Acc: 0.9346\n",
      "\n",
      "Epoch:62/100\n",
      "----------\n",
      "train Loss: 0.2227 Acc: 0.8893\n",
      "val Loss: 0.2057 Acc: 0.9412\n",
      "\n",
      "Epoch:63/100\n",
      "----------\n",
      "train Loss: 0.2821 Acc: 0.8607\n",
      "val Loss: 0.2231 Acc: 0.9216\n",
      "\n",
      "Epoch:64/100\n",
      "----------\n",
      "train Loss: 0.2682 Acc: 0.8934\n",
      "val Loss: 0.2169 Acc: 0.9216\n",
      "\n",
      "Epoch:65/100\n",
      "----------\n",
      "train Loss: 0.2646 Acc: 0.8975\n",
      "val Loss: 0.2131 Acc: 0.9346\n",
      "\n",
      "Epoch:66/100\n",
      "----------\n",
      "train Loss: 0.2971 Acc: 0.8852\n",
      "val Loss: 0.2417 Acc: 0.9150\n",
      "\n",
      "Epoch:67/100\n",
      "----------\n",
      "train Loss: 0.2667 Acc: 0.8770\n",
      "val Loss: 0.2122 Acc: 0.9346\n",
      "\n",
      "Epoch:68/100\n",
      "----------\n",
      "train Loss: 0.2762 Acc: 0.9016\n",
      "val Loss: 0.2143 Acc: 0.9412\n",
      "\n",
      "Epoch:69/100\n",
      "----------\n",
      "train Loss: 0.3344 Acc: 0.8607\n",
      "val Loss: 0.2075 Acc: 0.9281\n",
      "\n",
      "Epoch:70/100\n",
      "----------\n",
      "train Loss: 0.2608 Acc: 0.9016\n",
      "val Loss: 0.1932 Acc: 0.9281\n",
      "\n",
      "Epoch:71/100\n",
      "----------\n",
      "train Loss: 0.2035 Acc: 0.9180\n",
      "val Loss: 0.2022 Acc: 0.9281\n",
      "\n",
      "Epoch:72/100\n",
      "----------\n",
      "train Loss: 0.3125 Acc: 0.8852\n",
      "val Loss: 0.1992 Acc: 0.9412\n",
      "\n",
      "Epoch:73/100\n",
      "----------\n",
      "train Loss: 0.3099 Acc: 0.8689\n",
      "val Loss: 0.1977 Acc: 0.9412\n",
      "\n",
      "Epoch:74/100\n",
      "----------\n",
      "train Loss: 0.2340 Acc: 0.8934\n",
      "val Loss: 0.2291 Acc: 0.9346\n",
      "\n",
      "Epoch:75/100\n",
      "----------\n",
      "train Loss: 0.3082 Acc: 0.8770\n",
      "val Loss: 0.2199 Acc: 0.9216\n",
      "\n",
      "Epoch:76/100\n",
      "----------\n",
      "train Loss: 0.2670 Acc: 0.8852\n",
      "val Loss: 0.2026 Acc: 0.9281\n",
      "\n",
      "Epoch:77/100\n",
      "----------\n",
      "train Loss: 0.2846 Acc: 0.8730\n",
      "val Loss: 0.2209 Acc: 0.9216\n",
      "\n",
      "Epoch:78/100\n",
      "----------\n",
      "train Loss: 0.3263 Acc: 0.8811\n",
      "val Loss: 0.2108 Acc: 0.9281\n",
      "\n",
      "Epoch:79/100\n",
      "----------\n",
      "train Loss: 0.2189 Acc: 0.8934\n",
      "val Loss: 0.2090 Acc: 0.9150\n",
      "\n",
      "Epoch:80/100\n",
      "----------\n",
      "train Loss: 0.2569 Acc: 0.8934\n",
      "val Loss: 0.1959 Acc: 0.9346\n",
      "\n",
      "Epoch:81/100\n",
      "----------\n",
      "train Loss: 0.2607 Acc: 0.8975\n",
      "val Loss: 0.2044 Acc: 0.9412\n",
      "\n",
      "Epoch:82/100\n",
      "----------\n",
      "train Loss: 0.2628 Acc: 0.8607\n",
      "val Loss: 0.2101 Acc: 0.9346\n",
      "\n",
      "Epoch:83/100\n",
      "----------\n",
      "train Loss: 0.2786 Acc: 0.8770\n",
      "val Loss: 0.2116 Acc: 0.9346\n",
      "\n",
      "Epoch:84/100\n",
      "----------\n",
      "train Loss: 0.2205 Acc: 0.8852\n",
      "val Loss: 0.1985 Acc: 0.9346\n",
      "\n",
      "Epoch:85/100\n",
      "----------\n",
      "train Loss: 0.2454 Acc: 0.9057\n",
      "val Loss: 0.2102 Acc: 0.9412\n",
      "\n",
      "Epoch:86/100\n",
      "----------\n",
      "train Loss: 0.2699 Acc: 0.8811\n",
      "val Loss: 0.2120 Acc: 0.9412\n",
      "\n",
      "Epoch:87/100\n",
      "----------\n",
      "train Loss: 0.2125 Acc: 0.9180\n",
      "val Loss: 0.2115 Acc: 0.9346\n",
      "\n",
      "Epoch:88/100\n",
      "----------\n",
      "train Loss: 0.2640 Acc: 0.8893\n",
      "val Loss: 0.2173 Acc: 0.9281\n",
      "\n",
      "Epoch:89/100\n",
      "----------\n",
      "train Loss: 0.2072 Acc: 0.9098\n",
      "val Loss: 0.1981 Acc: 0.9412\n",
      "\n",
      "Epoch:90/100\n",
      "----------\n",
      "train Loss: 0.2260 Acc: 0.8975\n",
      "val Loss: 0.1930 Acc: 0.9346\n",
      "\n",
      "Epoch:91/100\n",
      "----------\n",
      "train Loss: 0.2689 Acc: 0.8934\n",
      "val Loss: 0.2186 Acc: 0.9281\n",
      "\n",
      "Epoch:92/100\n",
      "----------\n",
      "train Loss: 0.2722 Acc: 0.8811\n",
      "val Loss: 0.1970 Acc: 0.9477\n",
      "\n",
      "Epoch:93/100\n",
      "----------\n",
      "train Loss: 0.2523 Acc: 0.8852\n",
      "val Loss: 0.2229 Acc: 0.9216\n",
      "\n",
      "Epoch:94/100\n",
      "----------\n",
      "train Loss: 0.2191 Acc: 0.8975\n",
      "val Loss: 0.2586 Acc: 0.9150\n",
      "\n",
      "Epoch:95/100\n",
      "----------\n",
      "train Loss: 0.2514 Acc: 0.8811\n",
      "val Loss: 0.2091 Acc: 0.9346\n",
      "\n",
      "Epoch:96/100\n",
      "----------\n",
      "train Loss: 0.3837 Acc: 0.8566\n",
      "val Loss: 0.2187 Acc: 0.9346\n",
      "\n",
      "Epoch:97/100\n",
      "----------\n",
      "train Loss: 0.2365 Acc: 0.8811\n",
      "val Loss: 0.2387 Acc: 0.9281\n",
      "\n",
      "Epoch:98/100\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9016\n",
      "val Loss: 0.2139 Acc: 0.9281\n",
      "\n",
      "Epoch:99/100\n",
      "----------\n",
      "train Loss: 0.2738 Acc: 0.8934\n",
      "val Loss: 0.2019 Acc: 0.9412\n",
      "\n",
      "Epoch:100/100\n",
      "----------\n",
      "train Loss: 0.2273 Acc: 0.8975\n",
      "val Loss: 0.2198 Acc: 0.9216\n",
      "\n",
      "Training complete in 2m 24s\n",
      "Best val Acc: 0.9477\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "# Define the loss function\n",
    "loss=nn.CrossEntropyLoss()\n",
    "# Define th eOptimzer\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "# Define the scheduler for LR Update\n",
    "step_lr_scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)\n",
    "# Calling the training function\n",
    "model=train_model(model,loss,optimizer,step_lr_scheduler,num_epochs=EPOCHS)\n",
    "\n",
    "# The method above is called fine-tuning of all model parameters, where we adjust the entire model's parameters using a lower learning rate (LR).\n",
    "\n",
    "# Another option is to freeze the parameters of the entire model and fine-tune only the last layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n",
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 1, Layer Name: bn1.weight, Shape: torch.Size([64])\n",
      "Index: 2, Layer Name: bn1.bias, Shape: torch.Size([64])\n",
      "Index: 3, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 4, Layer Name: layer1.0.bn1.weight, Shape: torch.Size([64])\n",
      "Index: 5, Layer Name: layer1.0.bn1.bias, Shape: torch.Size([64])\n",
      "Index: 6, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 7, Layer Name: layer1.0.bn2.weight, Shape: torch.Size([64])\n",
      "Index: 8, Layer Name: layer1.0.bn2.bias, Shape: torch.Size([64])\n",
      "Index: 9, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 10, Layer Name: layer1.1.bn1.weight, Shape: torch.Size([64])\n",
      "Index: 11, Layer Name: layer1.1.bn1.bias, Shape: torch.Size([64])\n",
      "Index: 12, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 13, Layer Name: layer1.1.bn2.weight, Shape: torch.Size([64])\n",
      "Index: 14, Layer Name: layer1.1.bn2.bias, Shape: torch.Size([64])\n",
      "Index: 15, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 16, Layer Name: layer2.0.bn1.weight, Shape: torch.Size([128])\n",
      "Index: 17, Layer Name: layer2.0.bn1.bias, Shape: torch.Size([128])\n",
      "Index: 18, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 19, Layer Name: layer2.0.bn2.weight, Shape: torch.Size([128])\n",
      "Index: 20, Layer Name: layer2.0.bn2.bias, Shape: torch.Size([128])\n",
      "Index: 21, Layer Name: layer2.0.downsample.0.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Index: 22, Layer Name: layer2.0.downsample.1.weight, Shape: torch.Size([128])\n",
      "Index: 23, Layer Name: layer2.0.downsample.1.bias, Shape: torch.Size([128])\n",
      "Index: 24, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 25, Layer Name: layer2.1.bn1.weight, Shape: torch.Size([128])\n",
      "Index: 26, Layer Name: layer2.1.bn1.bias, Shape: torch.Size([128])\n",
      "Index: 27, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 28, Layer Name: layer2.1.bn2.weight, Shape: torch.Size([128])\n",
      "Index: 29, Layer Name: layer2.1.bn2.bias, Shape: torch.Size([128])\n",
      "Index: 30, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 31, Layer Name: layer3.0.bn1.weight, Shape: torch.Size([256])\n",
      "Index: 32, Layer Name: layer3.0.bn1.bias, Shape: torch.Size([256])\n",
      "Index: 33, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 34, Layer Name: layer3.0.bn2.weight, Shape: torch.Size([256])\n",
      "Index: 35, Layer Name: layer3.0.bn2.bias, Shape: torch.Size([256])\n",
      "Index: 36, Layer Name: layer3.0.downsample.0.weight, Shape: torch.Size([256, 128, 1, 1])\n",
      "Index: 37, Layer Name: layer3.0.downsample.1.weight, Shape: torch.Size([256])\n",
      "Index: 38, Layer Name: layer3.0.downsample.1.bias, Shape: torch.Size([256])\n",
      "Index: 39, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 40, Layer Name: layer3.1.bn1.weight, Shape: torch.Size([256])\n",
      "Index: 41, Layer Name: layer3.1.bn1.bias, Shape: torch.Size([256])\n",
      "Index: 42, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 43, Layer Name: layer3.1.bn2.weight, Shape: torch.Size([256])\n",
      "Index: 44, Layer Name: layer3.1.bn2.bias, Shape: torch.Size([256])\n",
      "Index: 45, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 46, Layer Name: layer4.0.bn1.weight, Shape: torch.Size([512])\n",
      "Index: 47, Layer Name: layer4.0.bn1.bias, Shape: torch.Size([512])\n",
      "Index: 48, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 49, Layer Name: layer4.0.bn2.weight, Shape: torch.Size([512])\n",
      "Index: 50, Layer Name: layer4.0.bn2.bias, Shape: torch.Size([512])\n",
      "Index: 51, Layer Name: layer4.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1])\n",
      "Index: 52, Layer Name: layer4.0.downsample.1.weight, Shape: torch.Size([512])\n",
      "Index: 53, Layer Name: layer4.0.downsample.1.bias, Shape: torch.Size([512])\n",
      "Index: 54, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 55, Layer Name: layer4.1.bn1.weight, Shape: torch.Size([512])\n",
      "Index: 56, Layer Name: layer4.1.bn1.bias, Shape: torch.Size([512])\n",
      "Index: 57, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 58, Layer Name: layer4.1.bn2.weight, Shape: torch.Size([512])\n",
      "Index: 59, Layer Name: layer4.1.bn2.bias, Shape: torch.Size([512])\n",
      "Index: 60, Layer Name: fc.weight, Shape: torch.Size([1000, 512])\n",
      "Index: 61, Layer Name: fc.bias, Shape: torch.Size([1000])\n",
      "\n",
      "conv1 : torch.Size([64, 3, 7, 7])\n",
      "bn1 : torch.Size([64])\n",
      "layer1.0.conv1 : torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn1 : torch.Size([64])\n",
      "layer1.0.conv2 : torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2 : torch.Size([64])\n",
      "layer1.1.conv1 : torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn1 : torch.Size([64])\n",
      "layer1.1.conv2 : torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2 : torch.Size([64])\n",
      "layer2.0.conv1 : torch.Size([128, 64, 3, 3])\n",
      "layer2.0.bn1 : torch.Size([128])\n",
      "layer2.0.conv2 : torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2 : torch.Size([128])\n",
      "layer2.0.downsample.0 : torch.Size([128, 64, 1, 1])\n",
      "layer2.0.downsample.1 : torch.Size([128])\n",
      "layer2.1.conv1 : torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn1 : torch.Size([128])\n",
      "layer2.1.conv2 : torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2 : torch.Size([128])\n",
      "layer3.0.conv1 : torch.Size([256, 128, 3, 3])\n",
      "layer3.0.bn1 : torch.Size([256])\n",
      "layer3.0.conv2 : torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2 : torch.Size([256])\n",
      "layer3.0.downsample.0 : torch.Size([256, 128, 1, 1])\n",
      "layer3.0.downsample.1 : torch.Size([256])\n",
      "layer3.1.conv1 : torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn1 : torch.Size([256])\n",
      "layer3.1.conv2 : torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2 : torch.Size([256])\n",
      "layer4.0.conv1 : torch.Size([512, 256, 3, 3])\n",
      "layer4.0.bn1 : torch.Size([512])\n",
      "layer4.0.conv2 : torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2 : torch.Size([512])\n",
      "layer4.0.downsample.0 : torch.Size([512, 256, 1, 1])\n",
      "layer4.0.downsample.1 : torch.Size([512])\n",
      "layer4.1.conv1 : torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn1 : torch.Size([512])\n",
      "layer4.1.conv2 : torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2 : torch.Size([512])\n",
      "fc : torch.Size([1000, 512])\n",
      "Index: 0, Layer Name: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Index: 1, Layer Name: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 2, Layer Name: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 3, Layer Name: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 4, Layer Name: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Index: 5, Layer Name: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Index: 6, Layer Name: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 7, Layer Name: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 8, Layer Name: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Index: 9, Layer Name: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Index: 10, Layer Name: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 11, Layer Name: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 12, Layer Name: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Index: 13, Layer Name: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Index: 14, Layer Name: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 15, Layer Name: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 16, Layer Name: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Index: 17, Layer Name: fc.weight, Shape: torch.Size([1000, 512])\n",
      "Index: 18, Layer Name: fc.bias, Shape: torch.Size([1000])\n",
      "\n",
      "The number of input features is: 512\n",
      "Epoch:1/100\n",
      "----------\n",
      "train Loss: 0.7099 Acc: 0.5328\n",
      "val Loss: 0.5929 Acc: 0.6797\n",
      "\n",
      "Epoch:2/100\n",
      "----------\n",
      "train Loss: 0.5775 Acc: 0.7254\n",
      "val Loss: 0.4393 Acc: 0.8170\n",
      "\n",
      "Epoch:3/100\n",
      "----------\n",
      "train Loss: 0.5375 Acc: 0.7459\n",
      "val Loss: 0.3625 Acc: 0.8627\n",
      "\n",
      "Epoch:4/100\n",
      "----------\n",
      "train Loss: 0.4209 Acc: 0.8320\n",
      "val Loss: 0.3106 Acc: 0.8889\n",
      "\n",
      "Epoch:5/100\n",
      "----------\n",
      "train Loss: 0.4291 Acc: 0.8156\n",
      "val Loss: 0.2741 Acc: 0.9216\n",
      "\n",
      "Epoch:6/100\n",
      "----------\n",
      "train Loss: 0.4165 Acc: 0.8156\n",
      "val Loss: 0.2979 Acc: 0.9085\n",
      "\n",
      "Epoch:7/100\n",
      "----------\n",
      "train Loss: 0.4119 Acc: 0.7869\n",
      "val Loss: 0.2427 Acc: 0.9216\n",
      "\n",
      "Epoch:8/100\n",
      "----------\n",
      "train Loss: 0.3809 Acc: 0.8484\n",
      "val Loss: 0.2305 Acc: 0.9281\n",
      "\n",
      "Epoch:9/100\n",
      "----------\n",
      "train Loss: 0.4745 Acc: 0.7869\n",
      "val Loss: 0.2284 Acc: 0.9412\n",
      "\n",
      "Epoch:10/100\n",
      "----------\n",
      "train Loss: 0.4035 Acc: 0.8156\n",
      "val Loss: 0.2178 Acc: 0.9346\n",
      "\n",
      "Epoch:11/100\n",
      "----------\n",
      "train Loss: 0.3858 Acc: 0.8197\n",
      "val Loss: 0.2276 Acc: 0.9412\n",
      "\n",
      "Epoch:12/100\n",
      "----------\n",
      "train Loss: 0.3379 Acc: 0.8770\n",
      "val Loss: 0.2384 Acc: 0.9216\n",
      "\n",
      "Epoch:13/100\n",
      "----------\n",
      "train Loss: 0.4144 Acc: 0.7951\n",
      "val Loss: 0.2264 Acc: 0.9216\n",
      "\n",
      "Epoch:14/100\n",
      "----------\n",
      "train Loss: 0.3403 Acc: 0.8607\n",
      "val Loss: 0.2150 Acc: 0.9281\n",
      "\n",
      "Epoch:15/100\n",
      "----------\n",
      "train Loss: 0.3586 Acc: 0.8648\n",
      "val Loss: 0.2144 Acc: 0.9216\n",
      "\n",
      "Epoch:16/100\n",
      "----------\n",
      "train Loss: 0.3765 Acc: 0.8279\n",
      "val Loss: 0.2436 Acc: 0.9281\n",
      "\n",
      "Epoch:17/100\n",
      "----------\n",
      "train Loss: 0.3872 Acc: 0.8156\n",
      "val Loss: 0.2130 Acc: 0.9346\n",
      "\n",
      "Epoch:18/100\n",
      "----------\n",
      "train Loss: 0.3945 Acc: 0.8443\n",
      "val Loss: 0.2194 Acc: 0.9346\n",
      "\n",
      "Epoch:19/100\n",
      "----------\n",
      "train Loss: 0.3643 Acc: 0.8361\n",
      "val Loss: 0.2283 Acc: 0.9412\n",
      "\n",
      "Epoch:20/100\n",
      "----------\n",
      "train Loss: 0.3422 Acc: 0.8689\n",
      "val Loss: 0.2267 Acc: 0.9412\n",
      "\n",
      "Epoch:21/100\n",
      "----------\n",
      "train Loss: 0.3378 Acc: 0.8648\n",
      "val Loss: 0.2363 Acc: 0.9281\n",
      "\n",
      "Epoch:22/100\n",
      "----------\n",
      "train Loss: 0.3644 Acc: 0.8525\n",
      "val Loss: 0.2440 Acc: 0.9085\n",
      "\n",
      "Epoch:23/100\n",
      "----------\n",
      "train Loss: 0.3871 Acc: 0.7992\n",
      "val Loss: 0.2154 Acc: 0.9346\n",
      "\n",
      "Epoch:24/100\n",
      "----------\n",
      "train Loss: 0.3079 Acc: 0.8934\n",
      "val Loss: 0.2243 Acc: 0.9216\n",
      "\n",
      "Epoch:25/100\n",
      "----------\n",
      "train Loss: 0.3692 Acc: 0.8443\n",
      "val Loss: 0.2249 Acc: 0.9412\n",
      "\n",
      "Epoch:26/100\n",
      "----------\n",
      "train Loss: 0.3556 Acc: 0.8566\n",
      "val Loss: 0.2191 Acc: 0.9412\n",
      "\n",
      "Epoch:27/100\n",
      "----------\n",
      "train Loss: 0.3730 Acc: 0.8238\n",
      "val Loss: 0.2151 Acc: 0.9281\n",
      "\n",
      "Epoch:28/100\n",
      "----------\n",
      "train Loss: 0.2948 Acc: 0.8811\n",
      "val Loss: 0.2139 Acc: 0.9346\n",
      "\n",
      "Epoch:29/100\n",
      "----------\n",
      "train Loss: 0.3857 Acc: 0.8279\n",
      "val Loss: 0.2337 Acc: 0.9346\n",
      "\n",
      "Epoch:30/100\n",
      "----------\n",
      "train Loss: 0.3757 Acc: 0.8115\n",
      "val Loss: 0.2165 Acc: 0.9281\n",
      "\n",
      "Epoch:31/100\n",
      "----------\n",
      "train Loss: 0.3940 Acc: 0.8320\n",
      "val Loss: 0.2220 Acc: 0.9281\n",
      "\n",
      "Epoch:32/100\n",
      "----------\n",
      "train Loss: 0.4344 Acc: 0.7951\n",
      "val Loss: 0.2164 Acc: 0.9346\n",
      "\n",
      "Epoch:33/100\n",
      "----------\n",
      "train Loss: 0.3708 Acc: 0.8484\n",
      "val Loss: 0.2156 Acc: 0.9281\n",
      "\n",
      "Epoch:34/100\n",
      "----------\n",
      "train Loss: 0.3480 Acc: 0.8566\n",
      "val Loss: 0.2126 Acc: 0.9281\n",
      "\n",
      "Epoch:35/100\n",
      "----------\n",
      "train Loss: 0.4007 Acc: 0.8115\n",
      "val Loss: 0.2198 Acc: 0.9412\n",
      "\n",
      "Epoch:36/100\n",
      "----------\n",
      "train Loss: 0.3584 Acc: 0.8566\n",
      "val Loss: 0.2169 Acc: 0.9412\n",
      "\n",
      "Epoch:37/100\n",
      "----------\n",
      "train Loss: 0.3782 Acc: 0.8361\n",
      "val Loss: 0.2148 Acc: 0.9346\n",
      "\n",
      "Epoch:38/100\n",
      "----------\n",
      "train Loss: 0.3682 Acc: 0.8525\n",
      "val Loss: 0.2285 Acc: 0.9412\n",
      "\n",
      "Epoch:39/100\n",
      "----------\n",
      "train Loss: 0.3770 Acc: 0.8443\n",
      "val Loss: 0.2092 Acc: 0.9412\n",
      "\n",
      "Epoch:40/100\n",
      "----------\n",
      "train Loss: 0.3264 Acc: 0.8566\n",
      "val Loss: 0.2142 Acc: 0.9346\n",
      "\n",
      "Epoch:41/100\n",
      "----------\n",
      "train Loss: 0.4031 Acc: 0.8197\n",
      "val Loss: 0.2111 Acc: 0.9346\n",
      "\n",
      "Epoch:42/100\n",
      "----------\n",
      "train Loss: 0.3783 Acc: 0.8402\n",
      "val Loss: 0.2087 Acc: 0.9281\n",
      "\n",
      "Epoch:43/100\n",
      "----------\n",
      "train Loss: 0.3997 Acc: 0.7992\n",
      "val Loss: 0.2089 Acc: 0.9281\n",
      "\n",
      "Epoch:44/100\n",
      "----------\n",
      "train Loss: 0.3504 Acc: 0.8566\n",
      "val Loss: 0.2087 Acc: 0.9346\n",
      "\n",
      "Epoch:45/100\n",
      "----------\n",
      "train Loss: 0.3397 Acc: 0.8525\n",
      "val Loss: 0.2154 Acc: 0.9281\n",
      "\n",
      "Epoch:46/100\n",
      "----------\n",
      "train Loss: 0.3767 Acc: 0.8484\n",
      "val Loss: 0.2184 Acc: 0.9412\n",
      "\n",
      "Epoch:47/100\n",
      "----------\n",
      "train Loss: 0.3420 Acc: 0.8648\n",
      "val Loss: 0.2129 Acc: 0.9346\n",
      "\n",
      "Epoch:48/100\n",
      "----------\n",
      "train Loss: 0.3475 Acc: 0.8648\n",
      "val Loss: 0.2244 Acc: 0.9281\n",
      "\n",
      "Epoch:49/100\n",
      "----------\n",
      "train Loss: 0.3725 Acc: 0.8361\n",
      "val Loss: 0.2261 Acc: 0.9281\n",
      "\n",
      "Epoch:50/100\n",
      "----------\n",
      "train Loss: 0.3678 Acc: 0.8402\n",
      "val Loss: 0.2261 Acc: 0.9281\n",
      "\n",
      "Epoch:51/100\n",
      "----------\n",
      "train Loss: 0.3538 Acc: 0.8566\n",
      "val Loss: 0.2247 Acc: 0.9281\n",
      "\n",
      "Epoch:52/100\n",
      "----------\n",
      "train Loss: 0.4110 Acc: 0.7910\n",
      "val Loss: 0.2094 Acc: 0.9281\n",
      "\n",
      "Epoch:53/100\n",
      "----------\n",
      "train Loss: 0.3709 Acc: 0.8320\n",
      "val Loss: 0.2147 Acc: 0.9346\n",
      "\n",
      "Epoch:54/100\n",
      "----------\n",
      "train Loss: 0.3415 Acc: 0.8566\n",
      "val Loss: 0.2199 Acc: 0.9346\n",
      "\n",
      "Epoch:55/100\n",
      "----------\n",
      "train Loss: 0.3081 Acc: 0.8934\n",
      "val Loss: 0.2230 Acc: 0.9281\n",
      "\n",
      "Epoch:56/100\n",
      "----------\n",
      "train Loss: 0.3592 Acc: 0.8730\n",
      "val Loss: 0.2157 Acc: 0.9281\n",
      "\n",
      "Epoch:57/100\n",
      "----------\n",
      "train Loss: 0.3282 Acc: 0.8607\n",
      "val Loss: 0.2175 Acc: 0.9412\n",
      "\n",
      "Epoch:58/100\n",
      "----------\n",
      "train Loss: 0.3338 Acc: 0.8689\n",
      "val Loss: 0.2197 Acc: 0.9216\n",
      "\n",
      "Epoch:59/100\n",
      "----------\n",
      "train Loss: 0.3253 Acc: 0.8730\n",
      "val Loss: 0.2190 Acc: 0.9412\n",
      "\n",
      "Epoch:60/100\n",
      "----------\n",
      "train Loss: 0.3670 Acc: 0.8484\n",
      "val Loss: 0.2119 Acc: 0.9281\n",
      "\n",
      "Epoch:61/100\n",
      "----------\n",
      "train Loss: 0.3651 Acc: 0.8443\n",
      "val Loss: 0.2398 Acc: 0.9216\n",
      "\n",
      "Epoch:62/100\n",
      "----------\n",
      "train Loss: 0.3494 Acc: 0.8525\n",
      "val Loss: 0.2165 Acc: 0.9346\n",
      "\n",
      "Epoch:63/100\n",
      "----------\n",
      "train Loss: 0.3575 Acc: 0.8648\n",
      "val Loss: 0.2266 Acc: 0.9216\n",
      "\n",
      "Epoch:64/100\n",
      "----------\n",
      "train Loss: 0.3043 Acc: 0.8934\n",
      "val Loss: 0.2253 Acc: 0.9281\n",
      "\n",
      "Epoch:65/100\n",
      "----------\n",
      "train Loss: 0.3161 Acc: 0.8811\n",
      "val Loss: 0.2192 Acc: 0.9346\n",
      "\n",
      "Epoch:66/100\n",
      "----------\n",
      "train Loss: 0.3627 Acc: 0.8484\n",
      "val Loss: 0.2327 Acc: 0.9281\n",
      "\n",
      "Epoch:67/100\n",
      "----------\n",
      "train Loss: 0.3289 Acc: 0.8566\n",
      "val Loss: 0.2287 Acc: 0.9412\n",
      "\n",
      "Epoch:68/100\n",
      "----------\n",
      "train Loss: 0.3423 Acc: 0.8484\n",
      "val Loss: 0.2126 Acc: 0.9346\n",
      "\n",
      "Epoch:69/100\n",
      "----------\n",
      "train Loss: 0.3915 Acc: 0.8238\n",
      "val Loss: 0.2217 Acc: 0.9281\n",
      "\n",
      "Epoch:70/100\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8484\n",
      "val Loss: 0.2158 Acc: 0.9281\n",
      "\n",
      "Epoch:71/100\n",
      "----------\n",
      "train Loss: 0.3665 Acc: 0.8443\n",
      "val Loss: 0.2303 Acc: 0.9281\n",
      "\n",
      "Epoch:72/100\n",
      "----------\n",
      "train Loss: 0.3736 Acc: 0.8607\n",
      "val Loss: 0.2166 Acc: 0.9346\n",
      "\n",
      "Epoch:73/100\n",
      "----------\n",
      "train Loss: 0.3924 Acc: 0.8402\n",
      "val Loss: 0.2180 Acc: 0.9281\n",
      "\n",
      "Epoch:74/100\n",
      "----------\n",
      "train Loss: 0.3760 Acc: 0.8279\n",
      "val Loss: 0.2416 Acc: 0.9150\n",
      "\n",
      "Epoch:75/100\n",
      "----------\n",
      "train Loss: 0.3842 Acc: 0.8484\n",
      "val Loss: 0.2359 Acc: 0.9216\n",
      "\n",
      "Epoch:76/100\n",
      "----------\n",
      "train Loss: 0.3245 Acc: 0.8811\n",
      "val Loss: 0.2373 Acc: 0.9281\n",
      "\n",
      "Epoch:77/100\n",
      "----------\n",
      "train Loss: 0.3143 Acc: 0.8770\n",
      "val Loss: 0.2172 Acc: 0.9281\n",
      "\n",
      "Epoch:78/100\n",
      "----------\n",
      "train Loss: 0.3495 Acc: 0.8402\n",
      "val Loss: 0.2219 Acc: 0.9281\n",
      "\n",
      "Epoch:79/100\n",
      "----------\n",
      "train Loss: 0.4290 Acc: 0.7869\n",
      "val Loss: 0.2175 Acc: 0.9281\n",
      "\n",
      "Epoch:80/100\n",
      "----------\n",
      "train Loss: 0.3731 Acc: 0.8361\n",
      "val Loss: 0.2141 Acc: 0.9346\n",
      "\n",
      "Epoch:81/100\n",
      "----------\n",
      "train Loss: 0.3422 Acc: 0.8689\n",
      "val Loss: 0.2179 Acc: 0.9346\n",
      "\n",
      "Epoch:82/100\n",
      "----------\n",
      "train Loss: 0.3253 Acc: 0.8607\n",
      "val Loss: 0.2376 Acc: 0.9216\n",
      "\n",
      "Epoch:83/100\n",
      "----------\n",
      "train Loss: 0.4364 Acc: 0.8279\n",
      "val Loss: 0.2226 Acc: 0.9346\n",
      "\n",
      "Epoch:84/100\n",
      "----------\n",
      "train Loss: 0.3613 Acc: 0.8320\n",
      "val Loss: 0.2163 Acc: 0.9346\n",
      "\n",
      "Epoch:85/100\n",
      "----------\n",
      "train Loss: 0.3679 Acc: 0.8484\n",
      "val Loss: 0.2411 Acc: 0.9281\n",
      "\n",
      "Epoch:86/100\n",
      "----------\n",
      "train Loss: 0.4173 Acc: 0.8443\n",
      "val Loss: 0.2173 Acc: 0.9216\n",
      "\n",
      "Epoch:87/100\n",
      "----------\n",
      "train Loss: 0.3728 Acc: 0.8320\n",
      "val Loss: 0.2154 Acc: 0.9281\n",
      "\n",
      "Epoch:88/100\n",
      "----------\n",
      "train Loss: 0.3315 Acc: 0.8402\n",
      "val Loss: 0.2220 Acc: 0.9412\n",
      "\n",
      "Epoch:89/100\n",
      "----------\n",
      "train Loss: 0.3507 Acc: 0.8525\n",
      "val Loss: 0.2216 Acc: 0.9281\n",
      "\n",
      "Epoch:90/100\n",
      "----------\n",
      "train Loss: 0.3610 Acc: 0.8402\n",
      "val Loss: 0.2170 Acc: 0.9412\n",
      "\n",
      "Epoch:91/100\n",
      "----------\n",
      "train Loss: 0.3776 Acc: 0.8361\n",
      "val Loss: 0.2115 Acc: 0.9346\n",
      "\n",
      "Epoch:92/100\n",
      "----------\n",
      "train Loss: 0.3816 Acc: 0.8279\n",
      "val Loss: 0.2214 Acc: 0.9216\n",
      "\n",
      "Epoch:93/100\n",
      "----------\n",
      "train Loss: 0.3463 Acc: 0.8648\n",
      "val Loss: 0.2136 Acc: 0.9346\n",
      "\n",
      "Epoch:94/100\n",
      "----------\n",
      "train Loss: 0.3272 Acc: 0.8770\n",
      "val Loss: 0.2256 Acc: 0.9346\n",
      "\n",
      "Epoch:95/100\n",
      "----------\n",
      "train Loss: 0.3498 Acc: 0.8402\n",
      "val Loss: 0.2155 Acc: 0.9346\n",
      "\n",
      "Epoch:96/100\n",
      "----------\n",
      "train Loss: 0.3676 Acc: 0.8402\n",
      "val Loss: 0.2203 Acc: 0.9346\n",
      "\n",
      "Epoch:97/100\n",
      "----------\n",
      "train Loss: 0.3304 Acc: 0.8484\n",
      "val Loss: 0.2121 Acc: 0.9281\n",
      "\n",
      "Epoch:98/100\n",
      "----------\n",
      "train Loss: 0.3849 Acc: 0.8320\n",
      "val Loss: 0.2191 Acc: 0.9216\n",
      "\n",
      "Epoch:99/100\n",
      "----------\n",
      "train Loss: 0.3555 Acc: 0.8402\n",
      "val Loss: 0.2203 Acc: 0.9281\n",
      "\n",
      "Epoch:100/100\n",
      "----------\n",
      "train Loss: 0.3267 Acc: 0.8648\n",
      "val Loss: 0.2167 Acc: 0.9281\n",
      "\n",
      "Training complete in 2m 8s\n",
      "Best val Acc: 0.9412\n"
     ]
    }
   ],
   "source": [
    "model=models.resnet18(pretrained=True) # The optimized weight trained in ImageNet\n",
    "model.to(device)\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=images[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "# Freeze all the layers in the network as a second option of the model pretraining\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "# We can keep unfreeze the last two  layers\n",
    "# The parameters of the layers are typically organized as: (weight, bias), hence we'll need to \"unfreeze\" 4 parameters for 2 layers\n",
    "#parameters = list(model.parameters())\n",
    "#parameters[-4].requires_grad = True  # Unfreeze weights of the second last layer\n",
    "#parameters[-3].requires_grad = True  # Unfreeze bias of the second last layer\n",
    "#parameters[-2].requires_grad = True  # Unfreeze weights of the last layer\n",
    "#parameters[-1].requires_grad = True  # Unfreeze bias of the last layer\n",
    "    \n",
    "\n",
    " \n",
    "# Unfreeze the last convolutional layer of the last convolutional block\n",
    "#model.layer4[1].conv2.weight.requires_grad = True # Note: Not all models have the same architecture or have a bias layer\n",
    "\n",
    "\n",
    "\n",
    "# Unfreeze the last convolutional layer of each convolutional block\n",
    "model.layer1[1].conv2.weight.requires_grad = True\n",
    "model.layer2[1].conv2.weight.requires_grad = True\n",
    "model.layer3[1].conv2.weight.requires_grad = True\n",
    "model.layer4[1].conv2.weight.requires_grad = True\n",
    "\n",
    "\n",
    "# Print all layes of the model\n",
    "for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "    print(f\"Index: {idx}, Layer Name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print('')\n",
    "\n",
    "# Iterate through the named modules to print teh layers that have weights\n",
    "for name, module in model.named_modules():\n",
    "    # Check if the module has weight attribute to get its shape\n",
    "    if hasattr(module, 'weight') and hasattr(module.weight, 'shape'):\n",
    "        print(name, \":\", module.weight.shape)\n",
    "        \n",
    "# print only the layers that perform convolution\n",
    "\n",
    "index = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if \"conv\" in name or 'fc' in name:\n",
    "        print(f\"Index: {index}, Layer Name: {name}, Shape: {param.shape}\")\n",
    "        index += 1\n",
    "print('')        \n",
    "\n",
    "\n",
    "# get the number of input feature from the last layer\n",
    "num_features=model.fc.in_features # fc is the last layer in the model\n",
    "print(f'The number of input features is: {num_features}')\n",
    "\n",
    "\n",
    "# Create a new layer and assign it to teh last layer\n",
    "model.fc=nn.Linear(num_features,2) # we inserted a new fully connected layer with a dimensionality of 2 is the number of classes\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "loss=nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001)\n",
    "\n",
    "NUM_EPOCHS=250\n",
    "\n",
    "# scheduler for LR updates\n",
    "step_lr_sceduler=optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1) # the LR will be reduced by a factor of 10 percent every 10 epochs\n",
    "\n",
    "# Calling training function\n",
    "model=train_model(model,loss,optimizer,step_lr_sceduler,num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
