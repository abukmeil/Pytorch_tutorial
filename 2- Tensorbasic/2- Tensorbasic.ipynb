{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors \n",
    "## <span style='color:yellow'>In this tutorial, we will explore how to manipulate tensors and perform basic operations.</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch and Numpy Conversion \n",
    "## <span style='color:yellow'>PyTorch primarily relies on tensor operations.</span>\n",
    "## <span style='color:yellow'>In numpy, data is represented as vectors and arrays.</span>\n",
    "## <span style='color:yellow'> PyTorch represents data as tensors that can exist in different dimensions, such as 1-D, 2-D, 3-D, and so forth.</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating tensors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6590e-24])\n",
      "tensor([0.0000e+00, 6.7262e-44, 1.0563e-05])\n",
      "tensor([[1.4727e-34, 0.0000e+00, 1.6598e-37],\n",
      "        [0.0000e+00, 8.9683e-44, 0.0000e+00]])\n",
      "tensor([[1.4610e-34, 0.0000e+00, 1.6649e-37],\n",
      "        [0.0000e+00, 4.4842e-44, 0.0000e+00]])\n",
      "tensor([[[1.4903e-34, 0.0000e+00, 1.6590e-24],\n",
      "         [4.5758e-41, 8.9683e-44, 0.0000e+00]],\n",
      "\n",
      "        [[1.1210e-43, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty tensor with a scalar value, actuly it contains random values \n",
    "import torch\n",
    "x=torch.empty(1)\n",
    "print(x)\n",
    "\n",
    "# Cretaing 1-d vector with three elements\n",
    "x=torch.empty(3)\n",
    "print(x)\n",
    "\n",
    "# Cretaing an array of 2 rows and 3 columns\n",
    "x=torch.empty(2,3)\n",
    "print(x)\n",
    "\n",
    "# Cretaing an array of 2 rows and 3 columns with size keyword\n",
    "x=torch.empty(size=(2,3))\n",
    "print(x)\n",
    "\n",
    "# Cretaing 3-d tensor\n",
    "x=torch.empty(2,2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5900, 0.3172, 0.0128],\n",
      "        [0.6074, 0.6437, 0.7279],\n",
      "        [0.8216, 0.2308, 0.4287]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor with random float values\n",
    "x=torch.rand(3,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a zero tensor\n",
    "x=torch.zeros(3,3)\n",
    "print(x)\n",
    "print(\"\")\n",
    "# Creating a tensor of ones\n",
    "x=torch.ones(3,3)\n",
    "print(x)\n",
    "print(\"\")\n",
    "\n",
    "# Creating a tensor of identity matrix, I=eye\n",
    "x=torch.eye(3,3)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "\n",
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor for a range of values\n",
    "x=torch.arange(start=0,end=5,step=1)  # 5 is execluded\n",
    "print(x)\n",
    "print(\"\")\n",
    "\n",
    "# Creating a tensor with a range of linearly-spaced values\n",
    "x=torch.linspace(start=0.1,end=1,steps=10)  # 1 is included\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9420,  0.3974,  0.1368],\n",
      "        [ 0.9126, -0.5145, -0.1995],\n",
      "        [ 1.0370,  0.0701,  0.4484]])\n",
      "tensor([[0.9256, 0.5714, 1.0000],\n",
      "        [0.6685, 0.0617, 0.9041],\n",
      "        [0.0899, 0.8458, 0.1956]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([5, 5, 5, 5, 5, 5])\n",
      "tensor([[5, 0, 0, 0, 0],\n",
      "        [0, 5, 0, 0, 0],\n",
      "        [0, 0, 5, 0, 0],\n",
      "        [0, 0, 0, 5, 0],\n",
      "        [0, 0, 0, 0, 5]])\n",
      "tensor([[5, 5, 5],\n",
      "        [5, 5, 5],\n",
      "        [5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "# Creating and empty tensor and then filling it with random values\n",
    "x=torch.empty(size=(3,3)).normal_(mean=0,std=1)\n",
    "print(x)\n",
    "\n",
    "# Creating and empty tensor and then filling it with uniform distribution with a range of 0 to 1\n",
    "x=torch.empty(size=(3,3)).uniform_(0,1)\n",
    "print(x)\n",
    "\n",
    "# Craeting a tensor with ones in the diagonal and zeros elsewhere (same as torch.eye)\n",
    "x=torch.diag(torch.ones(5))\n",
    "print(x)\n",
    "\n",
    "# Creating a tensor with repeated values\n",
    "x=torch.full((6,),5)\n",
    "print(x)\n",
    "\n",
    "# Creating a diagonla matrix with values of 5 at the diagonal\n",
    "x=torch.diag(torch.full((5,),5))\n",
    "print(x)\n",
    "\n",
    "# Creating a 2-D matrix and fill it with\n",
    "x=torch.full((3,3),5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      " \n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      " \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float16)\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The default data type is float32, but we can change that to any data type.\n",
    "print(x.dtype)\n",
    "print(\" \")\n",
    "\n",
    "# Create a tensor with int values\n",
    "x=torch.ones(3,3,dtype=torch.int)\n",
    "print(x)\n",
    "print(\" \")\n",
    "# Create a tensor with float16 values\n",
    "x=torch.ones(3,3,dtype=torch.float16)\n",
    "print(x)\n",
    "print(x.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True,  True])\n",
      "tensor([0, 1, 2, 3, 4], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0., 1., 2., 3., 4.], dtype=torch.float16)\n",
      "tensor([0., 1., 2., 3., 4.])\n",
      "tensor([0., 1., 2., 3., 4.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Converting a tensor to boolean tensor\n",
    "x=torch.arange(0,5)\n",
    "print(x.bool())\n",
    "print(x.short())  # int16  Not used too much\n",
    "print(x.long())   # int64  Not used too much\n",
    "print(x.half())   # float16 if you want to train with less precision\n",
    "print(x.float())  # float32\n",
    "print(x.double()) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 2.3000])\n",
      "tensor([[2.5000, 2.3000],\n",
      "        [3.5000, 3.3000]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a tensor form data, e.g., a list\n",
    "x=torch.tensor([2.5,2.3])\n",
    "print(x)\n",
    "\n",
    "# Construct a tensor form data, with two rowa and three columns\n",
    "x=torch.tensor([[2.5,2.3],[3.5,3.3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1548, 0.0867, 0.3322],\n",
      "        [0.7407, 0.8050, 0.4341],\n",
      "        [0.6616, 0.0183, 0.0089]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a tensor form uniform distribution\n",
    "x=torch.rand(3,3)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8425, 0.6785, 0.7375],\n",
      "        [0.1565, 0.1295, 0.9566],\n",
      "        [0.4427, 0.7676, 0.4728]])\n",
      "\n",
      "tensor([[0.7086, 0.4885, 0.7117],\n",
      "        [0.1611, 0.0394, 0.5918],\n",
      "        [0.8605, 0.5656, 0.8052]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(3,3)\n",
    "y=torch.rand(3,3)\n",
    "\n",
    "print(x); print(\"\"), print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2682, 0.8829, 1.5025],\n",
      "        [1.2687, 0.9427, 1.1500],\n",
      "        [0.4149, 1.5328, 0.1432]])\n",
      " \n",
      "tensor([[1.2682, 0.8829, 1.5025],\n",
      "        [1.2687, 0.9427, 1.1500],\n",
      "        [0.4149, 1.5328, 0.1432]])\n",
      "\n",
      "tensor([[1.2682, 0.8829, 1.5025],\n",
      "        [1.2687, 0.9427, 1.1500],\n",
      "        [0.4149, 1.5328, 0.1432]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "z=x+y\n",
    "print(z)\n",
    "print(\" \")\n",
    "\n",
    "# Alternative addition\n",
    "z=torch.add(x,y)\n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "# Inplace addition\n",
    "y.add_(x)  # Note in the Pytorch any method that contains trailing _ is applied in place.\n",
    "print(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6917, -0.6036, -0.5631],\n",
      "        [-0.5804, -0.1175, -0.4490],\n",
      "        [-0.2280, -0.7360, -0.0334]])\n"
     ]
    }
   ],
   "source": [
    "# Subtraction\n",
    "z=x-y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1890, 1.3890, 1.0362],\n",
      "        [0.9716, 3.2850, 1.6164],\n",
      "        [0.5144, 1.3572, 0.5872]])\n",
      "\n",
      "tensor([[1.1890, 1.3890, 1.0362],\n",
      "        [0.9716, 3.2850, 1.6164],\n",
      "        [0.5144, 1.3572, 0.5872]])\n"
     ]
    }
   ],
   "source": [
    "# division\n",
    "z=x/y\n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "# Alternative division\n",
    "z=torch.true_divide(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5970, 0.3315, 0.5249],\n",
      "        [0.0252, 0.0051, 0.5662],\n",
      "        [0.3809, 0.4342, 0.3807]])\n",
      "\n",
      "tensor([[0.5970, 0.3315, 0.5249],\n",
      "        [0.0252, 0.0051, 0.5662],\n",
      "        [0.3809, 0.4342, 0.3807]])\n",
      "tensor([[1.3409, 0.8554, 1.5950],\n",
      "        [0.9550, 0.6226, 0.9583],\n",
      "        [0.8442, 0.5139, 1.1501]])\n"
     ]
    }
   ],
   "source": [
    "# Multiplication (element wise multiplication)\n",
    "z= x*y\n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "z=torch.mul(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3409, 0.8554, 1.5950],\n",
      "        [0.9550, 0.6226, 0.9583],\n",
      "        [0.8442, 0.5139, 1.1501]])\n",
      "\n",
      "tensor([[1.3409, 0.8554, 1.5950],\n",
      "        [0.9550, 0.6226, 0.9583],\n",
      "        [0.8442, 0.5139, 1.1501]])\n",
      "\n",
      "tensor([[1.3409, 0.8554, 1.5950],\n",
      "        [0.9550, 0.6226, 0.9583],\n",
      "        [0.8442, 0.5139, 1.1501]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "'''\n",
    "Dot Product: The dot product of two vectors b (often represented as \n",
    "a⋅b) is a scalar (a single number) obtained by multiplying the corresponding entries of the two vectors and then summing those products.\n",
    "Matrix Multiplication: Matrix multiplication involves taking the dot products of rows of the first matrix with the columns of the second matrix. \n",
    "\n",
    "In general, matrix multiplication can be seen as an extension of the dot product concept,\n",
    "transitioning from operations between vectors to operations between matrices\n",
    "'''\n",
    "z=torch.mm(x,y)  \n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "z=x.mm(y)  \n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "z=x@y\n",
    "print(z)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7098, 0.4604, 0.5439],\n",
      "        [0.0245, 0.0168, 0.9152],\n",
      "        [0.1960, 0.5892, 0.2236]])\n",
      "\n",
      "tensor([[0.7098, 0.4604, 0.5439],\n",
      "        [0.0245, 0.0168, 0.9152],\n",
      "        [0.1960, 0.5892, 0.2236]])\n"
     ]
    }
   ],
   "source": [
    "# Exponentiation\n",
    "# Elemnt wise exponentiation\n",
    "z=x.pow(2)\n",
    "print(z)\n",
    "print(\"\")\n",
    "# Alternative\n",
    "z=x**2\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.0744, 10.6624, 13.7826],\n",
      "        [ 4.6985,  5.5344,  7.1115],\n",
      "        [ 6.2134,  7.2940,  9.4534]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix exponentiation (e.g., e^x) not element wise\n",
    "z=x.matrix_power(6) # like consider multiplying x by itself 6 times\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8994)\n"
     ]
    }
   ],
   "source": [
    "# Dot product: Element-wise multiplication between two vectors, then sum all the elements \n",
    "x_=torch.rand(5)\n",
    "y_=torch.rand(5)\n",
    "z_=torch.dot(x_,y_)\n",
    "print(z_) # It is a scalar, i.e., the sum of teh product of the elements of x_ and y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 20])\n",
      "\n",
      "torch.Size([32, 10, 20])\n",
      "\n",
      "torch.Size([32, 10, 10])\n",
      "torch.Size([32, 10, 20])\n",
      "\n",
      "torch.Size([32, 20, 30])\n",
      "\n",
      "torch.Size([32, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "# Batch matrix multiplication: will have three dimensions and the first dimension will be the batch size\n",
    "\n",
    "batch=32\n",
    "m=10\n",
    "n=20\n",
    "x_=torch.rand(batch,m,n)\n",
    "print(x_.shape)\n",
    "print(\"\")\n",
    "\n",
    "y_=torch.rand(batch,m,n)\n",
    "print(y_.shape)\n",
    "print(\"\")\n",
    "\n",
    "z_=torch.bmm(x_,y_.transpose(1,2)) # transpose(1,2) means transpose the second and third dimensions\n",
    "print(z_.shape)\n",
    "\n",
    "\n",
    "# Anothe example of batch matrix multiplication\n",
    "m=10\n",
    "n=20\n",
    "p=30\n",
    "x_=torch.rand(batch,m,n)\n",
    "print(x_.shape)\n",
    "print(\"\")\n",
    "\n",
    "y_=torch.rand(batch,n,p)\n",
    "print(y_.shape)\n",
    "print(\"\")\n",
    "\n",
    "z_=torch.bmm(x_,y_)\n",
    "print(z_.shape)  # The result shape is (batch,m,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7563, -0.4522,  0.0286,  0.3471,  0.1631,  0.1275,  0.0258],\n",
      "        [ 0.1677, -0.0206, -0.0339, -0.3295,  0.1852, -0.2167,  0.0493],\n",
      "        [-0.1145, -0.1452,  0.1168,  0.0798,  0.0321, -0.1144,  0.2216],\n",
      "        [ 0.0217, -0.4696, -0.2065,  0.4021, -0.1430, -0.4055,  0.8285],\n",
      "        [-0.4057, -0.3355,  0.2379, -0.1755, -0.0353, -0.2844,  0.5057],\n",
      "        [ 0.0780, -0.6872,  0.1508,  0.2999,  0.2472, -0.6879,  0.3021],\n",
      "        [ 0.2134,  0.2083,  0.4940,  0.0635,  0.7313, -0.3155,  0.3513]])\n",
      "\n",
      "tensor([[ 0., -1., -2.],\n",
      "        [ 0., -1., -2.],\n",
      "        [ 0., -1., -2.],\n",
      "        [ 0., -1., -2.],\n",
      "        [ 0., -1., -2.]])\n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting: It is a way of making the tensor of different shapes compatible for element wise operations\n",
    "x_=torch.rand((7,7))\n",
    "y_=torch.rand((1,7))\n",
    "\n",
    "z=x_-y_\n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "x_ = torch.ones(5, 3)\n",
    "y_ = torch.tensor([1, 2, 3])\n",
    "z_ = x_ - y_  # y_ is broadcasted to match the shape of B.\n",
    "print(z_)\n",
    "print(\"\")\n",
    "\n",
    "z_=x_**y_\n",
    "print(z_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [ True,  True, False],\n",
      "        [ True, False, False]])\n",
      "\n",
      "tensor([False, False, False,  True,  True])\n",
      "\n",
      "tensor([False, False, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "# Simple comparison (element wise comparison)\n",
    "z=x>0.5 # we can use any comparison operator\n",
    "print(z)\n",
    "print(\"\")\n",
    "# Comparison of two tensors\n",
    "x=torch.tensor([1,2,3,4,5])\n",
    "y=torch.tensor([6,7,2,4,5])\n",
    "print(x.eq(y)) # element wise comparison\n",
    "print(\"\")\n",
    "print(torch.eq(x,y)) # element wise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7613, 1.2500, 1.6376])\n",
      "\n",
      "tensor([0.7960, 0.6951, 0.6432])\n",
      "tensor([0, 1, 0])\n",
      "\n",
      "tensor([0, 1, 0])\n",
      "\n",
      "tensor([0.4439, 0.1717, 0.4159])\n",
      "tensor([2, 0, 2])\n",
      "\n",
      "tensor([2, 0, 2])\n",
      "\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Summing all the elements of a tensor\n",
    "x=torch.rand(3,3)\n",
    "sum_x=torch.sum(x,dim=0) # sum along the rows\n",
    "print(sum_x)\n",
    "print(\"\")\n",
    "\n",
    "# Maxiumn value of a tensor\n",
    "vals,idxs=torch.max(x,dim=0) # Max along the rows\n",
    "print(vals)\n",
    "print(idxs)\n",
    "print(\"\")\n",
    "\n",
    "# argmax returns the index of the maximum value as torch.max \n",
    "idxs=torch.argmax(x,dim=0) \n",
    "print(idxs)\n",
    "print(\"\")\n",
    "\n",
    "# Minimum value of a tensor\n",
    "vals,idxs=torch.min(x,dim=0) # Min along the rows\n",
    "print(vals)\n",
    "print(idxs)\n",
    "print(\"\")\n",
    "\n",
    "# argmin returns the index of the minimum value as as torch.min\n",
    "idxs=torch.argmin(x,dim=0) \n",
    "print(idxs)\n",
    "print(\"\")\n",
    "\n",
    "# Absolute value\n",
    "x=torch.tensor([-1,-2,3,4,-5])\n",
    "print(torch.abs(x))\n",
    "print(\"\")\n",
    "\n",
    "# Mean value of a tensor: Note that the values should be float\n",
    "x=torch.tensor([1.,2,3,4,5])\n",
    "z=torch.mean(x.float(),dim=0)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2813, 0.6537, 0.5260],\n",
      "        [0.5614, 0.7041, 0.6153],\n",
      "        [0.3806, 0.2670, 0.5228],\n",
      "        [0.4200, 0.4503, 0.7490],\n",
      "        [0.2669, 0.4182, 0.9161]])\n",
      " \n",
      "tensor([[0.2813, 0.6537, 0.5260],\n",
      "        [0.5614, 0.7041, 0.6153],\n",
      "        [0.3806, 0.2670, 0.5228],\n",
      "        [0.4200, 0.4503, 0.7490],\n",
      "        [0.2669, 0.4182, 0.9161]])\n",
      "\n",
      "tensor([0.2813, 0.5614, 0.3806, 0.4200, 0.2669])\n",
      "\n",
      "tensor([0.2813, 0.6537, 0.5260])\n",
      "\n",
      "0.6153056025505066\n"
     ]
    }
   ],
   "source": [
    "# Slicing and indexing operation\n",
    "x=torch.rand(5,3)\n",
    "print(x)\n",
    "print(\" \")\n",
    "print(x[:])\n",
    "print(\"\")\n",
    "\n",
    "# Printing the first column of data\n",
    "print(x[:,0])\n",
    "print(\"\")\n",
    "\n",
    "# Printing the first row of data\n",
    "print(x[0,:])\n",
    "print('')\n",
    "# Unpacking the value of a tensor of one item of one tensor\n",
    "print(x[1,2].item())\n",
    "# The above method is used with a tensor of one item only to be converted into python scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8301, 0.9952, 0.6584, 0.9640, 0.6179, 0.6423, 0.7284, 0.2951, 0.8792,\n",
      "        0.1873, 0.8834, 0.4428, 0.6125, 0.9796, 0.7261, 0.0301, 0.3052, 0.6889,\n",
      "        0.5245, 0.5986])\n",
      "\n",
      "torch.Size([20])\n",
      "\n",
      "tensor([0.8301, 0.2297, 0.2424, 0.1125, 0.8853, 0.4135, 0.9356, 0.3309, 0.8056,\n",
      "        0.1464, 0.8970, 0.6053, 0.4129, 0.9959, 0.3379])\n",
      "\n",
      "tensor([9.9990e+03, 9.9521e-01, 6.5839e-01, 9.6399e-01, 6.1795e-01, 6.4226e-01,\n",
      "        7.2838e-01, 2.9513e-01, 8.7923e-01, 1.8730e-01, 8.8343e-01, 4.4280e-01,\n",
      "        6.1246e-01, 9.7959e-01, 7.2606e-01, 3.0144e-02, 3.0516e-01, 6.8890e-01,\n",
      "        5.2452e-01, 5.9855e-01])\n"
     ]
    }
   ],
   "source": [
    "batch_size=15\n",
    "features=20\n",
    "x=torch.rand(batch_size,features)\n",
    "# To show the first sample of the batch\n",
    "print(x[0]) # = x[0,:]\n",
    "print(\"\")\n",
    "\n",
    "# To show the shape of the first sample of the batch\n",
    "print(x[0].shape)\n",
    "print(\"\")\n",
    "# To see the first feature over all samples\n",
    "print(x[:,0])\n",
    "print(\"\")\n",
    "# Feature value update\n",
    "x[0,0]=9999\n",
    "print(x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6, 8])\n",
      "\n",
      "tensor([0.3885, 0.3524, 0.9628])\n",
      "\n",
      "tensor([ 0,  1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "\n",
      "tensor([], dtype=torch.int64)\n",
      " \n",
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n"
     ]
    }
   ],
   "source": [
    "# Fancy indexing\n",
    "x=torch.arange(15)\n",
    "idxs=[2,4,6,8]\n",
    "print(x[idxs])\n",
    "print(\"\")\n",
    "\n",
    "x=torch.rand(10,10)\n",
    "rows= torch.tensor([1,2,3])\n",
    "columns=torch.tensor([1,5,3])\n",
    "print(x[rows,columns])\n",
    "print(\"\")\n",
    "\n",
    "# Advanced Indexing\n",
    "x=torch.arange(20)\n",
    "print(x[(x<2) | (x>9)]) # pick values that  < 2 OR > 9\n",
    "print(\"\")\n",
    "\n",
    "print(x[(x<2) & (x>9)]) # pick values that  < 2 AND > 9\n",
    "print(\" \")\n",
    "\n",
    "# Modulos sclicing\n",
    "print(x[x.remainder(2)==0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.5000,  1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  7.0000,\n",
      "         8.0000,  9.0000, 10.0000, 11.0000, 12.0000, 13.0000, 14.0000, 15.0000,\n",
      "        16.0000, 17.0000, 18.0000, 19.0000])\n"
     ]
    }
   ],
   "source": [
    "#  The 'where' operation is used to verify the value and update the value if a condition is met\n",
    "x=torch.arange(20)\n",
    "print(torch.where(x>6,x,x/2)) # if x>6 then x else x/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "\n",
      "3\n",
      "\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# Unique operation\n",
    "x=torch.tensor([0,1,2,3,4,4,5,5,6,0,1,2])\n",
    "print(x.unique())\n",
    "print(\"\")\n",
    "\n",
    "# ndimension\n",
    "x=torch.rand((5,3,5))\n",
    "print(x.ndimension())\n",
    "print(\"\")\n",
    "\n",
    "# Counting the number of elements in a tensor (useful to check how many weighs parameters in a neural network)\n",
    "print(x.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2080, 0.7496, 0.3791, 0.2435],\n",
      "        [0.1031, 0.8237, 0.8971, 0.0366],\n",
      "        [0.5213, 0.7330, 0.5563, 0.6467],\n",
      "        [0.7369, 0.0575, 0.1787, 0.1076]])\n",
      "\n",
      "\n",
      "tensor([[0.1031, 0.0575, 0.1787, 0.0366],\n",
      "        [0.2080, 0.7330, 0.3791, 0.1076],\n",
      "        [0.5213, 0.7496, 0.5563, 0.2435],\n",
      "        [0.7369, 0.8237, 0.8971, 0.6467]])\n"
     ]
    }
   ],
   "source": [
    "# Sorting tensor\n",
    "x=torch.rand(4,4)\n",
    "print(x)\n",
    "print(\"\")\n",
    "sorted_val, idxs=torch.sort(x,dim=0,descending=False) # sort along the rows\n",
    "print(\"\")\n",
    "print(sorted_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2080, 0.7496, 0.3791, 0.2435],\n",
      "        [0.1031, 0.8237, 0.8971, 0.0366],\n",
      "        [0.5213, 0.7330, 0.5563, 0.6467],\n",
      "        [0.7369, 0.0575, 0.1787, 0.1076]])\n",
      "\n",
      "tensor([[0.2080, 0.7496, 0.3791, 0.2435],\n",
      "        [0.2000, 0.8237, 0.8971, 0.2000],\n",
      "        [0.5213, 0.7330, 0.5563, 0.6467],\n",
      "        [0.7369, 0.2000, 0.2000, 0.2000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking all elements of a tensor are  less than a value (e.g 0) and fill them to 0 ( if you set min=0.3 then all nums <0.3 will be filled with 0.3) will be filled with 0.3) \n",
    "z=torch.clamp(x,min=0)  # The same for max\n",
    "print(z)\n",
    "print(\"\")\n",
    "\n",
    "z=torch.clamp(x,min=0.2)\n",
    "print(z)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "# any condition if any value is true then it will return true\n",
    "x=torch.tensor([1,0,1,0,1],dtype=torch.bool)\n",
    "z=torch.any(x)\n",
    "print(z)\n",
    "\n",
    "# all condition if all values are true then it will return true\n",
    "z= torch.all(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1047, 0.5071, 0.0542, 0.3330],\n",
      "        [0.8789, 0.9451, 0.8701, 0.3063],\n",
      "        [0.7993, 0.7721, 0.3849, 0.9517],\n",
      "        [0.4460, 0.6858, 0.4334, 0.4663]])\n",
      " \n",
      "tensor([0.1047, 0.5071, 0.0542, 0.3330, 0.8789, 0.9451, 0.8701, 0.3063, 0.7993,\n",
      "        0.7721, 0.3849, 0.9517, 0.4460, 0.6858, 0.4334, 0.4663])\n",
      " \n",
      "tensor([[0.4649, 0.7464],\n",
      "        [0.4141, 0.8326],\n",
      "        [0.0027, 0.7936],\n",
      "        [0.4572, 0.6388],\n",
      "        [0.8123, 0.3690],\n",
      "        [0.0588, 0.7176],\n",
      "        [0.6422, 0.4016],\n",
      "        [0.5986, 0.0438],\n",
      "        [0.8627, 0.5596]])\n",
      " \n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping tensor\n",
    "x=torch.rand(4,4)\n",
    "print(x)\n",
    "print(\" \")\n",
    "y=x.view(16)\n",
    "print(y)\n",
    "print(\" \")\n",
    "\n",
    "x=torch.rand(18)\n",
    "y=x.view(9,2)  \n",
    "print(y)\n",
    "print(\" \")\n",
    "\n",
    "# reshape is used to reshape a tensor also. The 'view' is used more often and with contiguous memory (adjacent and in sequential order)\n",
    "x=torch.arange(25)\n",
    "y=x.reshape(5,5)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "\n",
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n",
      "\n",
      "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(9) # Contiguous (adjacent) memory involves ordered and adjacent values stored in memory\n",
    "print(x) \n",
    "y=x.view(3,3)\n",
    "print(y)\n",
    "\n",
    "print(y)\n",
    "print(\"\")\n",
    "\n",
    "# apply transpose\n",
    "y_=y.t()      # Non contiguous memory involves ordered and non adjacent values stored in memory\n",
    "print(y_)\n",
    "print(\"\")\n",
    "#print(y_.view(9)) # This will give an error because the memory is not contiguous\n",
    "# To reshap it \n",
    "print(y_.contiguous().view(9)) # This will work because the memory is contiguous now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2328, 0.2444, 0.0055, 0.4042, 0.1343, 0.2987, 0.7968, 0.9876, 0.2291],\n",
      "        [0.1968, 0.5056, 0.1688, 0.6687, 0.9624, 0.8983, 0.1265, 0.8305, 0.8529]])\n",
      "\n",
      "torch.Size([16, 200])\n"
     ]
    }
   ],
   "source": [
    "# If you do not want to specify the first shape arguments (# rows), then pass -1 and Pytorch will automaticaaly select the best shape\n",
    "x=torch.rand(18)\n",
    "y=x.view(-1,9)\n",
    "print(y)\n",
    "print(\"\")\n",
    "\n",
    "batch=16\n",
    "x=torch.rand(batch,10,20)\n",
    "y=x.view(batch,-1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9965, 0.0650, 0.0797, 0.5257, 0.3935, 0.0216])\n"
     ]
    }
   ],
   "source": [
    "# Flattiing a tensor\n",
    "x=torch.rand(2,3)\n",
    "y=x.view(-1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 25])\n"
     ]
    }
   ],
   "source": [
    "# permut is used to change the order of the dimensions such as transpose operation in matrix\n",
    "batch=64\n",
    "samples=10\n",
    "features=25\n",
    "x=torch.rand(batch,features,samples)\n",
    "y=x.permute(0,2,1) # 0 is the batch index, 2 is the samples, and 1 is the features\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "\n",
      "torch.Size([1, 15])\n",
      "\n",
      "torch.Size([1, 1, 15])\n",
      "\n",
      "torch.Size([1, 1, 15, 1])\n",
      "\n",
      "torch.Size([1, 15, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Add dimension to a tensor \n",
    "\n",
    "'''\n",
    "x = [1, 2, 3]\n",
    "{x = [1, 2, 3] >>>> >>> x=x.unsqueeze(0) >>>> >>>> x = [[1, 2, 3]]}\n",
    "{x = [1, 2, 3] >>>> >>> x=x.unsqueeze(1) >>>> >>>> x = x = [[1],[2],[3]]}\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "x=torch.arange(15)\n",
    "print(x.shape)\n",
    "print(\"\")\n",
    "\n",
    "x=x.unsqueeze(0) # add a dimension at the beginning  \n",
    "print(x.shape)\n",
    "print(\"\")\n",
    "\n",
    "# Add anotehr dimension at the middle\n",
    "x=x.unsqueeze(1) \n",
    "print(x.shape)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Add anotehr dimension at the end\n",
    "x=x.unsqueeze(-1) \n",
    "print(x.shape)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Eliminate the first dimension from the beginning\n",
    "x=x.squeeze(1) \n",
    "print(x.shape)\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6])\n",
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "# Concatinating two tensors\n",
    "x1=torch.rand(4,6)\n",
    "x2=torch.rand(4,6)\n",
    "print(torch.cat((x1,x2),dim=0).shape) # Concatinate along the rows)    \n",
    "print(torch.cat((x1,x2),dim=1).shape) # Concatinate along the columns)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy and Pytorch conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      " \n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a tensor of ones\n",
    "x=torch.ones(5)\n",
    "print(x)\n",
    "print(\" \")\n",
    "# Conversion to numpy\n",
    "y=x.numpy()\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      " \n",
      "[1. 1. 1. 1. 1.]\n",
      " \n",
      "tensor([4., 4., 4., 4., 4.])\n",
      "[4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Note: If the tensors are located in the CPU (NOT the GPUs), then the tensor and converted np array point to the same memory address.\n",
    "x=torch.ones(5)\n",
    "print(x)\n",
    "print(\" \")\n",
    "\n",
    "# Conversion to numpy\n",
    "y=x.numpy()\n",
    "print(y)\n",
    "print(\" \")\n",
    "\n",
    "# Let us add 3 inplace to all matrix x. Note again: anay  method with trainling _ is used in place\n",
    "x.add_(3)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# Thus be carfull when you make the conversion and using the inplace methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      " \n",
      "[6. 6. 6. 6. 6.]\n",
      " \n",
      "tensor([6., 6., 6., 6., 6.], dtype=torch.float64)\n",
      " \n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Numpy to Pytorch conversion\n",
    "x=np.ones(5)\n",
    "print(x)\n",
    "\n",
    "# Coversion\n",
    "y = torch.from_numpy(x)\n",
    "y1 = torch.from_numpy(x).to(torch.float32)\n",
    "\n",
    "print(y)\n",
    "print(\" \")\n",
    "\n",
    "x+=5\n",
    "\n",
    "print(x)\n",
    "print(\" \")\n",
    "print(y)\n",
    "print(\" \")\n",
    "print(y1)  # This will not be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of availabe GPUs are: 4\n",
      "\n",
      "Details from the GPU 0\n",
      "Name : NVIDIA RTX A6000\n",
      "Compute cabability: 8.6\n",
      "Total memory: 47.54 GB\n",
      "\n",
      "Details from the GPU 1\n",
      "Name : NVIDIA RTX A6000\n",
      "Compute cabability: 8.6\n",
      "Total memory: 47.54 GB\n",
      "\n",
      "Details from the GPU 2\n",
      "Name : NVIDIA RTX A6000\n",
      "Compute cabability: 8.6\n",
      "Total memory: 47.54 GB\n",
      "\n",
      "Details from the GPU 3\n",
      "Name : NVIDIA RTX A6000\n",
      "Compute cabability: 8.6\n",
      "Total memory: 47.54 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is available or not\n",
    "if torch.cuda.is_available():\n",
    "    print(f'The total number of availabe GPUs are: {torch.cuda.device_count()}')\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    device=torch.cuda.get_device_properties(i))\n",
    "    print(f'\\nDetails from the GPU {i}')\n",
    "    print(f'Name : {device.name}')\n",
    "    print(f'Compute cabability: {device.major}.{device.minor}')\n",
    "    print(f'Total memory: {device.total_memory/1024**3:.2f} GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4412, 0.6757, 1.5678, 0.8500, 0.7999],\n",
      "        [1.0786, 0.6483, 1.5910, 1.1502, 1.4139],\n",
      "        [0.8372, 0.9341, 0.3341, 0.4727, 1.2235],\n",
      "        [1.5364, 0.8016, 0.6310, 1.2169, 0.9612],\n",
      "        [1.3565, 0.8035, 1.1249, 1.1857, 1.4396]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor into a GPU\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda:0\") # We can set the desired gpu\n",
    "    x=torch.rand(5,5,device=device)\n",
    "    # Alternativelly\n",
    "    y=torch.rand(5,5)\n",
    "    y=y.to(device)\n",
    "    # Addition\n",
    "    z=x+y\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5000, 2.3000],\n",
      "        [3.5000, 3.3000]])\n",
      "tensor([[2.5000, 2.3000],\n",
      "        [3.5000, 3.3000]], device='cuda:0')\n",
      "torch.float32\n",
      "cuda:0\n",
      "torch.Size([2, 2])\n",
      "2\n",
      "torch.Size([2, 2])\n",
      "2\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor into a GPU or cpu \n",
    "# cpu\n",
    "x=torch.tensor([[2.5,2.3],[3.5,3.3]],dtype=torch.float32,device='cpu')\n",
    "print(x)\n",
    "\n",
    "# GPU\n",
    "x=torch.tensor([[2.5,2.3],[3.5,3.3]],dtype=torch.float32,device='cuda')\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.device)\n",
    "print(x.size())\n",
    "print(x.size(0))\n",
    "print(x.shape)\n",
    "print(x.shape[0])\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Note: Numpy can handle only cpu tensors, thus the follwoing line of code will return an error\n",
    "#z.numpy()\n",
    "\n",
    "# Thus we can move z from the GPU to cpu to convert it into numpy\n",
    "z=z.to(\"cpu\")\n",
    "\n",
    "znumpy=z.numpy()\n",
    "print(type(znumpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1184, 0.4573, 0.5545, 0.1520, 0.5867, 0.6577],\n",
      "        [0.2050, 0.3934, 0.4485, 0.9007, 0.0036, 0.3371],\n",
      "        [0.0056, 0.5949, 0.8334, 0.0306, 0.7424, 0.8395],\n",
      "        [0.4566, 0.2756, 0.9948, 0.7113, 0.0781, 0.5844],\n",
      "        [0.1381, 0.2350, 0.8446, 0.5974, 0.3487, 0.8691]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Telling pytorch that the tensor need to calculate the gradient\n",
    "x=torch.rand(5,6,requires_grad=True) \n",
    "print(x) # requires_grad=True will be printed and in informs teh pytorch that the tensor require gradient calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8278, 0.0268, 0.8620, 0.0368, 0.6558],\n",
      "        [0.3227, 0.1824, 0.3449, 0.4699, 0.8693],\n",
      "        [0.3718, 0.6464, 0.3250, 0.1720, 0.6946],\n",
      "        [0.7781, 0.3550, 0.7605, 0.2204, 0.9655],\n",
      "        [0.6405, 0.1738, 0.8970, 0.4033, 0.4720]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(5,5,requires_grad=True)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
