{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imbalanced Dataset</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style='color:yellow'>An imbalanced dataset is one in which the distribution of data sampels across different classes is uneven.</span></h3>\n",
    "\n",
    "<h3><span style='color:yellow'>Strategies to address imbalanced datasets:</span></h3>\n",
    "\n",
    "<ul style='font-size: 1.2em;'>\n",
    "    <li> Oversampling: Increase the frequency of samples from underrepresented classes to match the representation of the majority class.</li>\n",
    "    <li> Class Weighting: Modify the loss function by assigning higher weights to the minority classes, amplifying their influence during model training.</li>\n",
    "    <li> Synthetic Data Generation: Create artificial data points for the minority class to balance the dataset.</li>\n",
    "</ul>\n",
    "\n",
    "<h3><span style='color:yellow'>The imbalanced dataset I'm using below is highly skewed, consisting of two classes: cats (8 samples) and dogs (2 samples).</span></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Weighting: After building the model, we pass a weight argument to the loss function.\n",
    "# The dataset comprises two classes: 8 samples for the first class and 2 samples for the second class.\n",
    "# We assign a weight of 2 to the first class and a weight of 8 to the second class.\n",
    "\n",
    "\n",
    "# Two class weightining: \n",
    "loss = nn.CrossEntropyLoss(weight=torch.tensor([2, 8])) # 8 is the weight for the minority class\n",
    "\n",
    "# Two class weightining v1: \n",
    "# 8+2 = 10>> 2/10 = 0.2, 8/10 = 0.8\n",
    "loss = nn.CrossEntropyLoss(weight=torch.tensor([0.2, 0.8])) # 8 is the weight for the minority class\n",
    "\n",
    "# Two class weightining v2: \n",
    "# dog/cat = 2/8 = 4,,, cat/dog = 2/8 = 0.25 we need the smaller value to weigh the first (major) class\n",
    "loss = nn.CrossEntropyLoss(weight=torch.tensor([0.25, 4])) # 8 is the weight for the minority class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style='color:yellow'>What if we have four classes? In that case, we should use the total number of samples across all classes as the numerator, i.e., len(dataset) divided by the number of samples in each class.</span></h3>\n",
    "\n",
    "<h3><span style='color:yellow'>If I have four classes and the samples are distributed among the classes as follows: 100, 20, 50, and 250.</span></h3>\n",
    "\n",
    "<h4>weight for Class 1: Total samples / Number of samples of Class 1 = 420/100 = 4.2</h4>\n",
    "<h4>Weight for Class 2: Total samples / Number of samples of Class 2 = 420/20 = 21</h4>\n",
    "<h4>Weight for Class 3: Total samples / Number of samples of Class 3 = 420/50 = 8.4</h4>\n",
    "<h4>Weight for Class 4: Total samples / Number of samples of Class 4 = 420/250 = 1.68</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four class weightining: \n",
    "loss = nn.CrossEntropyLoss(weight=torch.tensor([4.2, 21, 8.4, 1.68]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "root_dir='/home/mohanad/learn/Pytorch/8- Dataset and DataLoader/datastes/imbalanced data'\n",
    "def get_loader_with_sampling(root_dir,batch_size):\n",
    "    image_transform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),])\n",
    "    dataset=datasets.ImageFolder(root=root_dir,transform=image_transform)\n",
    "    \n",
    "    class_weights=[.2,.8]  # This should be determined based on the class and sample distribution as demonstrated in the previous class weighting example.\n",
    "    sample_weights=[0]*len(dataset)\n",
    "    \n",
    "    for idx, (image,label) in enumerate(dataset):\n",
    "        class_weight=class_weights[label]\n",
    "        sample_weights[idx]=class_weight\n",
    "        \n",
    "    sampler=WeightedRandomSampler(sample_weights,num_samples=len(sample_weights),replacement=True) # Setting replacement=True means that a single sample can be selected multiple times during sampling.\n",
    "    loader=DataLoader(dataset=dataset,batch_size=batch_size,sampler=sampler)\n",
    "    return loader\n",
    "    \n",
    "\n",
    "def main():\n",
    "    loader=get_loader_with_sampling(root_dir=root_dir,batch_size=4)\n",
    "    for idx, (images,labels) in enumerate(loader):\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above we imposed the class weight manually, but we can do it automatically as follows:\n",
    "def get_loader_with_sampling(root_dir, batch_size):\n",
    "    image_transform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset=datasets.ImageFolder(root=root_dir, transform=image_transform)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_counts = [0] * len(dataset.classes)  # Initialize counts for each class\n",
    "    for _, label in dataset:\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    total_samples = sum(class_counts)\n",
    "    class_weights = [total_samples / count for count in class_counts]\n",
    "\n",
    "    # Assign sample weights\n",
    "    sample_weights = [0] * len(dataset)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        sample_weights[idx] = class_weights[label]\n",
    "\n",
    "    # Use WeightedRandomSampler\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def main():\n",
    "    loader=get_loader_with_sampling(root_dir=root_dir,batch_size=2)\n",
    "    for idx, (images,labels) in enumerate(loader):\n",
    "        print(labels)\n",
    "        \n",
    "    print(\"\")\n",
    "    num_cat=0\n",
    "    num_dog=0\n",
    "    for epoch in range(15):\n",
    "        for image,label in loader:\n",
    "            num_cat+=torch.sum(label==0)\n",
    "            num_dog+=torch.sum(label==1)\n",
    "    print(\"num_cat: \",num_cat)\n",
    "    print(\"num_dog balanced: \",num_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([1, 0])\n",
      "\n",
      "num_cat:  tensor(70)\n",
      "num_dog balanced:  tensor(80)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
