{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Building a Dataset Class for (NLP) text applications</h1>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style='color:yellow'>For NLP applications, there are many preprocessing steps that should be performed on the raw data.</span></h1>\n",
    "\n",
    "<h3><span style='color:yellow'>Torchtext: A powerful library for text preprocessing.</span></h3>\n",
    "<h3><span style='color:yellow'>Its capabilities include:</span></h3>\n",
    "\n",
    "<ul style='font-size: 1.2em;'>\n",
    "    <li>File loading</li>\n",
    "    <li>Tokenization</li>\n",
    "    <li>Vocabulary building</li>\n",
    "    <li>Numericalization/Indexing</li>\n",
    "    <li>Word embedding</li>\n",
    "    <li>Batching</li>\n",
    "    <li>Embedding lookup: Mapping sentences to fixed-dimension word vectors</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style='color:yellow'>Text Preprocessing Pipeline:</span></h1>\n",
    "\n",
    "<ul style='font-size: 1.2em;'>\n",
    "    <li>Tokenization: Split a sentence into a sequence of words, such as [\"Hello\", \"world\", \".\"].</li>\n",
    "    <li>Vocabulary: Map each word to an index, for example, [0, 1, ...].</li>\n",
    "    <li>Numericalization: Map each word from the list based on its index from the vocabulary to build the feature vector, like [0, 1, ...].</li>\n",
    "    <li>Embedding Lookup: For each word, there is a d-dimensional embedding vector representing that word.</li>\n",
    "    <li>The above d-dimensional vector can be sourced from pretrained embeddings such as GloVe or FastText. Words are mapped from the list based on their index in the vocabulary to construct feature vectors like [5, 1, ...].</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style='color:yellow'>This tutorial can be applied to any JSON, CSV, or TSV (tab-separated files).</span></h1>\n",
    "<h1><span style='color:yellow'>Ensure the data is located in the dataset directory and separated into train and test files.</span></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field,TabularDataset,BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initializes a Field object from torchtext.data, which defines how the DATA should be processed\n",
    "\n",
    "tokenize=lambda x : x.split()\n",
    "\n",
    "quote=Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n",
    "\n",
    "# sequential=Indicates: that the data is a sequence (like a sentence) and not a single value (like a label)\n",
    "# use_vocab=True: This means unique tokens in the data will be converted to unique integers, which is a standard preprocessing step for text \n",
    "# lower=True: This converts all the text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a Field object from torchtext.data, which defines how the SCORES (labels) should be processed\n",
    "score=Field(sequential=False, use_vocab=False)\n",
    "# Note that we are dealing with a sentiment analysis example, so we set \"sequential\" to False. Conversely, for other applications like translation, we must set it to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': ('q', <torchtext.data.field.Field at 0x7f1b08487130>),\n",
       " 'score': ('s', <torchtext.data.field.Field at 0x7f1b08487b20>)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify which column should be used from the dataset.\n",
    "fields={'quote':('q',quote), 'score':('s',score)}\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['q', 's'])\n",
      "\n",
      "dict_values([['do', 'not', 'pray', 'for', 'an', 'easy', 'life,', 'pray', 'for', 'the', 'strength', 'to', 'endure', 'a', 'difficult', 'one.'], 1])\n",
      "\n",
      " The length of the training data is 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Tabular dataset split\n",
    "data_path='./datastes/text data/'\n",
    "train_data, test_data=TabularDataset.splits(\n",
    "    path=data_path,\n",
    "    train='train.json',\n",
    "    test='test.json',\n",
    "    format='json',\n",
    "    fields=fields\n",
    ")\n",
    "\n",
    "# Print a sample of train_data\n",
    "print(train_data[1].__dict__.keys())\n",
    "print('')\n",
    "print(train_data[1].__dict__.values())\n",
    "print('')\n",
    "# Printing the length of train_data \n",
    "print(f' The length of the training data is {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a vocabulary on training data\n",
    "quote.build_vocab(\n",
    "    train_data,\n",
    "    max_size=10000,  # max_size sets a limit on the number of tokens in the vocabulary\n",
    "    min_freq=2,  # min_freq sets a minimum frequency threshold for a token to be included in the vocabulary\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Constructing the iterators to do patch and padding\n",
    "# BucketIterator Creates padding to ensure the length of tokenized (mapped) sentences is consistent (each padding value will be set to 1).\n",
    "\n",
    "train_iterator,test_iterator=BucketIterator.splits(\n",
    "    (train_data,test_data),\n",
    "    batch_size=2,\n",
    "    device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.q]:[torch.LongTensor of size 16x2]\n",
      "\t[.s]:[torch.LongTensor of size 2]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.q]:[torch.LongTensor of size 14x2]\n",
      "\t[.s]:[torch.LongTensor of size 2]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.q]:[torch.LongTensor of size 16x2]\n",
      "\t[.s]:[torch.LongTensor of size 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33, 27],\n",
      "        [19, 29],\n",
      "        [24,  7],\n",
      "        [14, 26],\n",
      "        [15, 18],\n",
      "        [34,  2],\n",
      "        [32, 25],\n",
      "        [31,  1],\n",
      "        [16,  1],\n",
      "        [20,  1],\n",
      "        [22,  1],\n",
      "        [12,  1],\n",
      "        [ 5,  1],\n",
      "        [ 8,  1]])\n",
      "tensor([1, 0])\n",
      "tensor([[10, 10],\n",
      "        [21, 21],\n",
      "        [ 4,  4],\n",
      "        [ 3,  3],\n",
      "        [ 6,  6],\n",
      "        [11, 11],\n",
      "        [17, 17],\n",
      "        [ 4,  4],\n",
      "        [ 3,  3],\n",
      "        [30, 30],\n",
      "        [28, 28],\n",
      "        [ 5,  5],\n",
      "        [13, 13],\n",
      "        [ 2,  2],\n",
      "        [ 9,  9],\n",
      "        [23, 23]])\n",
      "tensor([1, 1])\n",
      "tensor([[33, 27],\n",
      "        [19, 29],\n",
      "        [24,  7],\n",
      "        [14, 26],\n",
      "        [15, 18],\n",
      "        [34,  2],\n",
      "        [32, 25],\n",
      "        [31,  1],\n",
      "        [16,  1],\n",
      "        [20,  1],\n",
      "        [22,  1],\n",
      "        [12,  1],\n",
      "        [ 5,  1],\n",
      "        [ 8,  1]])\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch.q)\n",
    "    print(batch.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We implemented the tokenization step using a lambda function that splits sequences of words by space.\n",
    "# Professionally, we will redo the tokenization using the space library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the above implementation using the spacy library\n",
    "from torchtext.data import Field,TabularDataset,BucketIterator\n",
    "import spacy\n",
    "# !python -m spacy download en_core_web_sm to install the spacy en model\n",
    "\n",
    "spacy_en_model=spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define spacy-based tokenizer to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [token.text for token in spacy_en_model.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "quote=Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n",
    "score=Field(sequential=False, use_vocab=False)\n",
    "\n",
    "fields={'quote':('q',quote), 'score':('s',score)}\n",
    "\n",
    "train_data, test_data=TabularDataset.splits(\n",
    "    path=data_path,\n",
    "    train='train.json',\n",
    "    test='test.json',\n",
    "    format='json',\n",
    "    fields=fields\n",
    ")\n",
    "\n",
    "quote.build_vocab(\n",
    "    train_data,\n",
    "    max_size=10000,\n",
    "    min_freq=2,\n",
    "    vectors='glove.6B.100d'  # using pretrained word embeddings based on GloVe vectors. The size of the vectors is 1GB\n",
    ")\n",
    "\n",
    "train_iterator,test_iterator=BucketIterator.splits(\n",
    "    (train_data,test_data),\n",
    "    batch_size=2,\n",
    "    device='cpu')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 29],\n",
      "        [25, 31],\n",
      "        [ 7,  3],\n",
      "        [ 5, 11],\n",
      "        [10, 28],\n",
      "        [15, 22],\n",
      "        [21,  4],\n",
      "        [ 3, 27],\n",
      "        [ 7,  9],\n",
      "        [ 5,  1],\n",
      "        [32,  1],\n",
      "        [30,  1],\n",
      "        [ 8,  1],\n",
      "        [17,  1],\n",
      "        [ 4,  1],\n",
      "        [13,  1],\n",
      "        [ 6,  1],\n",
      "        [ 2,  1]])\n",
      "tensor([1, 0])\n",
      "tensor([[35, 29],\n",
      "        [23, 31],\n",
      "        [26,  3],\n",
      "        [18, 11],\n",
      "        [19, 28],\n",
      "        [36, 22],\n",
      "        [34,  4],\n",
      "        [ 2, 27],\n",
      "        [33,  9],\n",
      "        [20,  1],\n",
      "        [24,  1],\n",
      "        [ 6,  1],\n",
      "        [16,  1],\n",
      "        [ 8,  1],\n",
      "        [12,  1],\n",
      "        [ 2,  1]])\n",
      "tensor([1, 0])\n",
      "tensor([[35, 14],\n",
      "        [23, 25],\n",
      "        [26,  7],\n",
      "        [18,  5],\n",
      "        [19, 10],\n",
      "        [36, 15],\n",
      "        [34, 21],\n",
      "        [ 2,  3],\n",
      "        [33,  7],\n",
      "        [20,  5],\n",
      "        [24, 32],\n",
      "        [ 6, 30],\n",
      "        [16,  8],\n",
      "        [ 8, 17],\n",
      "        [12,  4],\n",
      "        [ 2, 13],\n",
      "        [ 1,  6],\n",
      "        [ 1,  2]])\n",
      "tensor([1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/.local/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch.q)\n",
    "    print(batch.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can repeat the above implementation for CSV and TSV files. The only difference is the format parameter in the TabularDataset.splits() function.\n",
    "\n",
    "train_data, test_data=TabularDataset.splits(\n",
    "    path=data_path,\n",
    "    train='train.csv',\n",
    "    test='test.csv',\n",
    "    format='csv',\n",
    "    fields=fields)\n",
    "    \n",
    "    \n",
    "#or \n",
    "\n",
    "train_data, test_data=TabularDataset.splits(\n",
    "    path=data_path,\n",
    "    train='train.tsv',\n",
    "    test='test.tsv',\n",
    "    format='tsv',\n",
    "    fields=fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will revisit this implementation to build a model, such as an RNN-LSTM, in upcoming tutorials when we cover RNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
